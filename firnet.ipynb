{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b806ae9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T06:56:08.653753Z",
     "iopub.status.busy": "2025-08-11T06:56:08.653432Z",
     "iopub.status.idle": "2025-08-11T06:56:08.775296Z",
     "shell.execute_reply": "2025-08-11T06:56:08.774413Z"
    },
    "papermill": {
     "duration": 0.12831,
     "end_time": "2025-08-11T06:56:08.776872",
     "exception": false,
     "start_time": "2025-08-11T06:56:08.648562",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.12\r\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "085cb32f",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-08-11T06:56:08.784862Z",
     "iopub.status.busy": "2025-08-11T06:56:08.784573Z",
     "iopub.status.idle": "2025-08-11T06:56:14.213636Z",
     "shell.execute_reply": "2025-08-11T06:56:14.212736Z"
    },
    "papermill": {
     "duration": 5.434648,
     "end_time": "2025-08-11T06:56:14.215194",
     "exception": false,
     "start_time": "2025-08-11T06:56:08.780546",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\r\n",
      "Copyright (c) 2005-2023 NVIDIA Corporation\r\n",
      "Built on Tue_Aug_15_22:02:13_PDT_2023\r\n",
      "Cuda compilation tools, release 12.2, V12.2.140\r\n",
      "Build cuda_12.2.r12.2/compiler.33191640_0\r\n",
      "PyTorch: 2.5.1+cu121 CUDA Available: True CUDA Version: 12.1\r\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version\n",
    "!python -c \"import torch; print('PyTorch:', torch.__version__, 'CUDA Available:', torch.cuda.is_available(), 'CUDA Version:', torch.version.cuda)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c8e2d3e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T06:56:14.223530Z",
     "iopub.status.busy": "2025-08-11T06:56:14.223246Z",
     "iopub.status.idle": "2025-08-11T06:57:21.569561Z",
     "shell.execute_reply": "2025-08-11T06:57:21.568498Z"
    },
    "papermill": {
     "duration": 67.352895,
     "end_time": "2025-08-11T06:57:21.572038",
     "exception": false,
     "start_time": "2025-08-11T06:56:14.219143",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Skipping mmcv as it is not installed.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Skipping mmcv-full as it is not installed.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Skipping mmdet as it is not installed.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Step 2: Uninstall Conflicting Packages\n",
    "!pip uninstall -y mmcv mmcv-full mmdet torch torchvision tensorflow tensorboard -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa76893a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T06:57:21.580384Z",
     "iopub.status.busy": "2025-08-11T06:57:21.580100Z",
     "iopub.status.idle": "2025-08-11T06:59:42.255899Z",
     "shell.execute_reply": "2025-08-11T06:59:42.254845Z"
    },
    "papermill": {
     "duration": 140.681619,
     "end_time": "2025-08-11T06:59:42.257646",
     "exception": false,
     "start_time": "2025-08-11T06:57:21.576027",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 GB\u001b[0m \u001b[31m459.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.2/24.2 MB\u001b[0m \u001b[31m75.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "pytorch-lightning 2.5.0.post0 requires torch>=2.1.0, but you have torch 1.13.1+cu116 which is incompatible.\r\n",
      "torchaudio 2.5.1+cu121 requires torch==2.5.1, but you have torch 1.13.1+cu116 which is incompatible.\r\n",
      "torchmetrics 1.6.1 requires torch>=2.0.0, but you have torch 1.13.1+cu116 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 MB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.8/46.8 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m256.2/256.2 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.5/259.5 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.1/50.1 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.7/89.7 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m449.6/449.6 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.5/311.5 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.4/239.4 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m506.5/506.5 kB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.2/144.2 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.1/953.1 kB\u001b[0m \u001b[31m47.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.5/99.5 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Building wheel for oss2 (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Building wheel for aliyun-python-sdk-core (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Building wheel for crcmod (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "dopamine-rl 4.1.0 requires tensorflow>=2.2.0, which is not installed.\r\n",
      "tensorflow-decision-forests 1.10.0 requires tensorflow==2.17.0, which is not installed.\r\n",
      "datasets 3.3.1 requires requests>=2.32.2, but you have requests 2.28.2 which is incompatible.\r\n",
      "datasets 3.3.1 requires tqdm>=4.66.3, but you have tqdm 4.65.2 which is incompatible.\r\n",
      "featuretools 1.31.0 requires tqdm>=4.66.3, but you have tqdm 4.65.2 which is incompatible.\r\n",
      "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.12.0 which is incompatible.\r\n",
      "google-cloud-bigtable 2.27.0 requires google-api-core[grpc]<3.0.0dev,>=2.16.0, but you have google-api-core 1.34.1 which is incompatible.\r\n",
      "google-colab 1.0.0 requires notebook==6.5.5, but you have notebook 6.5.4 which is incompatible.\r\n",
      "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\r\n",
      "google-colab 1.0.0 requires requests==2.32.3, but you have requests 2.28.2 which is incompatible.\r\n",
      "jupyterlab-server 2.27.3 requires requests>=2.31, but you have requests 2.28.2 which is incompatible.\r\n",
      "langchain 0.3.12 requires async-timeout<5.0.0,>=4.0.0; python_version < \"3.11\", but you have async-timeout 5.0.1 which is incompatible.\r\n",
      "pandas-gbq 0.25.0 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\r\n",
      "plotnine 0.14.4 requires matplotlib>=3.8.0, but you have matplotlib 3.7.5 which is incompatible.\r\n",
      "pymc 5.19.1 requires rich>=13.7.1, but you have rich 13.4.2 which is incompatible.\r\n",
      "pytensor 2.26.4 requires filelock>=3.15, but you have filelock 3.14.0 which is incompatible.\r\n",
      "pytorch-lightning 2.5.0.post0 requires torch>=2.1.0, but you have torch 1.13.1+cu116 which is incompatible.\r\n",
      "sphinx 8.1.3 requires requests>=2.30.0, but you have requests 2.28.2 which is incompatible.\r\n",
      "torchmetrics 1.6.1 requires torch>=2.0.0, but you have torch 1.13.1+cu116 which is incompatible.\r\n",
      "yfinance 0.2.50 requires requests>=2.31, but you have requests 2.28.2 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.7/452.7 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install torch==1.13.1+cu116 torchvision==0.14.1+cu116 -f https://download.pytorch.org/whl/torch_stable.html -q\n",
    "!pip install mmcv-full==1.7.1 -f https://download.openmmlab.com/mmcv/dist/cu116/torch1.13.0/index.html -q\n",
    "!pip install mmdet==2.28.2 -q\n",
    "!pip install -U openmim -q\n",
    "!mim install \"mmengine>=0.7.0\" -q\n",
    "!pip install xmltodict -q  # For dataset conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c9b829c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T06:59:42.331631Z",
     "iopub.status.busy": "2025-08-11T06:59:42.331347Z",
     "iopub.status.idle": "2025-08-11T06:59:53.796252Z",
     "shell.execute_reply": "2025-08-11T06:59:53.795189Z"
    },
    "papermill": {
     "duration": 11.503187,
     "end_time": "2025-08-11T06:59:53.797907",
     "exception": false,
     "start_time": "2025-08-11T06:59:42.294720",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into '/kaggle/working/mmrotate'...\r\n",
      "remote: Enumerating objects: 482, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (482/482), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (333/333), done.\u001b[K\r\n",
      "remote: Total 482 (delta 143), reused 474 (delta 135), pack-reused 0 (from 0)\u001b[K\r\n",
      "Receiving objects: 100% (482/482), 11.52 MiB | 33.80 MiB/s, done.\r\n",
      "Resolving deltas: 100% (143/143), done.\r\n",
      "/kaggle/working/mmrotate\n",
      "Obtaining file:///kaggle/working/mmrotate\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "Collecting e2cnn (from mmrotate==0.3.4)\r\n",
      "  Downloading e2cnn-0.2.3-py3-none-any.whl.metadata (15 kB)\r\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mmrotate==0.3.4) (3.7.5)\r\n",
      "Requirement already satisfied: mmcv-full in /usr/local/lib/python3.10/dist-packages (from mmrotate==0.3.4) (1.7.1)\r\n",
      "Requirement already satisfied: mmdet<3.0.0,>=2.25.1 in /usr/local/lib/python3.10/dist-packages (from mmrotate==0.3.4) (2.28.2)\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mmrotate==0.3.4) (1.26.4)\r\n",
      "Requirement already satisfied: pycocotools in /usr/local/lib/python3.10/dist-packages (from mmrotate==0.3.4) (2.0.8)\r\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from mmrotate==0.3.4) (1.17.0)\r\n",
      "Requirement already satisfied: terminaltables in /usr/local/lib/python3.10/dist-packages (from mmrotate==0.3.4) (3.1.10)\r\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from mmrotate==0.3.4) (1.13.1+cu116)\r\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from mmdet<3.0.0,>=2.25.1->mmrotate==0.3.4) (1.13.1)\r\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from e2cnn->mmrotate==0.3.4) (1.13.1)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmrotate==0.3.4) (1.3.1)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmrotate==0.3.4) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmrotate==0.3.4) (4.55.3)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmrotate==0.3.4) (1.4.7)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmrotate==0.3.4) (24.2)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmrotate==0.3.4) (11.0.0)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmrotate==0.3.4) (3.2.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmrotate==0.3.4) (2.9.0.post0)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->mmrotate==0.3.4) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->mmrotate==0.3.4) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->mmrotate==0.3.4) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->mmrotate==0.3.4) (2025.0.1)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->mmrotate==0.3.4) (2022.0.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->mmrotate==0.3.4) (2.4.1)\r\n",
      "Requirement already satisfied: addict in /usr/local/lib/python3.10/dist-packages (from mmcv-full->mmrotate==0.3.4) (2.4.0)\r\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from mmcv-full->mmrotate==0.3.4) (6.0.2)\r\n",
      "Requirement already satisfied: yapf in /usr/local/lib/python3.10/dist-packages (from mmcv-full->mmrotate==0.3.4) (0.43.0)\r\n",
      "Requirement already satisfied: opencv-python>=3 in /usr/local/lib/python3.10/dist-packages (from mmcv-full->mmrotate==0.3.4) (4.10.0.84)\r\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->mmrotate==0.3.4) (4.12.2)\r\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->mmrotate==0.3.4) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->mmrotate==0.3.4) (2022.0.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->mmrotate==0.3.4) (1.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->mmrotate==0.3.4) (2024.2.0)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->e2cnn->mmrotate==0.3.4) (1.3.0)\r\n",
      "Requirement already satisfied: platformdirs>=3.5.1 in /usr/local/lib/python3.10/dist-packages (from yapf->mmcv-full->mmrotate==0.3.4) (4.3.6)\r\n",
      "Requirement already satisfied: tomli>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from yapf->mmcv-full->mmrotate==0.3.4) (2.2.1)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->mmrotate==0.3.4) (2024.2.0)\r\n",
      "Downloading e2cnn-0.2.3-py3-none-any.whl (225 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.3/225.3 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: e2cnn, mmrotate\r\n",
      "  Running setup.py develop for mmrotate\r\n",
      "Successfully installed e2cnn-0.2.3 mmrotate-0.3.4\r\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Clone and Install MMRotate 0.3.4\n",
    "!git clone https://github.com/zhangpeng2001/nirnet.git /kaggle/working/mmrotate\n",
    "%cd /kaggle/working/mmrotate\n",
    "# !git checkout v0.3.4  # Ensure exact version\n",
    "!pip install -r requirements/build.txt -q\n",
    "!pip install -v -e . -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5300285f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T06:59:53.873399Z",
     "iopub.status.busy": "2025-08-11T06:59:53.873079Z",
     "iopub.status.idle": "2025-08-11T06:59:55.203541Z",
     "shell.execute_reply": "2025-08-11T06:59:55.202612Z"
    },
    "papermill": {
     "duration": 1.370368,
     "end_time": "2025-08-11T06:59:55.205774",
     "exception": false,
     "start_time": "2025-08-11T06:59:53.835406",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mmcv-full                          1.7.1\r\n",
      "mmdet                              2.28.2\r\n",
      "mmengine                           0.10.7\r\n",
      "mmrotate                           0.3.4                /kaggle/working/mmrotate\r\n",
      "numpy                              1.26.4\r\n",
      "pytorch-ignite                     0.5.1\r\n",
      "pytorch-lightning                  2.5.0.post0\r\n",
      "torch                              1.13.1+cu116\r\n",
      "torchaudio                         2.5.1+cu121\r\n",
      "torchinfo                          1.8.0\r\n",
      "torchmetrics                       1.6.1\r\n",
      "torchsummary                       1.5.1\r\n",
      "torchtune                          0.5.0\r\n",
      "torchvision                        0.14.1+cu116\r\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Verify Installations\n",
    "!pip list | grep -E 'torch|mmcv|mmdet|mmengine|mmrotate|numpy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c742fab8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T06:59:55.280406Z",
     "iopub.status.busy": "2025-08-11T06:59:55.280100Z",
     "iopub.status.idle": "2025-08-11T06:59:55.294287Z",
     "shell.execute_reply": "2025-08-11T06:59:55.293676Z"
    },
    "papermill": {
     "duration": 0.05271,
     "end_time": "2025-08-11T06:59:55.295546",
     "exception": false,
     "start_time": "2025-08-11T06:59:55.242836",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 6: Prepare Dataset (SCCOS to DOTA format)\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import xmltodict\n",
    "import tqdm\n",
    "import math\n",
    "\n",
    "dataset_path = \"/kaggle/input/sccos-dataset/\"\n",
    "working_dir = \"/kaggle/working/sccos_dota\"\n",
    "train_images_dir = os.path.join(working_dir, \"train/images\")\n",
    "train_labels_dir = os.path.join(working_dir, \"train/labels\")\n",
    "val_images_dir = os.path.join(working_dir, \"val/images\")\n",
    "val_labels_dir = os.path.join(working_dir, \"val/labels\")\n",
    "test_images_dir = os.path.join(working_dir, \"test/images\")\n",
    "test_labels_dir = os.path.join(working_dir, \"test/labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45baa8de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T06:59:55.369891Z",
     "iopub.status.busy": "2025-08-11T06:59:55.369645Z",
     "iopub.status.idle": "2025-08-11T07:01:35.366687Z",
     "shell.execute_reply": "2025-08-11T07:01:35.365614Z"
    },
    "papermill": {
     "duration": 100.036283,
     "end_time": "2025-08-11T07:01:35.368210",
     "exception": false,
     "start_time": "2025-08-11T06:59:55.331927",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset split: Train=3711, Val=464, Test=464\n",
      "Converting train set to DOTA format...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3711/3711 [00:01<00:00, 2181.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting val set to DOTA format...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 464/464 [00:00<00:00, 2070.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting test set to DOTA format...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 464/464 [00:00<00:00, 2190.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset conversion to DOTA format complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Clean and recreate directories\n",
    "if os.path.exists(working_dir):\n",
    "    shutil.rmtree(working_dir)\n",
    "for dir_path in [train_images_dir, train_labels_dir, val_images_dir, val_labels_dir, test_images_dir, test_labels_dir]:\n",
    "    os.makedirs(dir_path, exist_ok=True)\n",
    "\n",
    "# Source paths\n",
    "train_img_dir = os.path.join(dataset_path, \"train/images\")\n",
    "train_ann_dir = os.path.join(dataset_path, \"train/annotations\")\n",
    "test_img_dir = os.path.join(dataset_path, \"test/images\")\n",
    "test_ann_dir = os.path.join(dataset_path, \"test/annotations\")\n",
    "\n",
    "# Get all files and split\n",
    "train_files = [f for f in os.listdir(train_img_dir) if f.endswith('.png')]\n",
    "test_files = [f for f in os.listdir(test_img_dir) if f.endswith('.png')]\n",
    "random.seed(42)\n",
    "random.shuffle(train_files)\n",
    "random.shuffle(test_files)\n",
    "test_size = len(test_files)\n",
    "val_size = test_size // 2\n",
    "val_files = test_files[:val_size]\n",
    "test_files = test_files[val_size:]\n",
    "\n",
    "# Copy files\n",
    "def copy_files(file_list, src_img_dir, src_ann_dir, dst_img_dir, dst_ann_dir):\n",
    "    for img_file in file_list:\n",
    "        shutil.copy(os.path.join(src_img_dir, img_file), os.path.join(dst_img_dir, img_file))\n",
    "        ann_file = img_file.replace('.png', '.xml')\n",
    "        if os.path.exists(os.path.join(src_ann_dir, ann_file)):\n",
    "            shutil.copy(os.path.join(src_ann_dir, ann_file), os.path.join(dst_ann_dir, ann_file))\n",
    "\n",
    "copy_files(train_files, train_img_dir, train_ann_dir, train_images_dir, train_labels_dir)\n",
    "copy_files(val_files, test_img_dir, test_ann_dir, val_images_dir, val_labels_dir)\n",
    "copy_files(test_files, test_img_dir, test_ann_dir, test_images_dir, test_labels_dir)\n",
    "print(f\"Dataset split: Train={len(train_files)}, Val={len(val_files)}, Test={len(test_files)}\")\n",
    "\n",
    "# Convert XML to DOTA format\n",
    "def convert_robndbox_to_corners(cx, cy, w, h, angle):\n",
    "    angle = float(angle)\n",
    "    cx, cy, w, h = float(cx), float(cy), float(w), float(h)\n",
    "    cos_a = math.cos(angle)\n",
    "    sin_a = math.sin(angle)\n",
    "    dx, dy = w / 2, h / 2\n",
    "    corners = [(-dx, -dy), (dx, -dy), (dx, dy), (-dx, dy)]\n",
    "    rotated_corners = [(cx + x * cos_a - y * sin_a, cy + x * sin_a + y * cos_a) for x, y in corners]\n",
    "    return rotated_corners\n",
    "\n",
    "def convert_xml_to_dota(xml_path, output_label_dir):\n",
    "    with open(xml_path, 'r') as f:\n",
    "        xml_data = xmltodict.parse(f.read())\n",
    "    objects = xml_data['annotation'].get('object', [])\n",
    "    if not isinstance(objects, list):\n",
    "        objects = [objects] if objects else []\n",
    "    txt_lines = []\n",
    "    for obj in objects:\n",
    "        if obj and 'robndbox' in obj:\n",
    "            robndbox = obj['robndbox']\n",
    "            try:\n",
    "                cx, cy, w, h, angle = robndbox['cx'], robndbox['cy'], robndbox['w'], robndbox['h'], robndbox['angle']\n",
    "                (x1, y1), (x2, y2), (x3, y3), (x4, y4) = convert_robndbox_to_corners(cx, cy, w, h, angle)\n",
    "                class_name = \"ship\"\n",
    "                difficulty = 0\n",
    "                txt_lines.append(f\"{x1:.2f} {y1:.2f} {x2:.2f} {y2:.2f} {x3:.2f} {y3:.2f} {x4:.2f} {y4:.2f} {class_name} {difficulty}\")\n",
    "            except (KeyError, ValueError) as e:\n",
    "                print(f\"Invalid robndbox data in {xml_path}: {e}\")\n",
    "                continue\n",
    "    txt_filename = os.path.splitext(os.path.basename(xml_path))[0] + \".txt\"\n",
    "    txt_path = os.path.join(output_label_dir, txt_filename)\n",
    "    if txt_lines:\n",
    "        with open(txt_path, 'w') as f:\n",
    "            f.write(\"\\n\".join(txt_lines))\n",
    "    os.remove(xml_path)\n",
    "\n",
    "for split, label_dir in [(\"train\", train_labels_dir), (\"val\", val_labels_dir), (\"test\", test_labels_dir)]:\n",
    "    print(f\"Converting {split} set to DOTA format...\")\n",
    "    for xml_file in tqdm.tqdm(os.listdir(label_dir)):\n",
    "        if xml_file.endswith(\".xml\"):\n",
    "            convert_xml_to_dota(os.path.join(label_dir, xml_file), label_dir)\n",
    "print(\"Dataset conversion to DOTA format complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2e67e7e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T07:01:35.447958Z",
     "iopub.status.busy": "2025-08-11T07:01:35.447692Z",
     "iopub.status.idle": "2025-08-11T07:03:21.070023Z",
     "shell.execute_reply": "2025-08-11T07:03:21.069058Z"
    },
    "papermill": {
     "duration": 105.702396,
     "end_time": "2025-08-11T07:03:21.110456",
     "exception": false,
     "start_time": "2025-08-11T07:01:35.408060",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.2/190.2 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating training images...\n",
      "Empty file detected: /kaggle/working/sccos_dota/train/images/2284.png\n",
      "Removed bad image: /kaggle/working/sccos_dota/train/images/2284.png\n",
      "Removed corresponding label: /kaggle/working/sccos_dota/train/labels/2284.txt\n",
      "Found and handled 1 bad files.\n"
     ]
    }
   ],
   "source": [
    "# NEW: Fix YAPF compatibility issue\n",
    "!pip install yapf==0.32.0 -q  # Pin to a version compatible with MMCV 1.7.1\n",
    "\n",
    "# NEW: Validate training images\n",
    "import os\n",
    "import cv2\n",
    "import mmcv\n",
    "\n",
    "def validate_images(image_dir, label_dir):\n",
    "    bad_files = []\n",
    "    for img_file in os.listdir(image_dir):\n",
    "        if not img_file.endswith('.png'):\n",
    "            continue\n",
    "        img_path = os.path.join(image_dir, img_file)\n",
    "        # Check if file is empty\n",
    "        if os.path.getsize(img_path) == 0:\n",
    "            bad_files.append(img_file)\n",
    "            print(f\"Empty file detected: {img_path}\")\n",
    "            continue\n",
    "        # Try loading with mmcv (mimics pipeline behavior)\n",
    "        try:\n",
    "            img = mmcv.imread(img_path)\n",
    "            if img is None:\n",
    "                raise ValueError(\"Image loaded as None\")\n",
    "        except Exception as e:\n",
    "            bad_files.append(img_file)\n",
    "            print(f\"Corrupt or unreadable file: {img_path} - Error: {e}\")\n",
    "    \n",
    "    # Remove bad files and their labels\n",
    "    for bad_file in bad_files:\n",
    "        img_path = os.path.join(image_dir, bad_file)\n",
    "        label_file = bad_file.replace('.png', '.txt')\n",
    "        label_path = os.path.join(label_dir, label_file)\n",
    "        if os.path.exists(img_path):\n",
    "            os.remove(img_path)\n",
    "            print(f\"Removed bad image: {img_path}\")\n",
    "        if os.path.exists(label_path):\n",
    "            os.remove(label_path)\n",
    "            print(f\"Removed corresponding label: {label_path}\")\n",
    "    \n",
    "    if bad_files:\n",
    "        print(f\"Found and handled {len(bad_files)} bad files.\")\n",
    "    else:\n",
    "        print(\"All images validated successfully.\")\n",
    "\n",
    "# Validate training set\n",
    "train_images_dir = \"/kaggle/working/sccos_dota/train/images\"\n",
    "train_labels_dir = \"/kaggle/working/sccos_dota/train/labels\"\n",
    "print(\"Validating training images...\")\n",
    "validate_images(train_images_dir, train_labels_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "afd7218f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T07:03:21.227944Z",
     "iopub.status.busy": "2025-08-11T07:03:21.227475Z",
     "iopub.status.idle": "2025-08-11T07:03:21.825023Z",
     "shell.execute_reply": "2025-08-11T07:03:21.823781Z"
    },
    "papermill": {
     "duration": 0.677811,
     "end_time": "2025-08-11T07:03:21.826573",
     "exception": false,
     "start_time": "2025-08-11T07:03:21.148762",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create directories for both models\n",
    "!mkdir -p configs/firnet\n",
    "# !mkdir -p configs/sparsefreqattnnet\n",
    "!mkdir -p /kaggle/working/runs/firnet_train\n",
    "!mkdir -p /kaggle/working/runs/sparsefreqattnnet_train\n",
    "!mkdir -p /kaggle/working/runs/firnet_test\n",
    "!mkdir -p /kaggle/working/runs/sparsefreqattnnet_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85ef0426",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T07:03:21.905113Z",
     "iopub.status.busy": "2025-08-11T07:03:21.904786Z",
     "iopub.status.idle": "2025-08-11T07:03:21.911970Z",
     "shell.execute_reply": "2025-08-11T07:03:21.911327Z"
    },
    "papermill": {
     "duration": 0.047718,
     "end_time": "2025-08-11T07:03:21.913171",
     "exception": false,
     "start_time": "2025-08-11T07:03:21.865453",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mmrotate/models/necks/nirnet.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mmrotate/models/necks/nirnet.py\n",
    "import torch\n",
    "\n",
    "from mmcv.cnn import ConvModule\n",
    "from mmcv.runner import auto_fp16\n",
    "from mmdet.models.necks import FPN\n",
    "from mmcv.cnn.bricks.transformer import MultiheadAttention\n",
    "\n",
    "from ..builder import ROTATED_NECKS\n",
    "\n",
    "\n",
    "@ROTATED_NECKS.register_module()\n",
    "class NIRNet(FPN):\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 out_channels,\n",
    "                 num_outs,\n",
    "                 num_groups=4,  # New: For group attention\n",
    "                 conv_cfg=None,\n",
    "                 norm_cfg=None,\n",
    "                 act_cfg=None,\n",
    "                 **kwargs):\n",
    "        super(NIRNet, self).__init__(\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            num_outs,\n",
    "            conv_cfg=conv_cfg,\n",
    "            norm_cfg=norm_cfg,\n",
    "            act_cfg=act_cfg,\n",
    "            **kwargs)\n",
    "\n",
    "        self.num_groups = num_groups  # New: Group attention param\n",
    "\n",
    "        self.encoder_conv = ConvModule(\n",
    "            out_channels,\n",
    "            out_channels,\n",
    "            3,\n",
    "            padding=1,\n",
    "            conv_cfg=conv_cfg,\n",
    "            norm_cfg=norm_cfg,\n",
    "            act_cfg=act_cfg,\n",
    "            groups=out_channels,\n",
    "            inplace=False)\n",
    "        self.fusion_conv = ConvModule(\n",
    "            out_channels,\n",
    "            out_channels,\n",
    "            3,\n",
    "            padding=1,\n",
    "            conv_cfg=conv_cfg,\n",
    "            norm_cfg=norm_cfg,\n",
    "            act_cfg=act_cfg,\n",
    "            inplace=False)\n",
    "        self.excite_conv = ConvModule(\n",
    "            out_channels,\n",
    "            out_channels,\n",
    "            3,\n",
    "            padding=1,\n",
    "            conv_cfg=conv_cfg,\n",
    "            norm_cfg=norm_cfg,\n",
    "            act_cfg=act_cfg,\n",
    "            inplace=False)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        self.fcm_ip_channel_fc = torch.nn.Linear(out_channels // 2, 1)\n",
    "        self.fcm_ip_channel_atten = MultiheadAttention(embed_dims=16, num_heads=8)\n",
    "        self.fcm_sp_channel_atten = MultiheadAttention(embed_dims=16, num_heads=8)\n",
    "        self.fcm_sp_channel_fc = torch.nn.Linear(out_channels // 2, 1)\n",
    "\n",
    "        # New: Lightweight group attention convs (one per group, shared across paths for efficiency)\n",
    "        self.group_attn_convs = torch.nn.ModuleList([\n",
    "            ConvModule(\n",
    "                out_channels // (2 * num_groups),  # Split channels further for IP/SP\n",
    "                out_channels // (2 * num_groups),\n",
    "                1,\n",
    "                conv_cfg=conv_cfg,\n",
    "                norm_cfg=norm_cfg,\n",
    "                act_cfg=None) for _ in range(num_groups)\n",
    "        ])\n",
    "\n",
    "    @auto_fp16()\n",
    "    def forward(self, inputs):\n",
    "        outs = super(NIRNet, self).forward(inputs)\n",
    "        outs = self.dpic(outs)\n",
    "        return tuple(outs)\n",
    "\n",
    "    def dpic(self, feats):\n",
    "\n",
    "        encoder_feats = []\n",
    "        \n",
    "        for feat in feats:\n",
    "            split_feat = self.encoder_conv(feat)\n",
    "            dw_feat, pw_feat = torch.split(split_feat, split_size_or_sections=128, dim=1)\n",
    "            # Enhanced NPM with frequency\n",
    "            weight1, weight2 = self.fp_npm(feat)\n",
    "            # Enhanced FCM with group attention\n",
    "            fcm_sp_feat = self.fcm_sp(pw_feat * (1 + weight1))\n",
    "            fcm_ip_feat = self.fcm_ip(dw_feat * (1 + weight2))\n",
    "            # Concatenation and fusion\n",
    "            fusion_feat = self.fusion_conv(torch.cat([fcm_ip_feat , fcm_sp_feat], dim=1))\n",
    "            encoder_feats.append(fusion_feat + feat)\n",
    "            \n",
    "        return encoder_feats\n",
    "    \n",
    "    def fcm_ip(self, feat):\n",
    "        # Optimal mask\n",
    "        pixel_feat = torch.max(feat, 1, keepdim=True)[0]\n",
    "        pixel_feat = pixel_feat + self.fcm_ip_channel_fc(feat.permute(0, 2, 3, 1)).permute(0, 3, 1, 2)\n",
    "        # Optimal descriptor\n",
    "        flatten_feat = feat.view(feat.size(0), feat.size(1), -1)\n",
    "        channel_feat_mean = torch.mean(flatten_feat, 2, keepdim=True).view(feat.size(0), 8, 16)\n",
    "        channel_feat_max = torch.max(flatten_feat, 2, keepdim=True)[0].view(feat.size(0), 8, 16)\n",
    "        channel_feat = self.fcm_ip_channel_atten(channel_feat_mean, channel_feat_mean, channel_feat_max)\n",
    "        channel_feat = channel_feat.view(channel_feat.size(0), -1).unsqueeze(-1).unsqueeze(-1)\n",
    "        # New: Group attention\n",
    "        channel_feat = self._apply_group_attention(channel_feat)\n",
    "        # Optimal feature\n",
    "        fcm_ip_feat = pixel_feat * channel_feat \n",
    "        return fcm_ip_feat\n",
    "    \n",
    "    def fcm_sp(self, feat):\n",
    "        # Holistic mask\n",
    "        pixel_feat = torch.mean(feat, 1, keepdim=True)\n",
    "        pixel_feat = pixel_feat + self.fcm_sp_channel_fc(feat.permute(0, 2, 3, 1)).permute(0, 3, 1, 2)\n",
    "        # Holistic descriptor\n",
    "        flatten_feat = feat.view(feat.size(0), feat.size(1), -1)\n",
    "        channel_feat_mean = self.sigmoid(torch.mean(flatten_feat, 2, keepdim=True).view(feat.size(0), 8, 16))\n",
    "        channel_feat_max = self.sigmoid(torch.max(flatten_feat, 2, keepdim=True)[0].view(feat.size(0), 8, 16))\n",
    "        channel_feat = self.fcm_sp_channel_atten(channel_feat_mean, channel_feat_mean, channel_feat_max)\n",
    "        channel_feat = channel_feat.view(channel_feat.size(0), -1).unsqueeze(-1).unsqueeze(-1)\n",
    "        # New: Group attention\n",
    "        channel_feat = self._apply_group_attention(channel_feat)\n",
    "        # Holistic feature\n",
    "        fcm_sp_feat = pixel_feat * channel_feat\n",
    "        return fcm_sp_feat\n",
    "\n",
    "    def fp_npm(self, feat):\n",
    "        # Original spatial min\n",
    "        pixel_feat = torch.min(feat, 1, keepdim=True)[0]\n",
    "        channel_feat = torch.min(torch.min(feat, 2, keepdim=True)[0], 3, keepdim=True)[0]\n",
    "        pcmin_feat = pixel_feat * channel_feat\n",
    "        # New: Frequency perception (low-freq blur, high-freq residual)\n",
    "        low_freq = torch.nn.functional.avg_pool2d(feat, kernel_size=3, stride=1, padding=1)\n",
    "        high_freq = feat - low_freq\n",
    "        freq_min = torch.min(low_freq, high_freq)\n",
    "        # Fuse spatial + freq\n",
    "        pcmin_feat = pcmin_feat + freq_min  # Simple addition for fusion\n",
    "        excitation = self.excite_conv(pcmin_feat)\n",
    "        excitation = self.sigmoid(excitation)\n",
    "        excitation1, excitation2 = torch.split(excitation, split_size_or_sections=128, dim=1)\n",
    "        return excitation1, excitation2\n",
    "\n",
    "    # New: Helper for group attention\n",
    "    def _apply_group_attention(self, feat):\n",
    "        groups = torch.chunk(feat, self.num_groups, dim=1)  # Split channels\n",
    "        attn_groups = [self.sigmoid(self.group_attn_convs[i](g)) * g for i, g in enumerate(groups)]\n",
    "        return torch.cat(attn_groups, dim=1)  # Fuse back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25d64a33",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T07:03:21.991067Z",
     "iopub.status.busy": "2025-08-11T07:03:21.990814Z",
     "iopub.status.idle": "2025-08-11T07:03:21.997074Z",
     "shell.execute_reply": "2025-08-11T07:03:21.996179Z"
    },
    "papermill": {
     "duration": 0.046859,
     "end_time": "2025-08-11T07:03:21.998487",
     "exception": false,
     "start_time": "2025-08-11T07:03:21.951628",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing configs/firnet/firnet_r50_fpn_1x_sccos.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile configs/firnet/firnet_r50_fpn_1x_sccos.py\n",
    "_base_ = [\n",
    "    '../_base_/datasets/dotav1.py',\n",
    "    '../_base_/schedules/schedule_1x.py',\n",
    "    '../_base_/default_runtime.py'\n",
    "]\n",
    "\n",
    "angle_version = 'le135'\n",
    "model = dict(\n",
    "    type='OrientedRCNN',\n",
    "    backbone=dict(\n",
    "        type='ResNet',\n",
    "        depth=50,\n",
    "        num_stages=4,\n",
    "        out_indices=(0, 1, 2, 3),\n",
    "        frozen_stages=1,\n",
    "        norm_cfg=dict(type='BN', requires_grad=True),\n",
    "        norm_eval=True,\n",
    "        style='pytorch',\n",
    "        init_cfg=dict(type='Pretrained', checkpoint='torchvision://resnet50')),\n",
    "    neck=dict(\n",
    "        type='NIRNet',  # Changed to FIRNet\n",
    "        in_channels=[256, 512, 1024, 2048],\n",
    "        out_channels=256,\n",
    "        num_outs=5),\n",
    "    rpn_head=dict(\n",
    "        type='OrientedRPNHead',\n",
    "        in_channels=256,\n",
    "        feat_channels=256,\n",
    "        version=angle_version,\n",
    "        anchor_generator=dict(\n",
    "            type='AnchorGenerator',\n",
    "            scales=[8],\n",
    "            ratios=[0.5, 1.0, 2.0],\n",
    "            strides=[4, 8, 16, 32, 64]),\n",
    "        bbox_coder=dict(\n",
    "            type='MidpointOffsetCoder',\n",
    "            angle_range=angle_version,\n",
    "            target_means=[0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "            target_stds=[1.0, 1.0, 1.0, 1.0, 0.5, 0.5]),\n",
    "        loss_cls=dict(\n",
    "            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),\n",
    "        loss_bbox=dict(\n",
    "            type='SmoothL1Loss', beta=0.1111111111111111, loss_weight=1.0)),\n",
    "    roi_head=dict(\n",
    "        type='OrientedStandardRoIHead',\n",
    "        bbox_roi_extractor=dict(\n",
    "            type='RotatedSingleRoIExtractor',\n",
    "            roi_layer=dict(\n",
    "                type='RoIAlignRotated',\n",
    "                out_size=7,\n",
    "                sample_num=2,\n",
    "                clockwise=True),\n",
    "            out_channels=256,\n",
    "            featmap_strides=[4, 8, 16, 32]),\n",
    "        bbox_head=dict(\n",
    "            type='RotatedShared2FCBBoxHead',\n",
    "            in_channels=256,\n",
    "            fc_out_channels=1024,\n",
    "            roi_feat_size=7,\n",
    "            num_classes=20,\n",
    "            bbox_coder=dict(\n",
    "                type='DeltaXYWHAOBBoxCoder',\n",
    "                angle_range=angle_version,\n",
    "                norm_factor=None,\n",
    "                edge_swap=True,\n",
    "                proj_xy=True,\n",
    "                target_means=(.0, .0, .0, .0, .0),\n",
    "                target_stds=(0.1, 0.1, 0.2, 0.2, 0.1)),\n",
    "            reg_class_agnostic=True,\n",
    "            loss_cls=dict(\n",
    "                type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0),\n",
    "            loss_bbox=dict(type='SmoothL1Loss', beta=1.0, loss_weight=1.0))),\n",
    "    train_cfg=dict(\n",
    "        rpn=dict(\n",
    "            assigner=dict(\n",
    "                type='MaxIoUAssigner',\n",
    "                pos_iou_thr=0.7,\n",
    "                neg_iou_thr=0.3,\n",
    "                min_pos_iou=0.3,\n",
    "                match_low_quality=True,\n",
    "                ignore_iof_thr=-1),\n",
    "            sampler=dict(\n",
    "                type='RandomSampler',\n",
    "                num=256,\n",
    "                pos_fraction=0.5,\n",
    "                neg_pos_ub=-1,\n",
    "                add_gt_as_proposals=False),\n",
    "            allowed_border=0,\n",
    "            pos_weight=-1,\n",
    "            debug=False),\n",
    "        rpn_proposal=dict(\n",
    "            nms_pre=2000,\n",
    "            max_per_img=2000,\n",
    "            nms=dict(type='nms', iou_threshold=0.8),\n",
    "            min_bbox_size=0),\n",
    "        rcnn=dict(\n",
    "            assigner=dict(\n",
    "                type='MaxIoUAssigner',\n",
    "                pos_iou_thr=0.5,\n",
    "                neg_iou_thr=0.5,\n",
    "                min_pos_iou=0.5,\n",
    "                match_low_quality=False,\n",
    "                iou_calculator=dict(type='RBboxOverlaps2D'),\n",
    "                ignore_iof_thr=-1),\n",
    "            sampler=dict(\n",
    "                type='RRandomSampler',\n",
    "                num=512,\n",
    "                pos_fraction=0.25,\n",
    "                neg_pos_ub=-1,\n",
    "                add_gt_as_proposals=True),\n",
    "            pos_weight=-1,\n",
    "            debug=False)),\n",
    "    test_cfg=dict(\n",
    "        rpn=dict(\n",
    "            nms_pre=2000,\n",
    "            max_per_img=2000,\n",
    "            nms=dict(type='nms', iou_threshold=0.8),\n",
    "            min_bbox_size=0),\n",
    "        rcnn=dict(\n",
    "            nms_pre=2000,\n",
    "            min_bbox_size=0,\n",
    "            score_thr=0.05,\n",
    "            nms=dict(iou_thr=0.1),\n",
    "            max_per_img=2000)))\n",
    "\n",
    "\n",
    "dataset_type = 'DOTADataset'\n",
    "data_root = '/kaggle/working/sccos_dota/'\n",
    "classes = ('ship',)  # Explicitly define classes\n",
    "img_norm_cfg = dict(\n",
    "    mean=[123.675, 116.28, 103.53],\n",
    "    std=[58.395, 57.12, 57.375],\n",
    "    to_rgb=True)\n",
    "train_pipeline = [\n",
    "    dict(type='LoadImageFromFile'),\n",
    "    dict(type='LoadAnnotations', with_bbox=True),\n",
    "    dict(type='RResize', img_scale=(1024, 1024)),\n",
    "    dict(\n",
    "        type='RRandomFlip',\n",
    "        flip_ratio=[0.25, 0.25, 0.25],\n",
    "        direction=['horizontal', 'vertical', 'diagonal'],\n",
    "        version='le135'),\n",
    "    dict(type='Normalize', **img_norm_cfg),\n",
    "    dict(type='Pad', size_divisor=32),\n",
    "    dict(type='DefaultFormatBundle'),\n",
    "    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n",
    "]\n",
    "test_pipeline = [\n",
    "    dict(type='LoadImageFromFile'),\n",
    "    dict(\n",
    "        type='MultiScaleFlipAug',\n",
    "        img_scale=(1024, 1024),\n",
    "        flip=False,\n",
    "        transforms=[\n",
    "            dict(type='RResize'),\n",
    "            dict(type='Normalize', **img_norm_cfg),\n",
    "            dict(type='Pad', size_divisor=32),\n",
    "            dict(type='DefaultFormatBundle'),\n",
    "            dict(type='Collect', keys=['img'])\n",
    "        ])\n",
    "]\n",
    "data = dict(\n",
    "    samples_per_gpu=2,\n",
    "    workers_per_gpu=2,\n",
    "    train=dict(\n",
    "        type=dataset_type,\n",
    "        ann_file=data_root + 'train/labels/',\n",
    "        img_prefix=data_root + 'train/images/',\n",
    "        pipeline=train_pipeline,\n",
    "        version='le135',\n",
    "        classes=('ship',)),\n",
    "    val=dict(\n",
    "        type=dataset_type,\n",
    "        ann_file=data_root + 'val/labels/',\n",
    "        img_prefix=data_root + 'val/images/',\n",
    "        pipeline=test_pipeline,\n",
    "        version='le135',\n",
    "        classes=('ship',)),\n",
    "    test=dict(\n",
    "        type=dataset_type,\n",
    "        ann_file=data_root + 'test/labels/',\n",
    "        img_prefix=data_root + 'test/images/',\n",
    "        pipeline=test_pipeline,\n",
    "        version='le135',\n",
    "        classes=('ship',)))\n",
    "evaluation = dict(interval=1, metric='mAP')\n",
    "runner = dict(type='EpochBasedRunner', max_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "114c341b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T07:03:22.076349Z",
     "iopub.status.busy": "2025-08-11T07:03:22.076010Z",
     "iopub.status.idle": "2025-08-11T07:20:28.382029Z",
     "shell.execute_reply": "2025-08-11T07:20:28.380956Z"
    },
    "papermill": {
     "duration": 1026.346567,
     "end_time": "2025-08-11T07:20:28.383502",
     "exception": false,
     "start_time": "2025-08-11T07:03:22.036935",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/mmrotate\n",
      "/usr/local/lib/python3.10/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 2.0.8 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\r\n",
      "  check_for_updates()\r\n",
      "/kaggle/working/mmrotate/mmrotate/utils/setup_env.py:38: UserWarning: Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.\r\n",
      "  warnings.warn(\r\n",
      "/kaggle/working/mmrotate/mmrotate/utils/setup_env.py:48: UserWarning: Setting MKL_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.\r\n",
      "  warnings.warn(\r\n",
      "2025-08-11 07:03:30,692 - mmrotate - INFO - Environment info:\r\n",
      "------------------------------------------------------------\r\n",
      "sys.platform: linux\r\n",
      "Python: 3.10.12 (main, Nov  6 2024, 20:22:13) [GCC 11.4.0]\r\n",
      "CUDA available: True\r\n",
      "GPU 0: Tesla P100-PCIE-16GB\r\n",
      "CUDA_HOME: /usr/local/cuda\r\n",
      "NVCC: Cuda compilation tools, release 12.2, V12.2.140\r\n",
      "GCC: x86_64-linux-gnu-gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\r\n",
      "PyTorch: 1.13.1+cu116\r\n",
      "PyTorch compiling details: PyTorch built with:\r\n",
      "  - GCC 9.3\r\n",
      "  - C++ Version: 201402\r\n",
      "  - Intel(R) oneAPI Math Kernel Library Version 2025.0.1-Product Build 20241031 for Intel(R) 64 architecture applications\r\n",
      "  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)\r\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\r\n",
      "  - LAPACK is enabled (usually provided by MKL)\r\n",
      "  - NNPACK is enabled\r\n",
      "  - CPU capability usage: AVX2\r\n",
      "  - CUDA Runtime 11.6\r\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\r\n",
      "  - CuDNN 8.3.2  (built against CUDA 11.5)\r\n",
      "  - Magma 2.6.1\r\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.6, CUDNN_VERSION=8.3.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.13.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \r\n",
      "\r\n",
      "TorchVision: 0.14.1+cu116\r\n",
      "OpenCV: 4.10.0\r\n",
      "MMCV: 1.7.1\r\n",
      "MMCV Compiler: GCC 9.3\r\n",
      "MMCV CUDA Compiler: 11.6\r\n",
      "MMRotate: 0.3.4+7250f04\r\n",
      "------------------------------------------------------------\r\n",
      "\r\n",
      "2025-08-11 07:03:30,912 - mmrotate - INFO - Distributed training: False\r\n",
      "2025-08-11 07:03:31,272 - mmrotate - INFO - Config:\r\n",
      "dataset_type = 'DOTADataset'\r\n",
      "data_root = '/kaggle/working/sccos_dota/'\r\n",
      "img_norm_cfg = dict(\r\n",
      "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\r\n",
      "train_pipeline = [\r\n",
      "    dict(type='LoadImageFromFile'),\r\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\r\n",
      "    dict(type='RResize', img_scale=(1024, 1024)),\r\n",
      "    dict(\r\n",
      "        type='RRandomFlip',\r\n",
      "        flip_ratio=[0.25, 0.25, 0.25],\r\n",
      "        direction=['horizontal', 'vertical', 'diagonal'],\r\n",
      "        version='le135'),\r\n",
      "    dict(\r\n",
      "        type='Normalize',\r\n",
      "        mean=[123.675, 116.28, 103.53],\r\n",
      "        std=[58.395, 57.12, 57.375],\r\n",
      "        to_rgb=True),\r\n",
      "    dict(type='Pad', size_divisor=32),\r\n",
      "    dict(type='DefaultFormatBundle'),\r\n",
      "    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\r\n",
      "]\r\n",
      "test_pipeline = [\r\n",
      "    dict(type='LoadImageFromFile'),\r\n",
      "    dict(\r\n",
      "        type='MultiScaleFlipAug',\r\n",
      "        img_scale=(1024, 1024),\r\n",
      "        flip=False,\r\n",
      "        transforms=[\r\n",
      "            dict(type='RResize'),\r\n",
      "            dict(\r\n",
      "                type='Normalize',\r\n",
      "                mean=[123.675, 116.28, 103.53],\r\n",
      "                std=[58.395, 57.12, 57.375],\r\n",
      "                to_rgb=True),\r\n",
      "            dict(type='Pad', size_divisor=32),\r\n",
      "            dict(type='DefaultFormatBundle'),\r\n",
      "            dict(type='Collect', keys=['img'])\r\n",
      "        ])\r\n",
      "]\r\n",
      "data = dict(\r\n",
      "    samples_per_gpu=2,\r\n",
      "    workers_per_gpu=2,\r\n",
      "    train=dict(\r\n",
      "        type='DOTADataset',\r\n",
      "        ann_file='/kaggle/working/sccos_dota/train/labels/',\r\n",
      "        img_prefix='/kaggle/working/sccos_dota/train/images/',\r\n",
      "        pipeline=[\r\n",
      "            dict(type='LoadImageFromFile'),\r\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\r\n",
      "            dict(type='RResize', img_scale=(1024, 1024)),\r\n",
      "            dict(\r\n",
      "                type='RRandomFlip',\r\n",
      "                flip_ratio=[0.25, 0.25, 0.25],\r\n",
      "                direction=['horizontal', 'vertical', 'diagonal'],\r\n",
      "                version='le135'),\r\n",
      "            dict(\r\n",
      "                type='Normalize',\r\n",
      "                mean=[123.675, 116.28, 103.53],\r\n",
      "                std=[58.395, 57.12, 57.375],\r\n",
      "                to_rgb=True),\r\n",
      "            dict(type='Pad', size_divisor=32),\r\n",
      "            dict(type='DefaultFormatBundle'),\r\n",
      "            dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\r\n",
      "        ],\r\n",
      "        version='le135',\r\n",
      "        classes=('ship', )),\r\n",
      "    val=dict(\r\n",
      "        type='DOTADataset',\r\n",
      "        ann_file='/kaggle/working/sccos_dota/val/labels/',\r\n",
      "        img_prefix='/kaggle/working/sccos_dota/val/images/',\r\n",
      "        pipeline=[\r\n",
      "            dict(type='LoadImageFromFile'),\r\n",
      "            dict(\r\n",
      "                type='MultiScaleFlipAug',\r\n",
      "                img_scale=(1024, 1024),\r\n",
      "                flip=False,\r\n",
      "                transforms=[\r\n",
      "                    dict(type='RResize'),\r\n",
      "                    dict(\r\n",
      "                        type='Normalize',\r\n",
      "                        mean=[123.675, 116.28, 103.53],\r\n",
      "                        std=[58.395, 57.12, 57.375],\r\n",
      "                        to_rgb=True),\r\n",
      "                    dict(type='Pad', size_divisor=32),\r\n",
      "                    dict(type='DefaultFormatBundle'),\r\n",
      "                    dict(type='Collect', keys=['img'])\r\n",
      "                ])\r\n",
      "        ],\r\n",
      "        version='le135',\r\n",
      "        classes=('ship', )),\r\n",
      "    test=dict(\r\n",
      "        type='DOTADataset',\r\n",
      "        ann_file='/kaggle/working/sccos_dota/test/labels/',\r\n",
      "        img_prefix='/kaggle/working/sccos_dota/test/images/',\r\n",
      "        pipeline=[\r\n",
      "            dict(type='LoadImageFromFile'),\r\n",
      "            dict(\r\n",
      "                type='MultiScaleFlipAug',\r\n",
      "                img_scale=(1024, 1024),\r\n",
      "                flip=False,\r\n",
      "                transforms=[\r\n",
      "                    dict(type='RResize'),\r\n",
      "                    dict(\r\n",
      "                        type='Normalize',\r\n",
      "                        mean=[123.675, 116.28, 103.53],\r\n",
      "                        std=[58.395, 57.12, 57.375],\r\n",
      "                        to_rgb=True),\r\n",
      "                    dict(type='Pad', size_divisor=32),\r\n",
      "                    dict(type='DefaultFormatBundle'),\r\n",
      "                    dict(type='Collect', keys=['img'])\r\n",
      "                ])\r\n",
      "        ],\r\n",
      "        version='le135',\r\n",
      "        classes=('ship', )))\r\n",
      "evaluation = dict(interval=1, metric='mAP')\r\n",
      "optimizer = dict(type='SGD', lr=0.0025, momentum=0.9, weight_decay=0.0001)\r\n",
      "optimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))\r\n",
      "lr_config = dict(\r\n",
      "    policy='step',\r\n",
      "    warmup='linear',\r\n",
      "    warmup_iters=500,\r\n",
      "    warmup_ratio=0.3333333333333333,\r\n",
      "    step=[8, 11])\r\n",
      "runner = dict(type='EpochBasedRunner', max_epochs=10)\r\n",
      "checkpoint_config = dict(interval=1)\r\n",
      "log_config = dict(interval=50, hooks=[dict(type='TextLoggerHook')])\r\n",
      "dist_params = dict(backend='nccl')\r\n",
      "log_level = 'INFO'\r\n",
      "load_from = None\r\n",
      "resume_from = None\r\n",
      "workflow = [('train', 1)]\r\n",
      "opencv_num_threads = 0\r\n",
      "mp_start_method = 'fork'\r\n",
      "angle_version = 'le135'\r\n",
      "model = dict(\r\n",
      "    type='OrientedRCNN',\r\n",
      "    backbone=dict(\r\n",
      "        type='ResNet',\r\n",
      "        depth=50,\r\n",
      "        num_stages=4,\r\n",
      "        out_indices=(0, 1, 2, 3),\r\n",
      "        frozen_stages=1,\r\n",
      "        norm_cfg=dict(type='BN', requires_grad=True),\r\n",
      "        norm_eval=True,\r\n",
      "        style='pytorch',\r\n",
      "        init_cfg=dict(type='Pretrained', checkpoint='torchvision://resnet50')),\r\n",
      "    neck=dict(\r\n",
      "        type='NIRNet',\r\n",
      "        in_channels=[256, 512, 1024, 2048],\r\n",
      "        out_channels=256,\r\n",
      "        num_outs=5),\r\n",
      "    rpn_head=dict(\r\n",
      "        type='OrientedRPNHead',\r\n",
      "        in_channels=256,\r\n",
      "        feat_channels=256,\r\n",
      "        version='le135',\r\n",
      "        anchor_generator=dict(\r\n",
      "            type='AnchorGenerator',\r\n",
      "            scales=[8],\r\n",
      "            ratios=[0.5, 1.0, 2.0],\r\n",
      "            strides=[4, 8, 16, 32, 64]),\r\n",
      "        bbox_coder=dict(\r\n",
      "            type='MidpointOffsetCoder',\r\n",
      "            angle_range='le135',\r\n",
      "            target_means=[0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\r\n",
      "            target_stds=[1.0, 1.0, 1.0, 1.0, 0.5, 0.5]),\r\n",
      "        loss_cls=dict(\r\n",
      "            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),\r\n",
      "        loss_bbox=dict(\r\n",
      "            type='SmoothL1Loss', beta=0.1111111111111111, loss_weight=1.0)),\r\n",
      "    roi_head=dict(\r\n",
      "        type='OrientedStandardRoIHead',\r\n",
      "        bbox_roi_extractor=dict(\r\n",
      "            type='RotatedSingleRoIExtractor',\r\n",
      "            roi_layer=dict(\r\n",
      "                type='RoIAlignRotated',\r\n",
      "                out_size=7,\r\n",
      "                sample_num=2,\r\n",
      "                clockwise=True),\r\n",
      "            out_channels=256,\r\n",
      "            featmap_strides=[4, 8, 16, 32]),\r\n",
      "        bbox_head=dict(\r\n",
      "            type='RotatedShared2FCBBoxHead',\r\n",
      "            in_channels=256,\r\n",
      "            fc_out_channels=1024,\r\n",
      "            roi_feat_size=7,\r\n",
      "            num_classes=20,\r\n",
      "            bbox_coder=dict(\r\n",
      "                type='DeltaXYWHAOBBoxCoder',\r\n",
      "                angle_range='le135',\r\n",
      "                norm_factor=None,\r\n",
      "                edge_swap=True,\r\n",
      "                proj_xy=True,\r\n",
      "                target_means=(0.0, 0.0, 0.0, 0.0, 0.0),\r\n",
      "                target_stds=(0.1, 0.1, 0.2, 0.2, 0.1)),\r\n",
      "            reg_class_agnostic=True,\r\n",
      "            loss_cls=dict(\r\n",
      "                type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0),\r\n",
      "            loss_bbox=dict(type='SmoothL1Loss', beta=1.0, loss_weight=1.0))),\r\n",
      "    train_cfg=dict(\r\n",
      "        rpn=dict(\r\n",
      "            assigner=dict(\r\n",
      "                type='MaxIoUAssigner',\r\n",
      "                pos_iou_thr=0.7,\r\n",
      "                neg_iou_thr=0.3,\r\n",
      "                min_pos_iou=0.3,\r\n",
      "                match_low_quality=True,\r\n",
      "                ignore_iof_thr=-1),\r\n",
      "            sampler=dict(\r\n",
      "                type='RandomSampler',\r\n",
      "                num=256,\r\n",
      "                pos_fraction=0.5,\r\n",
      "                neg_pos_ub=-1,\r\n",
      "                add_gt_as_proposals=False),\r\n",
      "            allowed_border=0,\r\n",
      "            pos_weight=-1,\r\n",
      "            debug=False),\r\n",
      "        rpn_proposal=dict(\r\n",
      "            nms_pre=2000,\r\n",
      "            max_per_img=2000,\r\n",
      "            nms=dict(type='nms', iou_threshold=0.8),\r\n",
      "            min_bbox_size=0),\r\n",
      "        rcnn=dict(\r\n",
      "            assigner=dict(\r\n",
      "                type='MaxIoUAssigner',\r\n",
      "                pos_iou_thr=0.5,\r\n",
      "                neg_iou_thr=0.5,\r\n",
      "                min_pos_iou=0.5,\r\n",
      "                match_low_quality=False,\r\n",
      "                iou_calculator=dict(type='RBboxOverlaps2D'),\r\n",
      "                ignore_iof_thr=-1),\r\n",
      "            sampler=dict(\r\n",
      "                type='RRandomSampler',\r\n",
      "                num=512,\r\n",
      "                pos_fraction=0.25,\r\n",
      "                neg_pos_ub=-1,\r\n",
      "                add_gt_as_proposals=True),\r\n",
      "            pos_weight=-1,\r\n",
      "            debug=False)),\r\n",
      "    test_cfg=dict(\r\n",
      "        rpn=dict(\r\n",
      "            nms_pre=2000,\r\n",
      "            max_per_img=2000,\r\n",
      "            nms=dict(type='nms', iou_threshold=0.8),\r\n",
      "            min_bbox_size=0),\r\n",
      "        rcnn=dict(\r\n",
      "            nms_pre=2000,\r\n",
      "            min_bbox_size=0,\r\n",
      "            score_thr=0.05,\r\n",
      "            nms=dict(iou_thr=0.1),\r\n",
      "            max_per_img=2000)))\r\n",
      "classes = ('ship', )\r\n",
      "work_dir = '/kaggle/working/runs/firnet_train'\r\n",
      "auto_resume = False\r\n",
      "gpu_ids = range(0, 1)\r\n",
      "\r\n",
      "2025-08-11 07:03:31,274 - mmrotate - INFO - Set random seed to 1732774208, deterministic: False\r\n",
      "/usr/local/lib/python3.10/dist-packages/mmdet/models/dense_heads/anchor_head.py:116: UserWarning: DeprecationWarning: `num_anchors` is deprecated, for consistency or also use `num_base_priors` instead\r\n",
      "  warnings.warn('DeprecationWarning: `num_anchors` is deprecated, '\r\n",
      "2025-08-11 07:03:31,741 - mmcv - INFO - initialize ResNet with init_cfg {'type': 'Pretrained', 'checkpoint': 'torchvision://resnet50'}\r\n",
      "2025-08-11 07:03:31,741 - mmcv - INFO - load model from: torchvision://resnet50\r\n",
      "2025-08-11 07:03:31,742 - mmcv - INFO - load checkpoint from torchvision path: torchvision://resnet50\r\n",
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\r\n",
      "100%|██████████████████████████████████████| 97.8M/97.8M [00:01<00:00, 69.4MB/s]\r\n",
      "2025-08-11 07:03:33,377 - mmcv - WARNING - The model and loaded state dict do not match exactly\r\n",
      "\r\n",
      "unexpected key in source state_dict: fc.weight, fc.bias\r\n",
      "\r\n",
      "2025-08-11 07:03:33,400 - mmcv - INFO - initialize NIRNet with init_cfg {'type': 'Xavier', 'layer': 'Conv2d', 'distribution': 'uniform'}\r\n",
      "2025-08-11 07:03:33,440 - mmcv - INFO - initialize OrientedRPNHead with init_cfg {'type': 'Normal', 'layer': 'Conv2d', 'std': 0.01}\r\n",
      "2025-08-11 07:03:33,445 - mmcv - INFO - initialize RotatedShared2FCBBoxHead with init_cfg [{'type': 'Normal', 'std': 0.01, 'override': {'name': 'fc_cls'}}, {'type': 'Normal', 'std': 0.001, 'override': {'name': 'fc_reg'}}, {'type': 'Xavier', 'layer': 'Linear', 'override': [{'name': 'shared_fcs'}, {'name': 'cls_fcs'}, {'name': 'reg_fcs'}]}]\r\n",
      "2025-08-11 07:03:33,632 - mmcv - INFO - \r\n",
      "backbone.conv1.weight - torch.Size([64, 3, 7, 7]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,632 - mmcv - INFO - \r\n",
      "backbone.bn1.weight - torch.Size([64]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,632 - mmcv - INFO - \r\n",
      "backbone.bn1.bias - torch.Size([64]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,632 - mmcv - INFO - \r\n",
      "backbone.layer1.0.conv1.weight - torch.Size([64, 64, 1, 1]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,632 - mmcv - INFO - \r\n",
      "backbone.layer1.0.bn1.weight - torch.Size([64]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,633 - mmcv - INFO - \r\n",
      "backbone.layer1.0.bn1.bias - torch.Size([64]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,633 - mmcv - INFO - \r\n",
      "backbone.layer1.0.conv2.weight - torch.Size([64, 64, 3, 3]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,633 - mmcv - INFO - \r\n",
      "backbone.layer1.0.bn2.weight - torch.Size([64]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,633 - mmcv - INFO - \r\n",
      "backbone.layer1.0.bn2.bias - torch.Size([64]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,633 - mmcv - INFO - \r\n",
      "backbone.layer1.0.conv3.weight - torch.Size([256, 64, 1, 1]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,633 - mmcv - INFO - \r\n",
      "backbone.layer1.0.bn3.weight - torch.Size([256]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,633 - mmcv - INFO - \r\n",
      "backbone.layer1.0.bn3.bias - torch.Size([256]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,633 - mmcv - INFO - \r\n",
      "backbone.layer1.0.downsample.0.weight - torch.Size([256, 64, 1, 1]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,633 - mmcv - INFO - \r\n",
      "backbone.layer1.0.downsample.1.weight - torch.Size([256]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,633 - mmcv - INFO - \r\n",
      "backbone.layer1.0.downsample.1.bias - torch.Size([256]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,633 - mmcv - INFO - \r\n",
      "backbone.layer1.1.conv1.weight - torch.Size([64, 256, 1, 1]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,634 - mmcv - INFO - \r\n",
      "backbone.layer1.1.bn1.weight - torch.Size([64]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,634 - mmcv - INFO - \r\n",
      "backbone.layer1.1.bn1.bias - torch.Size([64]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,634 - mmcv - INFO - \r\n",
      "backbone.layer1.1.conv2.weight - torch.Size([64, 64, 3, 3]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,634 - mmcv - INFO - \r\n",
      "backbone.layer1.1.bn2.weight - torch.Size([64]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,634 - mmcv - INFO - \r\n",
      "backbone.layer1.1.bn2.bias - torch.Size([64]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,634 - mmcv - INFO - \r\n",
      "backbone.layer1.1.conv3.weight - torch.Size([256, 64, 1, 1]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,634 - mmcv - INFO - \r\n",
      "backbone.layer1.1.bn3.weight - torch.Size([256]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,634 - mmcv - INFO - \r\n",
      "backbone.layer1.1.bn3.bias - torch.Size([256]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,634 - mmcv - INFO - \r\n",
      "backbone.layer1.2.conv1.weight - torch.Size([64, 256, 1, 1]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,634 - mmcv - INFO - \r\n",
      "backbone.layer1.2.bn1.weight - torch.Size([64]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,635 - mmcv - INFO - \r\n",
      "backbone.layer1.2.bn1.bias - torch.Size([64]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,635 - mmcv - INFO - \r\n",
      "backbone.layer1.2.conv2.weight - torch.Size([64, 64, 3, 3]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,635 - mmcv - INFO - \r\n",
      "backbone.layer1.2.bn2.weight - torch.Size([64]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,635 - mmcv - INFO - \r\n",
      "backbone.layer1.2.bn2.bias - torch.Size([64]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,635 - mmcv - INFO - \r\n",
      "backbone.layer1.2.conv3.weight - torch.Size([256, 64, 1, 1]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,635 - mmcv - INFO - \r\n",
      "backbone.layer1.2.bn3.weight - torch.Size([256]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,635 - mmcv - INFO - \r\n",
      "backbone.layer1.2.bn3.bias - torch.Size([256]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,635 - mmcv - INFO - \r\n",
      "backbone.layer2.0.conv1.weight - torch.Size([128, 256, 1, 1]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,635 - mmcv - INFO - \r\n",
      "backbone.layer2.0.bn1.weight - torch.Size([128]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,635 - mmcv - INFO - \r\n",
      "backbone.layer2.0.bn1.bias - torch.Size([128]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,636 - mmcv - INFO - \r\n",
      "backbone.layer2.0.conv2.weight - torch.Size([128, 128, 3, 3]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,636 - mmcv - INFO - \r\n",
      "backbone.layer2.0.bn2.weight - torch.Size([128]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,636 - mmcv - INFO - \r\n",
      "backbone.layer2.0.bn2.bias - torch.Size([128]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,636 - mmcv - INFO - \r\n",
      "backbone.layer2.0.conv3.weight - torch.Size([512, 128, 1, 1]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,636 - mmcv - INFO - \r\n",
      "backbone.layer2.0.bn3.weight - torch.Size([512]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,636 - mmcv - INFO - \r\n",
      "backbone.layer2.0.bn3.bias - torch.Size([512]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,636 - mmcv - INFO - \r\n",
      "backbone.layer2.0.downsample.0.weight - torch.Size([512, 256, 1, 1]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,636 - mmcv - INFO - \r\n",
      "backbone.layer2.0.downsample.1.weight - torch.Size([512]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,636 - mmcv - INFO - \r\n",
      "backbone.layer2.0.downsample.1.bias - torch.Size([512]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,636 - mmcv - INFO - \r\n",
      "backbone.layer2.1.conv1.weight - torch.Size([128, 512, 1, 1]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,636 - mmcv - INFO - \r\n",
      "backbone.layer2.1.bn1.weight - torch.Size([128]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,637 - mmcv - INFO - \r\n",
      "backbone.layer2.1.bn1.bias - torch.Size([128]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,637 - mmcv - INFO - \r\n",
      "backbone.layer2.1.conv2.weight - torch.Size([128, 128, 3, 3]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,637 - mmcv - INFO - \r\n",
      "backbone.layer2.1.bn2.weight - torch.Size([128]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,637 - mmcv - INFO - \r\n",
      "backbone.layer2.1.bn2.bias - torch.Size([128]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,637 - mmcv - INFO - \r\n",
      "backbone.layer2.1.conv3.weight - torch.Size([512, 128, 1, 1]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,637 - mmcv - INFO - \r\n",
      "backbone.layer2.1.bn3.weight - torch.Size([512]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,637 - mmcv - INFO - \r\n",
      "backbone.layer2.1.bn3.bias - torch.Size([512]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,637 - mmcv - INFO - \r\n",
      "backbone.layer2.2.conv1.weight - torch.Size([128, 512, 1, 1]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,637 - mmcv - INFO - \r\n",
      "backbone.layer2.2.bn1.weight - torch.Size([128]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,637 - mmcv - INFO - \r\n",
      "backbone.layer2.2.bn1.bias - torch.Size([128]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,638 - mmcv - INFO - \r\n",
      "backbone.layer2.2.conv2.weight - torch.Size([128, 128, 3, 3]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,638 - mmcv - INFO - \r\n",
      "backbone.layer2.2.bn2.weight - torch.Size([128]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,638 - mmcv - INFO - \r\n",
      "backbone.layer2.2.bn2.bias - torch.Size([128]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,638 - mmcv - INFO - \r\n",
      "backbone.layer2.2.conv3.weight - torch.Size([512, 128, 1, 1]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,638 - mmcv - INFO - \r\n",
      "backbone.layer2.2.bn3.weight - torch.Size([512]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,638 - mmcv - INFO - \r\n",
      "backbone.layer2.2.bn3.bias - torch.Size([512]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,638 - mmcv - INFO - \r\n",
      "backbone.layer2.3.conv1.weight - torch.Size([128, 512, 1, 1]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,638 - mmcv - INFO - \r\n",
      "backbone.layer2.3.bn1.weight - torch.Size([128]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,638 - mmcv - INFO - \r\n",
      "backbone.layer2.3.bn1.bias - torch.Size([128]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,638 - mmcv - INFO - \r\n",
      "backbone.layer2.3.conv2.weight - torch.Size([128, 128, 3, 3]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,638 - mmcv - INFO - \r\n",
      "backbone.layer2.3.bn2.weight - torch.Size([128]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,639 - mmcv - INFO - \r\n",
      "backbone.layer2.3.bn2.bias - torch.Size([128]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,639 - mmcv - INFO - \r\n",
      "backbone.layer2.3.conv3.weight - torch.Size([512, 128, 1, 1]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,639 - mmcv - INFO - \r\n",
      "backbone.layer2.3.bn3.weight - torch.Size([512]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,639 - mmcv - INFO - \r\n",
      "backbone.layer2.3.bn3.bias - torch.Size([512]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,639 - mmcv - INFO - \r\n",
      "backbone.layer3.0.conv1.weight - torch.Size([256, 512, 1, 1]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,639 - mmcv - INFO - \r\n",
      "backbone.layer3.0.bn1.weight - torch.Size([256]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,639 - mmcv - INFO - \r\n",
      "backbone.layer3.0.bn1.bias - torch.Size([256]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,639 - mmcv - INFO - \r\n",
      "backbone.layer3.0.conv2.weight - torch.Size([256, 256, 3, 3]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,639 - mmcv - INFO - \r\n",
      "backbone.layer3.0.bn2.weight - torch.Size([256]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,639 - mmcv - INFO - \r\n",
      "backbone.layer3.0.bn2.bias - torch.Size([256]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,639 - mmcv - INFO - \r\n",
      "backbone.layer3.0.conv3.weight - torch.Size([1024, 256, 1, 1]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,640 - mmcv - INFO - \r\n",
      "backbone.layer3.0.bn3.weight - torch.Size([1024]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,640 - mmcv - INFO - \r\n",
      "backbone.layer3.0.bn3.bias - torch.Size([1024]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,640 - mmcv - INFO - \r\n",
      "backbone.layer3.0.downsample.0.weight - torch.Size([1024, 512, 1, 1]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,640 - mmcv - INFO - \r\n",
      "backbone.layer3.0.downsample.1.weight - torch.Size([1024]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,640 - mmcv - INFO - \r\n",
      "backbone.layer3.0.downsample.1.bias - torch.Size([1024]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,640 - mmcv - INFO - \r\n",
      "backbone.layer3.1.conv1.weight - torch.Size([256, 1024, 1, 1]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,640 - mmcv - INFO - \r\n",
      "backbone.layer3.1.bn1.weight - torch.Size([256]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,640 - mmcv - INFO - \r\n",
      "backbone.layer3.1.bn1.bias - torch.Size([256]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,640 - mmcv - INFO - \r\n",
      "backbone.layer3.1.conv2.weight - torch.Size([256, 256, 3, 3]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,640 - mmcv - INFO - \r\n",
      "backbone.layer3.1.bn2.weight - torch.Size([256]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,640 - mmcv - INFO - \r\n",
      "backbone.layer3.1.bn2.bias - torch.Size([256]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,641 - mmcv - INFO - \r\n",
      "backbone.layer3.1.conv3.weight - torch.Size([1024, 256, 1, 1]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,641 - mmcv - INFO - \r\n",
      "backbone.layer3.1.bn3.weight - torch.Size([1024]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,641 - mmcv - INFO - \r\n",
      "backbone.layer3.1.bn3.bias - torch.Size([1024]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,641 - mmcv - INFO - \r\n",
      "backbone.layer3.2.conv1.weight - torch.Size([256, 1024, 1, 1]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,641 - mmcv - INFO - \r\n",
      "backbone.layer3.2.bn1.weight - torch.Size([256]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,641 - mmcv - INFO - \r\n",
      "backbone.layer3.2.bn1.bias - torch.Size([256]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,641 - mmcv - INFO - \r\n",
      "backbone.layer3.2.conv2.weight - torch.Size([256, 256, 3, 3]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,641 - mmcv - INFO - \r\n",
      "backbone.layer3.2.bn2.weight - torch.Size([256]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,641 - mmcv - INFO - \r\n",
      "backbone.layer3.2.bn2.bias - torch.Size([256]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,641 - mmcv - INFO - \r\n",
      "backbone.layer3.2.conv3.weight - torch.Size([1024, 256, 1, 1]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,642 - mmcv - INFO - \r\n",
      "backbone.layer3.2.bn3.weight - torch.Size([1024]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,642 - mmcv - INFO - \r\n",
      "backbone.layer3.2.bn3.bias - torch.Size([1024]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,642 - mmcv - INFO - \r\n",
      "backbone.layer3.3.conv1.weight - torch.Size([256, 1024, 1, 1]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,642 - mmcv - INFO - \r\n",
      "backbone.layer3.3.bn1.weight - torch.Size([256]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,642 - mmcv - INFO - \r\n",
      "backbone.layer3.3.bn1.bias - torch.Size([256]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,642 - mmcv - INFO - \r\n",
      "backbone.layer3.3.conv2.weight - torch.Size([256, 256, 3, 3]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,642 - mmcv - INFO - \r\n",
      "backbone.layer3.3.bn2.weight - torch.Size([256]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,642 - mmcv - INFO - \r\n",
      "backbone.layer3.3.bn2.bias - torch.Size([256]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,642 - mmcv - INFO - \r\n",
      "backbone.layer3.3.conv3.weight - torch.Size([1024, 256, 1, 1]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,642 - mmcv - INFO - \r\n",
      "backbone.layer3.3.bn3.weight - torch.Size([1024]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,642 - mmcv - INFO - \r\n",
      "backbone.layer3.3.bn3.bias - torch.Size([1024]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,643 - mmcv - INFO - \r\n",
      "backbone.layer3.4.conv1.weight - torch.Size([256, 1024, 1, 1]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,643 - mmcv - INFO - \r\n",
      "backbone.layer3.4.bn1.weight - torch.Size([256]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,643 - mmcv - INFO - \r\n",
      "backbone.layer3.4.bn1.bias - torch.Size([256]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,643 - mmcv - INFO - \r\n",
      "backbone.layer3.4.conv2.weight - torch.Size([256, 256, 3, 3]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,643 - mmcv - INFO - \r\n",
      "backbone.layer3.4.bn2.weight - torch.Size([256]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,643 - mmcv - INFO - \r\n",
      "backbone.layer3.4.bn2.bias - torch.Size([256]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,643 - mmcv - INFO - \r\n",
      "backbone.layer3.4.conv3.weight - torch.Size([1024, 256, 1, 1]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,643 - mmcv - INFO - \r\n",
      "backbone.layer3.4.bn3.weight - torch.Size([1024]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,643 - mmcv - INFO - \r\n",
      "backbone.layer3.4.bn3.bias - torch.Size([1024]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,643 - mmcv - INFO - \r\n",
      "backbone.layer3.5.conv1.weight - torch.Size([256, 1024, 1, 1]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,643 - mmcv - INFO - \r\n",
      "backbone.layer3.5.bn1.weight - torch.Size([256]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,644 - mmcv - INFO - \r\n",
      "backbone.layer3.5.bn1.bias - torch.Size([256]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,644 - mmcv - INFO - \r\n",
      "backbone.layer3.5.conv2.weight - torch.Size([256, 256, 3, 3]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,644 - mmcv - INFO - \r\n",
      "backbone.layer3.5.bn2.weight - torch.Size([256]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,644 - mmcv - INFO - \r\n",
      "backbone.layer3.5.bn2.bias - torch.Size([256]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,644 - mmcv - INFO - \r\n",
      "backbone.layer3.5.conv3.weight - torch.Size([1024, 256, 1, 1]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,644 - mmcv - INFO - \r\n",
      "backbone.layer3.5.bn3.weight - torch.Size([1024]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,644 - mmcv - INFO - \r\n",
      "backbone.layer3.5.bn3.bias - torch.Size([1024]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,644 - mmcv - INFO - \r\n",
      "backbone.layer4.0.conv1.weight - torch.Size([512, 1024, 1, 1]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,644 - mmcv - INFO - \r\n",
      "backbone.layer4.0.bn1.weight - torch.Size([512]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,644 - mmcv - INFO - \r\n",
      "backbone.layer4.0.bn1.bias - torch.Size([512]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,645 - mmcv - INFO - \r\n",
      "backbone.layer4.0.conv2.weight - torch.Size([512, 512, 3, 3]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,645 - mmcv - INFO - \r\n",
      "backbone.layer4.0.bn2.weight - torch.Size([512]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,645 - mmcv - INFO - \r\n",
      "backbone.layer4.0.bn2.bias - torch.Size([512]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,645 - mmcv - INFO - \r\n",
      "backbone.layer4.0.conv3.weight - torch.Size([2048, 512, 1, 1]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,645 - mmcv - INFO - \r\n",
      "backbone.layer4.0.bn3.weight - torch.Size([2048]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,645 - mmcv - INFO - \r\n",
      "backbone.layer4.0.bn3.bias - torch.Size([2048]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,645 - mmcv - INFO - \r\n",
      "backbone.layer4.0.downsample.0.weight - torch.Size([2048, 1024, 1, 1]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,645 - mmcv - INFO - \r\n",
      "backbone.layer4.0.downsample.1.weight - torch.Size([2048]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,645 - mmcv - INFO - \r\n",
      "backbone.layer4.0.downsample.1.bias - torch.Size([2048]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,645 - mmcv - INFO - \r\n",
      "backbone.layer4.1.conv1.weight - torch.Size([512, 2048, 1, 1]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,645 - mmcv - INFO - \r\n",
      "backbone.layer4.1.bn1.weight - torch.Size([512]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,646 - mmcv - INFO - \r\n",
      "backbone.layer4.1.bn1.bias - torch.Size([512]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,646 - mmcv - INFO - \r\n",
      "backbone.layer4.1.conv2.weight - torch.Size([512, 512, 3, 3]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,646 - mmcv - INFO - \r\n",
      "backbone.layer4.1.bn2.weight - torch.Size([512]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,646 - mmcv - INFO - \r\n",
      "backbone.layer4.1.bn2.bias - torch.Size([512]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,646 - mmcv - INFO - \r\n",
      "backbone.layer4.1.conv3.weight - torch.Size([2048, 512, 1, 1]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,646 - mmcv - INFO - \r\n",
      "backbone.layer4.1.bn3.weight - torch.Size([2048]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,646 - mmcv - INFO - \r\n",
      "backbone.layer4.1.bn3.bias - torch.Size([2048]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,646 - mmcv - INFO - \r\n",
      "backbone.layer4.2.conv1.weight - torch.Size([512, 2048, 1, 1]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,646 - mmcv - INFO - \r\n",
      "backbone.layer4.2.bn1.weight - torch.Size([512]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,646 - mmcv - INFO - \r\n",
      "backbone.layer4.2.bn1.bias - torch.Size([512]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,646 - mmcv - INFO - \r\n",
      "backbone.layer4.2.conv2.weight - torch.Size([512, 512, 3, 3]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,646 - mmcv - INFO - \r\n",
      "backbone.layer4.2.bn2.weight - torch.Size([512]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,647 - mmcv - INFO - \r\n",
      "backbone.layer4.2.bn2.bias - torch.Size([512]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,647 - mmcv - INFO - \r\n",
      "backbone.layer4.2.conv3.weight - torch.Size([2048, 512, 1, 1]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,647 - mmcv - INFO - \r\n",
      "backbone.layer4.2.bn3.weight - torch.Size([2048]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,647 - mmcv - INFO - \r\n",
      "backbone.layer4.2.bn3.bias - torch.Size([2048]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,647 - mmcv - INFO - \r\n",
      "neck.lateral_convs.0.conv.weight - torch.Size([256, 256, 1, 1]): \r\n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,647 - mmcv - INFO - \r\n",
      "neck.lateral_convs.0.conv.bias - torch.Size([256]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-08-11 07:03:33,647 - mmcv - INFO - \r\n",
      "neck.lateral_convs.1.conv.weight - torch.Size([256, 512, 1, 1]): \r\n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,647 - mmcv - INFO - \r\n",
      "neck.lateral_convs.1.conv.bias - torch.Size([256]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-08-11 07:03:33,647 - mmcv - INFO - \r\n",
      "neck.lateral_convs.2.conv.weight - torch.Size([256, 1024, 1, 1]): \r\n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,647 - mmcv - INFO - \r\n",
      "neck.lateral_convs.2.conv.bias - torch.Size([256]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-08-11 07:03:33,647 - mmcv - INFO - \r\n",
      "neck.lateral_convs.3.conv.weight - torch.Size([256, 2048, 1, 1]): \r\n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,647 - mmcv - INFO - \r\n",
      "neck.lateral_convs.3.conv.bias - torch.Size([256]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-08-11 07:03:33,648 - mmcv - INFO - \r\n",
      "neck.fpn_convs.0.conv.weight - torch.Size([256, 256, 3, 3]): \r\n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,648 - mmcv - INFO - \r\n",
      "neck.fpn_convs.0.conv.bias - torch.Size([256]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-08-11 07:03:33,648 - mmcv - INFO - \r\n",
      "neck.fpn_convs.1.conv.weight - torch.Size([256, 256, 3, 3]): \r\n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,648 - mmcv - INFO - \r\n",
      "neck.fpn_convs.1.conv.bias - torch.Size([256]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-08-11 07:03:33,648 - mmcv - INFO - \r\n",
      "neck.fpn_convs.2.conv.weight - torch.Size([256, 256, 3, 3]): \r\n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,648 - mmcv - INFO - \r\n",
      "neck.fpn_convs.2.conv.bias - torch.Size([256]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-08-11 07:03:33,648 - mmcv - INFO - \r\n",
      "neck.fpn_convs.3.conv.weight - torch.Size([256, 256, 3, 3]): \r\n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,648 - mmcv - INFO - \r\n",
      "neck.fpn_convs.3.conv.bias - torch.Size([256]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-08-11 07:03:33,648 - mmcv - INFO - \r\n",
      "neck.encoder_conv.conv.weight - torch.Size([256, 1, 3, 3]): \r\n",
      "Initialized by user-defined `init_weights` in ConvModule  \r\n",
      " \r\n",
      "2025-08-11 07:03:33,648 - mmcv - INFO - \r\n",
      "neck.encoder_conv.conv.bias - torch.Size([256]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-08-11 07:03:33,648 - mmcv - INFO - \r\n",
      "neck.fusion_conv.conv.weight - torch.Size([256, 256, 3, 3]): \r\n",
      "Initialized by user-defined `init_weights` in ConvModule  \r\n",
      " \r\n",
      "2025-08-11 07:03:33,648 - mmcv - INFO - \r\n",
      "neck.fusion_conv.conv.bias - torch.Size([256]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-08-11 07:03:33,648 - mmcv - INFO - \r\n",
      "neck.excite_conv.conv.weight - torch.Size([256, 256, 3, 3]): \r\n",
      "Initialized by user-defined `init_weights` in ConvModule  \r\n",
      " \r\n",
      "2025-08-11 07:03:33,649 - mmcv - INFO - \r\n",
      "neck.excite_conv.conv.bias - torch.Size([256]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-08-11 07:03:33,649 - mmcv - INFO - \r\n",
      "neck.fcm_ip_channel_fc.weight - torch.Size([1, 128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-08-11 07:03:33,649 - mmcv - INFO - \r\n",
      "neck.fcm_ip_channel_fc.bias - torch.Size([1]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-08-11 07:03:33,649 - mmcv - INFO - \r\n",
      "neck.fcm_ip_channel_atten.attn.in_proj_weight - torch.Size([48, 16]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-08-11 07:03:33,649 - mmcv - INFO - \r\n",
      "neck.fcm_ip_channel_atten.attn.in_proj_bias - torch.Size([48]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-08-11 07:03:33,649 - mmcv - INFO - \r\n",
      "neck.fcm_ip_channel_atten.attn.out_proj.weight - torch.Size([16, 16]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-08-11 07:03:33,649 - mmcv - INFO - \r\n",
      "neck.fcm_ip_channel_atten.attn.out_proj.bias - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-08-11 07:03:33,649 - mmcv - INFO - \r\n",
      "neck.fcm_sp_channel_atten.attn.in_proj_weight - torch.Size([48, 16]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-08-11 07:03:33,649 - mmcv - INFO - \r\n",
      "neck.fcm_sp_channel_atten.attn.in_proj_bias - torch.Size([48]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-08-11 07:03:33,649 - mmcv - INFO - \r\n",
      "neck.fcm_sp_channel_atten.attn.out_proj.weight - torch.Size([16, 16]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-08-11 07:03:33,649 - mmcv - INFO - \r\n",
      "neck.fcm_sp_channel_atten.attn.out_proj.bias - torch.Size([16]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-08-11 07:03:33,649 - mmcv - INFO - \r\n",
      "neck.fcm_sp_channel_fc.weight - torch.Size([1, 128]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-08-11 07:03:33,650 - mmcv - INFO - \r\n",
      "neck.fcm_sp_channel_fc.bias - torch.Size([1]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-08-11 07:03:33,650 - mmcv - INFO - \r\n",
      "neck.group_attn_convs.0.conv.weight - torch.Size([32, 32, 1, 1]): \r\n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,650 - mmcv - INFO - \r\n",
      "neck.group_attn_convs.0.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-08-11 07:03:33,650 - mmcv - INFO - \r\n",
      "neck.group_attn_convs.1.conv.weight - torch.Size([32, 32, 1, 1]): \r\n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,650 - mmcv - INFO - \r\n",
      "neck.group_attn_convs.1.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-08-11 07:03:33,650 - mmcv - INFO - \r\n",
      "neck.group_attn_convs.2.conv.weight - torch.Size([32, 32, 1, 1]): \r\n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,650 - mmcv - INFO - \r\n",
      "neck.group_attn_convs.2.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-08-11 07:03:33,650 - mmcv - INFO - \r\n",
      "neck.group_attn_convs.3.conv.weight - torch.Size([32, 32, 1, 1]): \r\n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,650 - mmcv - INFO - \r\n",
      "neck.group_attn_convs.3.conv.bias - torch.Size([32]): \r\n",
      "The value is the same before and after calling `init_weights` of OrientedRCNN  \r\n",
      " \r\n",
      "2025-08-11 07:03:33,650 - mmcv - INFO - \r\n",
      "rpn_head.rpn_conv.weight - torch.Size([256, 256, 3, 3]): \r\n",
      "NormalInit: mean=0, std=0.01, bias=0 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,650 - mmcv - INFO - \r\n",
      "rpn_head.rpn_conv.bias - torch.Size([256]): \r\n",
      "NormalInit: mean=0, std=0.01, bias=0 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,650 - mmcv - INFO - \r\n",
      "rpn_head.rpn_cls.weight - torch.Size([3, 256, 1, 1]): \r\n",
      "NormalInit: mean=0, std=0.01, bias=0 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,650 - mmcv - INFO - \r\n",
      "rpn_head.rpn_cls.bias - torch.Size([3]): \r\n",
      "NormalInit: mean=0, std=0.01, bias=0 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,651 - mmcv - INFO - \r\n",
      "rpn_head.rpn_reg.weight - torch.Size([18, 256, 1, 1]): \r\n",
      "NormalInit: mean=0, std=0.01, bias=0 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,651 - mmcv - INFO - \r\n",
      "rpn_head.rpn_reg.bias - torch.Size([18]): \r\n",
      "NormalInit: mean=0, std=0.01, bias=0 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,651 - mmcv - INFO - \r\n",
      "roi_head.bbox_head.fc_cls.weight - torch.Size([21, 1024]): \r\n",
      "XavierInit: gain=1, distribution=normal, bias=0 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,651 - mmcv - INFO - \r\n",
      "roi_head.bbox_head.fc_cls.bias - torch.Size([21]): \r\n",
      "NormalInit: mean=0, std=0.01, bias=0 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,651 - mmcv - INFO - \r\n",
      "roi_head.bbox_head.fc_reg.weight - torch.Size([5, 1024]): \r\n",
      "XavierInit: gain=1, distribution=normal, bias=0 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,651 - mmcv - INFO - \r\n",
      "roi_head.bbox_head.fc_reg.bias - torch.Size([5]): \r\n",
      "NormalInit: mean=0, std=0.001, bias=0 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,651 - mmcv - INFO - \r\n",
      "roi_head.bbox_head.shared_fcs.0.weight - torch.Size([1024, 12544]): \r\n",
      "XavierInit: gain=1, distribution=normal, bias=0 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,651 - mmcv - INFO - \r\n",
      "roi_head.bbox_head.shared_fcs.0.bias - torch.Size([1024]): \r\n",
      "XavierInit: gain=1, distribution=normal, bias=0 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,651 - mmcv - INFO - \r\n",
      "roi_head.bbox_head.shared_fcs.1.weight - torch.Size([1024, 1024]): \r\n",
      "XavierInit: gain=1, distribution=normal, bias=0 \r\n",
      " \r\n",
      "2025-08-11 07:03:33,651 - mmcv - INFO - \r\n",
      "roi_head.bbox_head.shared_fcs.1.bias - torch.Size([1024]): \r\n",
      "XavierInit: gain=1, distribution=normal, bias=0 \r\n",
      " \r\n",
      "2025-08-11 07:03:36,501 - mmrotate - INFO - Start running, host: root@45c80a22a731, work_dir: /kaggle/working/runs/firnet_train\r\n",
      "2025-08-11 07:03:36,501 - mmrotate - INFO - Hooks will be executed in the following order:\r\n",
      "before_run:\r\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \r\n",
      "(NORMAL      ) CheckpointHook                     \r\n",
      "(LOW         ) EvalHook                           \r\n",
      "(VERY_LOW    ) TextLoggerHook                     \r\n",
      " -------------------- \r\n",
      "before_train_epoch:\r\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \r\n",
      "(LOW         ) IterTimerHook                      \r\n",
      "(LOW         ) EvalHook                           \r\n",
      "(VERY_LOW    ) TextLoggerHook                     \r\n",
      " -------------------- \r\n",
      "before_train_iter:\r\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \r\n",
      "(LOW         ) IterTimerHook                      \r\n",
      "(LOW         ) EvalHook                           \r\n",
      " -------------------- \r\n",
      "after_train_iter:\r\n",
      "(ABOVE_NORMAL) OptimizerHook                      \r\n",
      "(NORMAL      ) CheckpointHook                     \r\n",
      "(LOW         ) IterTimerHook                      \r\n",
      "(LOW         ) EvalHook                           \r\n",
      "(VERY_LOW    ) TextLoggerHook                     \r\n",
      " -------------------- \r\n",
      "after_train_epoch:\r\n",
      "(NORMAL      ) CheckpointHook                     \r\n",
      "(LOW         ) EvalHook                           \r\n",
      "(VERY_LOW    ) TextLoggerHook                     \r\n",
      " -------------------- \r\n",
      "before_val_epoch:\r\n",
      "(LOW         ) IterTimerHook                      \r\n",
      "(VERY_LOW    ) TextLoggerHook                     \r\n",
      " -------------------- \r\n",
      "before_val_iter:\r\n",
      "(LOW         ) IterTimerHook                      \r\n",
      " -------------------- \r\n",
      "after_val_iter:\r\n",
      "(LOW         ) IterTimerHook                      \r\n",
      " -------------------- \r\n",
      "after_val_epoch:\r\n",
      "(VERY_LOW    ) TextLoggerHook                     \r\n",
      " -------------------- \r\n",
      "after_run:\r\n",
      "(VERY_LOW    ) TextLoggerHook                     \r\n",
      " -------------------- \r\n",
      "2025-08-11 07:03:36,502 - mmrotate - INFO - workflow: [('train', 1)], max: 10 epochs\r\n",
      "2025-08-11 07:03:36,502 - mmrotate - INFO - Checkpoints will be saved to /kaggle/working/runs/firnet_train by HardDiskBackend.\r\n",
      "/usr/local/lib/python3.10/dist-packages/mmdet/models/dense_heads/anchor_head.py:123: UserWarning: DeprecationWarning: anchor_generator is deprecated, please use \"prior_generator\" instead\r\n",
      "  warnings.warn('DeprecationWarning: anchor_generator is deprecated, '\r\n",
      "2025-08-11 07:04:06,038 - mmrotate - INFO - Epoch [1][50/1855]\tlr: 9.967e-04, eta: 3:02:07, time: 0.591, data_time: 0.055, memory: 5421, loss_rpn_cls: 0.4097, loss_rpn_bbox: 0.1313, loss_cls: 0.2242, acc: 96.3477, loss_bbox: 0.0173, loss: 0.7825, grad_norm: 7.8934\r\n",
      "2025-08-11 07:04:31,488 - mmrotate - INFO - Epoch [1][100/1855]\tlr: 1.163e-03, eta: 2:49:04, time: 0.509, data_time: 0.010, memory: 5421, loss_rpn_cls: 0.1585, loss_rpn_bbox: 0.1324, loss_cls: 0.0519, acc: 99.0234, loss_bbox: 0.0059, loss: 0.3488, grad_norm: 2.7256\r\n",
      "2025-08-11 07:04:57,031 - mmrotate - INFO - Epoch [1][150/1855]\tlr: 1.330e-03, eta: 2:44:37, time: 0.511, data_time: 0.011, memory: 5421, loss_rpn_cls: 0.1354, loss_rpn_bbox: 0.1226, loss_cls: 0.0463, acc: 99.1406, loss_bbox: 0.0063, loss: 0.3106, grad_norm: 2.2725\r\n",
      "2025-08-11 07:05:22,429 - mmrotate - INFO - Epoch [1][200/1855]\tlr: 1.497e-03, eta: 2:41:58, time: 0.508, data_time: 0.011, memory: 5421, loss_rpn_cls: 0.0971, loss_rpn_bbox: 0.1151, loss_cls: 0.0369, acc: 99.2676, loss_bbox: 0.0087, loss: 0.2579, grad_norm: 2.0433\r\n",
      "2025-08-11 07:05:47,855 - mmrotate - INFO - Epoch [1][250/1855]\tlr: 1.663e-03, eta: 2:40:14, time: 0.509, data_time: 0.011, memory: 5421, loss_rpn_cls: 0.0935, loss_rpn_bbox: 0.1133, loss_cls: 0.0361, acc: 99.2656, loss_bbox: 0.0074, loss: 0.2503, grad_norm: 1.5553\r\n",
      "2025-08-11 07:06:13,336 - mmrotate - INFO - Epoch [1][300/1855]\tlr: 1.830e-03, eta: 2:39:00, time: 0.510, data_time: 0.011, memory: 5421, loss_rpn_cls: 0.0792, loss_rpn_bbox: 0.0970, loss_cls: 0.0341, acc: 99.2715, loss_bbox: 0.0129, loss: 0.2231, grad_norm: 1.8243\r\n",
      "2025-08-11 07:06:38,763 - mmrotate - INFO - Epoch [1][350/1855]\tlr: 1.997e-03, eta: 2:37:57, time: 0.509, data_time: 0.010, memory: 5421, loss_rpn_cls: 0.0842, loss_rpn_bbox: 0.1027, loss_cls: 0.0445, acc: 99.1836, loss_bbox: 0.0115, loss: 0.2429, grad_norm: 2.3812\r\n",
      "2025-08-11 07:07:04,156 - mmrotate - INFO - Epoch [1][400/1855]\tlr: 2.163e-03, eta: 2:37:02, time: 0.508, data_time: 0.011, memory: 5421, loss_rpn_cls: 0.0871, loss_rpn_bbox: 0.0988, loss_cls: 0.0460, acc: 99.0117, loss_bbox: 0.0193, loss: 0.2512, grad_norm: 2.1436\r\n",
      "2025-08-11 07:07:29,630 - mmrotate - INFO - Epoch [1][450/1855]\tlr: 2.330e-03, eta: 2:36:16, time: 0.509, data_time: 0.011, memory: 5421, loss_rpn_cls: 0.0640, loss_rpn_bbox: 0.0918, loss_cls: 0.0348, acc: 99.1426, loss_bbox: 0.0158, loss: 0.2063, grad_norm: 1.8007\r\n",
      "2025-08-11 07:07:55,086 - mmrotate - INFO - Epoch [1][500/1855]\tlr: 2.497e-03, eta: 2:35:34, time: 0.509, data_time: 0.011, memory: 5421, loss_rpn_cls: 0.0576, loss_rpn_bbox: 0.1123, loss_cls: 0.0413, acc: 98.9883, loss_bbox: 0.0217, loss: 0.2330, grad_norm: 2.2903\r\n",
      "2025-08-11 07:08:20,574 - mmrotate - INFO - Epoch [1][550/1855]\tlr: 2.500e-03, eta: 2:34:56, time: 0.510, data_time: 0.011, memory: 5421, loss_rpn_cls: 0.0567, loss_rpn_bbox: 0.1024, loss_cls: 0.0478, acc: 98.7559, loss_bbox: 0.0291, loss: 0.2360, grad_norm: 2.1635\r\n",
      "2025-08-11 07:08:46,033 - mmrotate - INFO - Epoch [1][600/1855]\tlr: 2.500e-03, eta: 2:34:19, time: 0.509, data_time: 0.011, memory: 5421, loss_rpn_cls: 0.0620, loss_rpn_bbox: 0.1178, loss_cls: 0.0575, acc: 98.4023, loss_bbox: 0.0365, loss: 0.2738, grad_norm: 2.5484\r\n",
      "2025-08-11 07:09:11,564 - mmrotate - INFO - Epoch [1][650/1855]\tlr: 2.500e-03, eta: 2:33:46, time: 0.511, data_time: 0.011, memory: 5421, loss_rpn_cls: 0.0397, loss_rpn_bbox: 0.0926, loss_cls: 0.0363, acc: 99.0508, loss_bbox: 0.0227, loss: 0.1914, grad_norm: 1.7609\r\n",
      "2025-08-11 07:09:36,961 - mmrotate - INFO - Epoch [1][700/1855]\tlr: 2.500e-03, eta: 2:33:11, time: 0.508, data_time: 0.010, memory: 5421, loss_rpn_cls: 0.0773, loss_rpn_bbox: 0.1045, loss_cls: 0.0393, acc: 98.9004, loss_bbox: 0.0223, loss: 0.2435, grad_norm: 2.6843\r\n",
      "2025-08-11 07:10:02,234 - mmrotate - INFO - Epoch [1][750/1855]\tlr: 2.500e-03, eta: 2:32:34, time: 0.505, data_time: 0.010, memory: 5421, loss_rpn_cls: 0.0489, loss_rpn_bbox: 0.0939, loss_cls: 0.0528, acc: 98.5352, loss_bbox: 0.0355, loss: 0.2312, grad_norm: 2.4235\r\n",
      "2025-08-11 07:10:27,612 - mmrotate - INFO - Epoch [1][800/1855]\tlr: 2.500e-03, eta: 2:32:01, time: 0.508, data_time: 0.010, memory: 5421, loss_rpn_cls: 0.0400, loss_rpn_bbox: 0.0810, loss_cls: 0.0328, acc: 99.1680, loss_bbox: 0.0244, loss: 0.1782, grad_norm: 1.8543\r\n",
      "2025-08-11 07:10:53,046 - mmrotate - INFO - Epoch [1][850/1855]\tlr: 2.500e-03, eta: 2:31:30, time: 0.509, data_time: 0.011, memory: 5421, loss_rpn_cls: 0.0490, loss_rpn_bbox: 0.1082, loss_cls: 0.0681, acc: 98.0566, loss_bbox: 0.0465, loss: 0.2718, grad_norm: 2.8044\r\n",
      "2025-08-11 07:11:18,509 - mmrotate - INFO - Epoch [1][900/1855]\tlr: 2.500e-03, eta: 2:31:00, time: 0.509, data_time: 0.011, memory: 5421, loss_rpn_cls: 0.0623, loss_rpn_bbox: 0.0810, loss_cls: 0.0596, acc: 98.6914, loss_bbox: 0.0243, loss: 0.2272, grad_norm: 2.5387\r\n",
      "2025-08-11 07:11:43,922 - mmrotate - INFO - Epoch [1][950/1855]\tlr: 2.500e-03, eta: 2:30:29, time: 0.508, data_time: 0.010, memory: 5532, loss_rpn_cls: 0.0549, loss_rpn_bbox: 0.0970, loss_cls: 0.0545, acc: 98.5859, loss_bbox: 0.0229, loss: 0.2294, grad_norm: 2.0871\r\n",
      "2025-08-11 07:12:09,440 - mmrotate - INFO - Exp name: firnet_r50_fpn_1x_sccos.py\r\n",
      "2025-08-11 07:12:09,441 - mmrotate - INFO - Epoch [1][1000/1855]\tlr: 2.500e-03, eta: 2:30:01, time: 0.510, data_time: 0.011, memory: 5532, loss_rpn_cls: 0.0360, loss_rpn_bbox: 0.1024, loss_cls: 0.0628, acc: 98.1250, loss_bbox: 0.0481, loss: 0.2493, grad_norm: 2.4308\r\n",
      "2025-08-11 07:12:34,990 - mmrotate - INFO - Epoch [1][1050/1855]\tlr: 2.500e-03, eta: 2:29:34, time: 0.511, data_time: 0.011, memory: 5532, loss_rpn_cls: 0.0447, loss_rpn_bbox: 0.1061, loss_cls: 0.0554, acc: 98.4121, loss_bbox: 0.0397, loss: 0.2458, grad_norm: 2.2599\r\n",
      "2025-08-11 07:13:00,560 - mmrotate - INFO - Epoch [1][1100/1855]\tlr: 2.500e-03, eta: 2:29:07, time: 0.511, data_time: 0.012, memory: 5532, loss_rpn_cls: 0.0525, loss_rpn_bbox: 0.1162, loss_cls: 0.0762, acc: 97.6797, loss_bbox: 0.0604, loss: 0.3052, grad_norm: 2.9149\r\n",
      "2025-08-11 07:13:26,022 - mmrotate - INFO - Epoch [1][1150/1855]\tlr: 2.500e-03, eta: 2:28:39, time: 0.509, data_time: 0.011, memory: 5532, loss_rpn_cls: 0.0333, loss_rpn_bbox: 0.0827, loss_cls: 0.0726, acc: 97.8164, loss_bbox: 0.0495, loss: 0.2381, grad_norm: 2.2686\r\n",
      "2025-08-11 07:13:51,509 - mmrotate - INFO - Epoch [1][1200/1855]\tlr: 2.500e-03, eta: 2:28:11, time: 0.510, data_time: 0.011, memory: 5532, loss_rpn_cls: 0.0453, loss_rpn_bbox: 0.1075, loss_cls: 0.0715, acc: 97.7559, loss_bbox: 0.0632, loss: 0.2875, grad_norm: 2.5669\r\n",
      "2025-08-11 07:14:16,973 - mmrotate - INFO - Epoch [1][1250/1855]\tlr: 2.500e-03, eta: 2:27:43, time: 0.509, data_time: 0.011, memory: 5532, loss_rpn_cls: 0.0333, loss_rpn_bbox: 0.0787, loss_cls: 0.0864, acc: 97.1621, loss_bbox: 0.0774, loss: 0.2758, grad_norm: 2.5524\r\n",
      "2025-08-11 07:14:42,515 - mmrotate - INFO - Epoch [1][1300/1855]\tlr: 2.500e-03, eta: 2:27:17, time: 0.511, data_time: 0.011, memory: 5532, loss_rpn_cls: 0.0321, loss_rpn_bbox: 0.0630, loss_cls: 0.0723, acc: 97.7188, loss_bbox: 0.0553, loss: 0.2227, grad_norm: 2.4407\r\n",
      "2025-08-11 07:15:07,982 - mmrotate - INFO - Epoch [1][1350/1855]\tlr: 2.500e-03, eta: 2:26:49, time: 0.509, data_time: 0.011, memory: 5532, loss_rpn_cls: 0.0351, loss_rpn_bbox: 0.0659, loss_cls: 0.0750, acc: 97.5938, loss_bbox: 0.0596, loss: 0.2356, grad_norm: 2.6479\r\n",
      "2025-08-11 07:15:33,372 - mmrotate - INFO - Epoch [1][1400/1855]\tlr: 2.500e-03, eta: 2:26:21, time: 0.508, data_time: 0.010, memory: 5540, loss_rpn_cls: 0.0308, loss_rpn_bbox: 0.0572, loss_cls: 0.0798, acc: 97.4414, loss_bbox: 0.0582, loss: 0.2260, grad_norm: 2.4310\r\n",
      "2025-08-11 07:15:58,850 - mmrotate - INFO - Epoch [1][1450/1855]\tlr: 2.500e-03, eta: 2:25:54, time: 0.510, data_time: 0.011, memory: 5540, loss_rpn_cls: 0.0306, loss_rpn_bbox: 0.0775, loss_cls: 0.0660, acc: 97.6641, loss_bbox: 0.0599, loss: 0.2340, grad_norm: 2.3720\r\n",
      "2025-08-11 07:16:24,288 - mmrotate - INFO - Epoch [1][1500/1855]\tlr: 2.500e-03, eta: 2:25:27, time: 0.509, data_time: 0.011, memory: 5540, loss_rpn_cls: 0.0312, loss_rpn_bbox: 0.0702, loss_cls: 0.0792, acc: 97.2891, loss_bbox: 0.0699, loss: 0.2506, grad_norm: 2.5982\r\n",
      "2025-08-11 07:16:49,762 - mmrotate - INFO - Epoch [1][1550/1855]\tlr: 2.500e-03, eta: 2:25:00, time: 0.509, data_time: 0.011, memory: 5540, loss_rpn_cls: 0.0345, loss_rpn_bbox: 0.0935, loss_cls: 0.0722, acc: 97.3965, loss_bbox: 0.0648, loss: 0.2650, grad_norm: 2.5747\r\n",
      "2025-08-11 07:17:15,281 - mmrotate - INFO - Epoch [1][1600/1855]\tlr: 2.500e-03, eta: 2:24:33, time: 0.510, data_time: 0.011, memory: 5540, loss_rpn_cls: 0.0306, loss_rpn_bbox: 0.0672, loss_cls: 0.0779, acc: 97.3086, loss_bbox: 0.0651, loss: 0.2409, grad_norm: 2.4485\r\n",
      "2025-08-11 07:17:40,789 - mmrotate - INFO - Epoch [1][1650/1855]\tlr: 2.500e-03, eta: 2:24:07, time: 0.510, data_time: 0.011, memory: 5540, loss_rpn_cls: 0.0448, loss_rpn_bbox: 0.0798, loss_cls: 0.0605, acc: 98.1230, loss_bbox: 0.0377, loss: 0.2228, grad_norm: 2.5065\r\n",
      "2025-08-11 07:18:06,270 - mmrotate - INFO - Epoch [1][1700/1855]\tlr: 2.500e-03, eta: 2:23:40, time: 0.510, data_time: 0.011, memory: 5540, loss_rpn_cls: 0.0342, loss_rpn_bbox: 0.0743, loss_cls: 0.0818, acc: 97.4707, loss_bbox: 0.0522, loss: 0.2425, grad_norm: 2.6302\r\n",
      "2025-08-11 07:18:31,718 - mmrotate - INFO - Epoch [1][1750/1855]\tlr: 2.500e-03, eta: 2:23:13, time: 0.509, data_time: 0.010, memory: 5540, loss_rpn_cls: 0.0327, loss_rpn_bbox: 0.0701, loss_cls: 0.0634, acc: 97.9766, loss_bbox: 0.0418, loss: 0.2080, grad_norm: 2.1622\r\n",
      "2025-08-11 07:18:57,137 - mmrotate - INFO - Epoch [1][1800/1855]\tlr: 2.500e-03, eta: 2:22:46, time: 0.508, data_time: 0.010, memory: 5540, loss_rpn_cls: 0.0289, loss_rpn_bbox: 0.0782, loss_cls: 0.0824, acc: 97.0957, loss_bbox: 0.0712, loss: 0.2607, grad_norm: 2.4036\r\n",
      "2025-08-11 07:19:22,564 - mmrotate - INFO - Epoch [1][1850/1855]\tlr: 2.500e-03, eta: 2:22:20, time: 0.509, data_time: 0.011, memory: 5540, loss_rpn_cls: 0.0244, loss_rpn_bbox: 0.0514, loss_cls: 0.0583, acc: 98.0547, loss_bbox: 0.0436, loss: 0.1777, grad_norm: 1.9613\r\n",
      "2025-08-11 07:19:25,152 - mmrotate - INFO - Saving checkpoint at 1 epochs\r\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 464/464, 8.8 task/s, elapsed: 53s, ETA:     0s/usr/local/lib/python3.10/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.10/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.10/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.10/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 2.0.8 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\r\n",
      "  check_for_updates()\r\n",
      "/usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 2.0.8 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\r\n",
      "  check_for_updates()\r\n",
      "/usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 2.0.8 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\r\n",
      "  check_for_updates()\r\n",
      "/usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 2.0.8 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\r\n",
      "  check_for_updates()\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/kaggle/working/mmrotate/tools/train.py\", line 194, in <module>\r\n",
      "    main()\r\n",
      "  File \"/kaggle/working/mmrotate/tools/train.py\", line 183, in main\r\n",
      "    train_detector(\r\n",
      "  File \"/kaggle/working/mmrotate/mmrotate/apis/train.py\", line 144, in train_detector\r\n",
      "    runner.run(data_loaders, cfg.workflow)\r\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/mmcv/runner/epoch_based_runner.py\", line 136, in run\r\n",
      "    epoch_runner(data_loaders[i], **kwargs)\r\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/mmcv/runner/epoch_based_runner.py\", line 58, in train\r\n",
      "    self.call_hook('after_train_epoch')\r\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/mmcv/runner/base_runner.py\", line 317, in call_hook\r\n",
      "    getattr(hook, fn_name)(self)\r\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/mmcv/runner/hooks/evaluation.py\", line 271, in after_train_epoch\r\n",
      "    self._do_evaluate(runner)\r\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/mmdet/core/evaluation/eval_hooks.py\", line 63, in _do_evaluate\r\n",
      "    key_score = self.evaluate(runner, results)\r\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/mmcv/runner/hooks/evaluation.py\", line 367, in evaluate\r\n",
      "    eval_res = self.dataloader.dataset.evaluate(\r\n",
      "  File \"/kaggle/working/mmrotate/mmrotate/datasets/dota.py\", line 202, in evaluate\r\n",
      "    mean_ap, _ = eval_rbbox_map(\r\n",
      "  File \"/kaggle/working/mmrotate/mmrotate/core/evaluation/eval_map.py\", line 243, in eval_rbbox_map\r\n",
      "    print_map_summary(\r\n",
      "  File \"/kaggle/working/mmrotate/mmrotate/core/evaluation/eval_map.py\", line 305, in print_map_summary\r\n",
      "    label_names[j], num_gts[i, j], results[j]['num_dets'],\r\n",
      "IndexError: tuple index out of range\r\n",
      "FIRNet training completed.\n"
     ]
    }
   ],
   "source": [
    "# Train FIRNet (uncomment to run)\n",
    "%cd /kaggle/working/mmrotate\n",
    "!python tools/train.py \\\n",
    "    configs/firnet/firnet_r50_fpn_1x_sccos.py \\\n",
    "    --work-dir /kaggle/working/runs/firnet_train \\\n",
    "    --gpus 1\n",
    "print(\"FIRNet training completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7476dc49",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T07:20:28.513898Z",
     "iopub.status.busy": "2025-08-11T07:20:28.513605Z",
     "iopub.status.idle": "2025-08-11T07:23:19.696612Z",
     "shell.execute_reply": "2025-08-11T07:23:19.695532Z"
    },
    "papermill": {
     "duration": 171.250059,
     "end_time": "2025-08-11T07:23:19.698051",
     "exception": false,
     "start_time": "2025-08-11T07:20:28.447992",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/mmrotate\n",
      "/usr/local/lib/python3.10/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 2.0.8 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\r\n",
      "  check_for_updates()\r\n",
      "/kaggle/working/mmrotate/mmrotate/utils/setup_env.py:38: UserWarning: Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.\r\n",
      "  warnings.warn(\r\n",
      "/kaggle/working/mmrotate/mmrotate/utils/setup_env.py:48: UserWarning: Setting MKL_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.10/dist-packages/mmdet/models/dense_heads/anchor_head.py:116: UserWarning: DeprecationWarning: `num_anchors` is deprecated, for consistency or also use `num_base_priors` instead\r\n",
      "  warnings.warn('DeprecationWarning: `num_anchors` is deprecated, '\r\n",
      "load checkpoint from local path: /kaggle/working/runs/firnet_train/latest.pth\r\n",
      "[                                                  ] 0/464, elapsed: 0s, ETA:/usr/local/lib/python3.10/dist-packages/mmdet/models/dense_heads/anchor_head.py:123: UserWarning: DeprecationWarning: anchor_generator is deprecated, please use \"prior_generator\" instead\r\n",
      "  warnings.warn('DeprecationWarning: anchor_generator is deprecated, '\r\n",
      "[                                                  ] 1/464, 0.4 task/s, elapsed: 2s, ETA:  1106s/usr/local/lib/python3.10/dist-packages/mmdet/models/dense_heads/anchor_head.py:123: UserWarning: DeprecationWarning: anchor_generator is deprecated, please use \"prior_generator\" instead\r\n",
      "  warnings.warn('DeprecationWarning: anchor_generator is deprecated, '\r\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 464/464, 3.0 task/s, elapsed: 155s, ETA:     0s\r\n",
      "writing results to /kaggle/working/runs/firnet_test_results.pkl\r\n",
      "/usr/local/lib/python3.10/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.10/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.10/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.10/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 2.0.8 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\r\n",
      "  check_for_updates()\r\n",
      "/usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 2.0.8 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\r\n",
      "  check_for_updates()\r\n",
      "/usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 2.0.8 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\r\n",
      "  check_for_updates()\r\n",
      "/usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 2.0.8 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\r\n",
      "  check_for_updates()\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/kaggle/working/mmrotate/tools/test.py\", line 271, in <module>\r\n",
      "    main()\r\n",
      "  File \"/kaggle/working/mmrotate/tools/test.py\", line 263, in main\r\n",
      "    metric = dataset.evaluate(outputs, **eval_kwargs)\r\n",
      "  File \"/kaggle/working/mmrotate/mmrotate/datasets/dota.py\", line 202, in evaluate\r\n",
      "    mean_ap, _ = eval_rbbox_map(\r\n",
      "  File \"/kaggle/working/mmrotate/mmrotate/core/evaluation/eval_map.py\", line 243, in eval_rbbox_map\r\n",
      "    print_map_summary(\r\n",
      "  File \"/kaggle/working/mmrotate/mmrotate/core/evaluation/eval_map.py\", line 305, in print_map_summary\r\n",
      "    label_names[j], num_gts[i, j], results[j]['num_dets'],\r\n",
      "IndexError: tuple index out of range\r\n",
      "FIRNet testing completed. Results saved to /kaggle/working/runs/firnet_test_results.pkl\n"
     ]
    }
   ],
   "source": [
    "# Test FIRNet (uncomment to run)\n",
    "%cd /kaggle/working/mmrotate\n",
    "!python tools/test.py \\\n",
    "    configs/firnet/firnet_r50_fpn_1x_sccos.py \\\n",
    "    /kaggle/working/runs/firnet_train/latest.pth \\\n",
    "    --eval mAP \\\n",
    "    --out /kaggle/working/runs/firnet_test_results.pkl \\\n",
    "    --show-dir /kaggle/working/runs/firnet_test/vis\n",
    "print(\"FIRNet testing completed. Results saved to /kaggle/working/runs/firnet_test_results.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6771261,
     "sourceId": 10895847,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 228255757,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1634.934821,
   "end_time": "2025-08-11T07:23:20.606823",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-08-11T06:56:05.672002",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
