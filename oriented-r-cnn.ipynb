{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b895fc82",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T13:58:04.485982Z",
     "iopub.status.busy": "2025-06-13T13:58:04.485613Z",
     "iopub.status.idle": "2025-06-13T13:58:04.609930Z",
     "shell.execute_reply": "2025-06-13T13:58:04.608901Z"
    },
    "papermill": {
     "duration": 0.130267,
     "end_time": "2025-06-13T13:58:04.611306",
     "exception": false,
     "start_time": "2025-06-13T13:58:04.481039",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test  train\r\n"
     ]
    }
   ],
   "source": [
    "!ls /kaggle/input/sccos-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "babeec20",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T13:58:04.618492Z",
     "iopub.status.busy": "2025-06-13T13:58:04.618249Z",
     "iopub.status.idle": "2025-06-13T13:58:08.919793Z",
     "shell.execute_reply": "2025-06-13T13:58:08.918674Z"
    },
    "papermill": {
     "duration": 4.306827,
     "end_time": "2025-06-13T13:58:08.921501",
     "exception": false,
     "start_time": "2025-06-13T13:58:04.614674",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\r\n",
      "Copyright (c) 2005-2023 NVIDIA Corporation\r\n",
      "Built on Tue_Aug_15_22:02:13_PDT_2023\r\n",
      "Cuda compilation tools, release 12.2, V12.2.140\r\n",
      "Build cuda_12.2.r12.2/compiler.33191640_0\r\n",
      "PyTorch: 2.5.1+cu121 CUDA Available: True CUDA Version: 12.1\r\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version\n",
    "!python -c \"import torch; print('PyTorch:', torch.__version__, 'CUDA Available:', torch.cuda.is_available(), 'CUDA Version:', torch.version.cuda)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e39502a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T13:58:08.929402Z",
     "iopub.status.busy": "2025-06-13T13:58:08.929120Z",
     "iopub.status.idle": "2025-06-13T13:58:09.050857Z",
     "shell.execute_reply": "2025-06-13T13:58:09.049777Z"
    },
    "papermill": {
     "duration": 0.12755,
     "end_time": "2025-06-13T13:58:09.052646",
     "exception": false,
     "start_time": "2025-06-13T13:58:08.925096",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.12\r\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87d4f680",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T13:58:09.060358Z",
     "iopub.status.busy": "2025-06-13T13:58:09.060075Z",
     "iopub.status.idle": "2025-06-13T13:59:00.314997Z",
     "shell.execute_reply": "2025-06-13T13:59:00.314002Z"
    },
    "papermill": {
     "duration": 51.260399,
     "end_time": "2025-06-13T13:59:00.316519",
     "exception": false,
     "start_time": "2025-06-13T13:58:09.056120",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Skipping mmcv as it is not installed.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Skipping mmcv-full as it is not installed.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Skipping mmdet as it is not installed.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Step 2: Uninstall Conflicting Packages\n",
    "!pip uninstall -y mmcv mmcv-full mmdet torch torchvision tensorflow tensorboard -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dedf5740",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T13:59:00.324299Z",
     "iopub.status.busy": "2025-06-13T13:59:00.324049Z",
     "iopub.status.idle": "2025-06-13T14:01:11.893567Z",
     "shell.execute_reply": "2025-06-13T14:01:11.892350Z"
    },
    "papermill": {
     "duration": 131.57523,
     "end_time": "2025-06-13T14:01:11.895339",
     "exception": false,
     "start_time": "2025-06-13T13:59:00.320109",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 GB\u001b[0m \u001b[31m446.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.2/24.2 MB\u001b[0m \u001b[31m70.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "pytorch-lightning 2.5.0.post0 requires torch>=2.1.0, but you have torch 1.13.1+cu116 which is incompatible.\r\n",
      "torchaudio 2.5.1+cu121 requires torch==2.5.1, but you have torch 1.13.1+cu116 which is incompatible.\r\n",
      "torchmetrics 1.6.1 requires torch>=2.0.0, but you have torch 1.13.1+cu116 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.8/46.8 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m256.2/256.2 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.5/259.5 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.1/50.1 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.7/89.7 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m449.6/449.6 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.5/311.5 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.4/239.4 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m506.5/506.5 kB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.2/144.2 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.1/953.1 kB\u001b[0m \u001b[31m51.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.5/99.5 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Building wheel for oss2 (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Building wheel for aliyun-python-sdk-core (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Building wheel for crcmod (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "dopamine-rl 4.1.0 requires tensorflow>=2.2.0, which is not installed.\r\n",
      "tensorflow-decision-forests 1.10.0 requires tensorflow==2.17.0, which is not installed.\r\n",
      "datasets 3.3.1 requires requests>=2.32.2, but you have requests 2.28.2 which is incompatible.\r\n",
      "datasets 3.3.1 requires tqdm>=4.66.3, but you have tqdm 4.65.2 which is incompatible.\r\n",
      "featuretools 1.31.0 requires tqdm>=4.66.3, but you have tqdm 4.65.2 which is incompatible.\r\n",
      "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.12.0 which is incompatible.\r\n",
      "google-cloud-bigtable 2.27.0 requires google-api-core[grpc]<3.0.0dev,>=2.16.0, but you have google-api-core 1.34.1 which is incompatible.\r\n",
      "google-colab 1.0.0 requires notebook==6.5.5, but you have notebook 6.5.4 which is incompatible.\r\n",
      "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\r\n",
      "google-colab 1.0.0 requires requests==2.32.3, but you have requests 2.28.2 which is incompatible.\r\n",
      "jupyterlab-server 2.27.3 requires requests>=2.31, but you have requests 2.28.2 which is incompatible.\r\n",
      "langchain 0.3.12 requires async-timeout<5.0.0,>=4.0.0; python_version < \"3.11\", but you have async-timeout 5.0.1 which is incompatible.\r\n",
      "pandas-gbq 0.25.0 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\r\n",
      "plotnine 0.14.4 requires matplotlib>=3.8.0, but you have matplotlib 3.7.5 which is incompatible.\r\n",
      "pymc 5.19.1 requires rich>=13.7.1, but you have rich 13.4.2 which is incompatible.\r\n",
      "pytensor 2.26.4 requires filelock>=3.15, but you have filelock 3.14.0 which is incompatible.\r\n",
      "pytorch-lightning 2.5.0.post0 requires torch>=2.1.0, but you have torch 1.13.1+cu116 which is incompatible.\r\n",
      "sphinx 8.1.3 requires requests>=2.30.0, but you have requests 2.28.2 which is incompatible.\r\n",
      "torchmetrics 1.6.1 requires torch>=2.0.0, but you have torch 1.13.1+cu116 which is incompatible.\r\n",
      "yfinance 0.2.50 requires requests>=2.31, but you have requests 2.28.2 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.7/452.7 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install torch==1.13.1+cu116 torchvision==0.14.1+cu116 -f https://download.pytorch.org/whl/torch_stable.html -q\n",
    "!pip install mmcv-full==1.7.1 -f https://download.openmmlab.com/mmcv/dist/cu116/torch1.13.0/index.html -q\n",
    "!pip install mmdet==2.28.2 -q\n",
    "!pip install -U openmim -q\n",
    "!mim install \"mmengine>=0.7.0\" -q\n",
    "!pip install xmltodict -q  # For dataset conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24b8c245",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T14:01:11.972494Z",
     "iopub.status.busy": "2025-06-13T14:01:11.972211Z",
     "iopub.status.idle": "2025-06-13T14:01:13.434216Z",
     "shell.execute_reply": "2025-06-13T14:01:13.433362Z"
    },
    "papermill": {
     "duration": 1.502771,
     "end_time": "2025-06-13T14:01:13.435809",
     "exception": false,
     "start_time": "2025-06-13T14:01:11.933038",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\r\n",
      "Copyright (c) 2005-2023 NVIDIA Corporation\r\n",
      "Built on Tue_Aug_15_22:02:13_PDT_2023\r\n",
      "Cuda compilation tools, release 12.2, V12.2.140\r\n",
      "Build cuda_12.2.r12.2/compiler.33191640_0\r\n",
      "PyTorch: 1.13.1+cu116 CUDA Available: True CUDA Version: 11.6\r\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version\n",
    "!python -c \"import torch; print('PyTorch:', torch.__version__, 'CUDA Available:', torch.cuda.is_available(), 'CUDA Version:', torch.version.cuda)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0e8724b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T14:01:13.511718Z",
     "iopub.status.busy": "2025-06-13T14:01:13.511469Z",
     "iopub.status.idle": "2025-06-13T14:01:26.424727Z",
     "shell.execute_reply": "2025-06-13T14:01:26.423721Z"
    },
    "papermill": {
     "duration": 12.952693,
     "end_time": "2025-06-13T14:01:26.426504",
     "exception": false,
     "start_time": "2025-06-13T14:01:13.473811",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into '/kaggle/working/mmrotate'...\r\n",
      "remote: Enumerating objects: 3897, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (1265/1265), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (386/386), done.\u001b[K\r\n",
      "remote: Total 3897 (delta 987), reused 879 (delta 879), pack-reused 2632 (from 2)\u001b[K\r\n",
      "Receiving objects: 100% (3897/3897), 25.33 MiB | 20.85 MiB/s, done.\r\n",
      "Resolving deltas: 100% (2384/2384), done.\r\n",
      "/kaggle/working/mmrotate\n",
      "Obtaining file:///kaggle/working/mmrotate\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "Collecting e2cnn (from mmrotate==0.3.4)\r\n",
      "  Downloading e2cnn-0.2.3-py3-none-any.whl.metadata (15 kB)\r\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mmrotate==0.3.4) (3.7.5)\r\n",
      "Requirement already satisfied: mmcv-full in /usr/local/lib/python3.10/dist-packages (from mmrotate==0.3.4) (1.7.1)\r\n",
      "Requirement already satisfied: mmdet<3.0.0,>=2.25.1 in /usr/local/lib/python3.10/dist-packages (from mmrotate==0.3.4) (2.28.2)\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mmrotate==0.3.4) (1.26.4)\r\n",
      "Requirement already satisfied: pycocotools in /usr/local/lib/python3.10/dist-packages (from mmrotate==0.3.4) (2.0.8)\r\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from mmrotate==0.3.4) (1.17.0)\r\n",
      "Requirement already satisfied: terminaltables in /usr/local/lib/python3.10/dist-packages (from mmrotate==0.3.4) (3.1.10)\r\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from mmrotate==0.3.4) (1.13.1+cu116)\r\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from mmdet<3.0.0,>=2.25.1->mmrotate==0.3.4) (1.13.1)\r\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from e2cnn->mmrotate==0.3.4) (1.13.1)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmrotate==0.3.4) (1.3.1)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmrotate==0.3.4) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmrotate==0.3.4) (4.55.3)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmrotate==0.3.4) (1.4.7)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmrotate==0.3.4) (24.2)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmrotate==0.3.4) (11.0.0)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmrotate==0.3.4) (3.2.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmrotate==0.3.4) (2.9.0.post0)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->mmrotate==0.3.4) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->mmrotate==0.3.4) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->mmrotate==0.3.4) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->mmrotate==0.3.4) (2025.0.1)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->mmrotate==0.3.4) (2022.0.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->mmrotate==0.3.4) (2.4.1)\r\n",
      "Requirement already satisfied: addict in /usr/local/lib/python3.10/dist-packages (from mmcv-full->mmrotate==0.3.4) (2.4.0)\r\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from mmcv-full->mmrotate==0.3.4) (6.0.2)\r\n",
      "Requirement already satisfied: yapf in /usr/local/lib/python3.10/dist-packages (from mmcv-full->mmrotate==0.3.4) (0.43.0)\r\n",
      "Requirement already satisfied: opencv-python>=3 in /usr/local/lib/python3.10/dist-packages (from mmcv-full->mmrotate==0.3.4) (4.10.0.84)\r\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->mmrotate==0.3.4) (4.12.2)\r\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->mmrotate==0.3.4) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->mmrotate==0.3.4) (2022.0.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->mmrotate==0.3.4) (1.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->mmrotate==0.3.4) (2024.2.0)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->e2cnn->mmrotate==0.3.4) (1.3.0)\r\n",
      "Requirement already satisfied: platformdirs>=3.5.1 in /usr/local/lib/python3.10/dist-packages (from yapf->mmcv-full->mmrotate==0.3.4) (4.3.6)\r\n",
      "Requirement already satisfied: tomli>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from yapf->mmcv-full->mmrotate==0.3.4) (2.2.1)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->mmrotate==0.3.4) (2024.2.0)\r\n",
      "Downloading e2cnn-0.2.3-py3-none-any.whl (225 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.3/225.3 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: e2cnn, mmrotate\r\n",
      "  Running setup.py develop for mmrotate\r\n",
      "Successfully installed e2cnn-0.2.3 mmrotate-0.3.4\r\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Clone and Install MMRotate 0.3.4\n",
    "!git clone https://github.com/open-mmlab/mmrotate.git /kaggle/working/mmrotate\n",
    "%cd /kaggle/working/mmrotate\n",
    "# !git checkout v0.3.4  # Ensure exact version\n",
    "!pip install -r requirements/build.txt -q\n",
    "!pip install -v -e . -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf489bea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T14:01:26.511035Z",
     "iopub.status.busy": "2025-06-13T14:01:26.510724Z",
     "iopub.status.idle": "2025-06-13T14:01:27.908893Z",
     "shell.execute_reply": "2025-06-13T14:01:27.907782Z"
    },
    "papermill": {
     "duration": 1.442722,
     "end_time": "2025-06-13T14:01:27.910993",
     "exception": false,
     "start_time": "2025-06-13T14:01:26.468271",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mmcv-full                          1.7.1\r\n",
      "mmdet                              2.28.2\r\n",
      "mmengine                           0.10.7\r\n",
      "mmrotate                           0.3.4                /kaggle/working/mmrotate\r\n",
      "pytorch-ignite                     0.5.1\r\n",
      "pytorch-lightning                  2.5.0.post0\r\n",
      "torch                              1.13.1+cu116\r\n",
      "torchaudio                         2.5.1+cu121\r\n",
      "torchinfo                          1.8.0\r\n",
      "torchmetrics                       1.6.1\r\n",
      "torchsummary                       1.5.1\r\n",
      "torchtune                          0.5.0\r\n",
      "torchvision                        0.14.1+cu116\r\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Verify Installations\n",
    "!pip list | grep -E 'torch|mmcv|mmdet|mmengine|mmrotate'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "061e45e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T14:01:27.989720Z",
     "iopub.status.busy": "2025-06-13T14:01:27.989395Z",
     "iopub.status.idle": "2025-06-13T14:01:28.004792Z",
     "shell.execute_reply": "2025-06-13T14:01:28.004221Z"
    },
    "papermill": {
     "duration": 0.055683,
     "end_time": "2025-06-13T14:01:28.005928",
     "exception": false,
     "start_time": "2025-06-13T14:01:27.950245",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 6: Prepare Dataset (SCCOS to DOTA format)\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import xmltodict\n",
    "import tqdm\n",
    "import math\n",
    "\n",
    "dataset_path = \"/kaggle/input/sccos-dataset/\"\n",
    "working_dir = \"/kaggle/working/sccos_dota\"\n",
    "train_images_dir = os.path.join(working_dir, \"train/images\")\n",
    "train_labels_dir = os.path.join(working_dir, \"train/labels\")\n",
    "val_images_dir = os.path.join(working_dir, \"val/images\")\n",
    "val_labels_dir = os.path.join(working_dir, \"val/labels\")\n",
    "test_images_dir = os.path.join(working_dir, \"test/images\")\n",
    "test_labels_dir = os.path.join(working_dir, \"test/labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db1f3322",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T14:01:28.084471Z",
     "iopub.status.busy": "2025-06-13T14:01:28.084228Z",
     "iopub.status.idle": "2025-06-13T14:04:48.721272Z",
     "shell.execute_reply": "2025-06-13T14:04:48.719967Z"
    },
    "papermill": {
     "duration": 200.67771,
     "end_time": "2025-06-13T14:04:48.722609",
     "exception": false,
     "start_time": "2025-06-13T14:01:28.044899",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset split: Train=3711, Val=464, Test=464\n",
      "Converting train set to DOTA format...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3711/3711 [00:01<00:00, 2164.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting val set to DOTA format...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 464/464 [00:00<00:00, 2154.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting test set to DOTA format...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 464/464 [00:00<00:00, 2418.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset conversion to DOTA format complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Clean and recreate directories\n",
    "if os.path.exists(working_dir):\n",
    "    shutil.rmtree(working_dir)\n",
    "for dir_path in [train_images_dir, train_labels_dir, val_images_dir, val_labels_dir, test_images_dir, test_labels_dir]:\n",
    "    os.makedirs(dir_path, exist_ok=True)\n",
    "\n",
    "# Source paths\n",
    "train_img_dir = os.path.join(dataset_path, \"train/images\")\n",
    "train_ann_dir = os.path.join(dataset_path, \"train/annotations\")\n",
    "test_img_dir = os.path.join(dataset_path, \"test/images\")\n",
    "test_ann_dir = os.path.join(dataset_path, \"test/annotations\")\n",
    "\n",
    "# Get all files and split\n",
    "train_files = [f for f in os.listdir(train_img_dir) if f.endswith('.png')]\n",
    "test_files = [f for f in os.listdir(test_img_dir) if f.endswith('.png')]\n",
    "random.seed(42)\n",
    "random.shuffle(train_files)\n",
    "random.shuffle(test_files)\n",
    "test_size = len(test_files)\n",
    "val_size = test_size // 2\n",
    "val_files = test_files[:val_size]\n",
    "test_files = test_files[val_size:]\n",
    "\n",
    "# Copy files\n",
    "def copy_files(file_list, src_img_dir, src_ann_dir, dst_img_dir, dst_ann_dir):\n",
    "    for img_file in file_list:\n",
    "        shutil.copy(os.path.join(src_img_dir, img_file), os.path.join(dst_img_dir, img_file))\n",
    "        ann_file = img_file.replace('.png', '.xml')\n",
    "        if os.path.exists(os.path.join(src_ann_dir, ann_file)):\n",
    "            shutil.copy(os.path.join(src_ann_dir, ann_file), os.path.join(dst_ann_dir, ann_file))\n",
    "\n",
    "copy_files(train_files, train_img_dir, train_ann_dir, train_images_dir, train_labels_dir)\n",
    "copy_files(val_files, test_img_dir, test_ann_dir, val_images_dir, val_labels_dir)\n",
    "copy_files(test_files, test_img_dir, test_ann_dir, test_images_dir, test_labels_dir)\n",
    "print(f\"Dataset split: Train={len(train_files)}, Val={len(val_files)}, Test={len(test_files)}\")\n",
    "\n",
    "# Convert XML to DOTA format\n",
    "def convert_robndbox_to_corners(cx, cy, w, h, angle):\n",
    "    angle = float(angle)\n",
    "    cx, cy, w, h = float(cx), float(cy), float(w), float(h)\n",
    "    cos_a = math.cos(angle)\n",
    "    sin_a = math.sin(angle)\n",
    "    dx, dy = w / 2, h / 2\n",
    "    corners = [(-dx, -dy), (dx, -dy), (dx, dy), (-dx, dy)]\n",
    "    rotated_corners = [(cx + x * cos_a - y * sin_a, cy + x * sin_a + y * cos_a) for x, y in corners]\n",
    "    return rotated_corners\n",
    "\n",
    "def convert_xml_to_dota(xml_path, output_label_dir):\n",
    "    with open(xml_path, 'r') as f:\n",
    "        xml_data = xmltodict.parse(f.read())\n",
    "    objects = xml_data['annotation'].get('object', [])\n",
    "    if not isinstance(objects, list):\n",
    "        objects = [objects] if objects else []\n",
    "    txt_lines = []\n",
    "    for obj in objects:\n",
    "        if obj and 'robndbox' in obj:\n",
    "            robndbox = obj['robndbox']\n",
    "            try:\n",
    "                cx, cy, w, h, angle = robndbox['cx'], robndbox['cy'], robndbox['w'], robndbox['h'], robndbox['angle']\n",
    "                (x1, y1), (x2, y2), (x3, y3), (x4, y4) = convert_robndbox_to_corners(cx, cy, w, h, angle)\n",
    "                class_name = \"ship\"\n",
    "                difficulty = 0\n",
    "                txt_lines.append(f\"{x1:.2f} {y1:.2f} {x2:.2f} {y2:.2f} {x3:.2f} {y3:.2f} {x4:.2f} {y4:.2f} {class_name} {difficulty}\")\n",
    "            except (KeyError, ValueError) as e:\n",
    "                print(f\"Invalid robndbox data in {xml_path}: {e}\")\n",
    "                continue\n",
    "    txt_filename = os.path.splitext(os.path.basename(xml_path))[0] + \".txt\"\n",
    "    txt_path = os.path.join(output_label_dir, txt_filename)\n",
    "    if txt_lines:\n",
    "        with open(txt_path, 'w') as f:\n",
    "            f.write(\"\\n\".join(txt_lines))\n",
    "    os.remove(xml_path)\n",
    "\n",
    "for split, label_dir in [(\"train\", train_labels_dir), (\"val\", val_labels_dir), (\"test\", test_labels_dir)]:\n",
    "    print(f\"Converting {split} set to DOTA format...\")\n",
    "    for xml_file in tqdm.tqdm(os.listdir(label_dir)):\n",
    "        if xml_file.endswith(\".xml\"):\n",
    "            convert_xml_to_dota(os.path.join(label_dir, xml_file), label_dir)\n",
    "print(\"Dataset conversion to DOTA format complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2c3b9c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T14:04:48.803446Z",
     "iopub.status.busy": "2025-06-13T14:04:48.803230Z",
     "iopub.status.idle": "2025-06-13T14:06:31.299595Z",
     "shell.execute_reply": "2025-06-13T14:06:31.298557Z"
    },
    "papermill": {
     "duration": 102.616044,
     "end_time": "2025-06-13T14:06:31.379120",
     "exception": false,
     "start_time": "2025-06-13T14:04:48.763076",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.2/190.2 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating training images...\n",
      "Empty file detected: /kaggle/working/sccos_dota/train/images/2284.png\n",
      "Removed bad image: /kaggle/working/sccos_dota/train/images/2284.png\n",
      "Removed corresponding label: /kaggle/working/sccos_dota/train/labels/2284.txt\n",
      "Found and handled 1 bad files.\n"
     ]
    }
   ],
   "source": [
    "# NEW: Fix YAPF compatibility issue\n",
    "!pip install yapf==0.32.0 -q  # Pin to a version compatible with MMCV 1.7.1\n",
    "\n",
    "# NEW: Validate training images\n",
    "import os\n",
    "import cv2\n",
    "import mmcv\n",
    "\n",
    "def validate_images(image_dir, label_dir):\n",
    "    bad_files = []\n",
    "    for img_file in os.listdir(image_dir):\n",
    "        if not img_file.endswith('.png'):\n",
    "            continue\n",
    "        img_path = os.path.join(image_dir, img_file)\n",
    "        # Check if file is empty\n",
    "        if os.path.getsize(img_path) == 0:\n",
    "            bad_files.append(img_file)\n",
    "            print(f\"Empty file detected: {img_path}\")\n",
    "            continue\n",
    "        # Try loading with mmcv (mimics pipeline behavior)\n",
    "        try:\n",
    "            img = mmcv.imread(img_path)\n",
    "            if img is None:\n",
    "                raise ValueError(\"Image loaded as None\")\n",
    "        except Exception as e:\n",
    "            bad_files.append(img_file)\n",
    "            print(f\"Corrupt or unreadable file: {img_path} - Error: {e}\")\n",
    "    \n",
    "    # Remove bad files and their labels\n",
    "    for bad_file in bad_files:\n",
    "        img_path = os.path.join(image_dir, bad_file)\n",
    "        label_file = bad_file.replace('.png', '.txt')\n",
    "        label_path = os.path.join(label_dir, label_file)\n",
    "        if os.path.exists(img_path):\n",
    "            os.remove(img_path)\n",
    "            print(f\"Removed bad image: {img_path}\")\n",
    "        if os.path.exists(label_path):\n",
    "            os.remove(label_path)\n",
    "            print(f\"Removed corresponding label: {label_path}\")\n",
    "    \n",
    "    if bad_files:\n",
    "        print(f\"Found and handled {len(bad_files)} bad files.\")\n",
    "    else:\n",
    "        print(\"All images validated successfully.\")\n",
    "\n",
    "# Validate training set\n",
    "train_images_dir = \"/kaggle/working/sccos_dota/train/images\"\n",
    "train_labels_dir = \"/kaggle/working/sccos_dota/train/labels\"\n",
    "print(\"Validating training images...\")\n",
    "validate_images(train_images_dir, train_labels_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c9fbec4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T14:06:31.459826Z",
     "iopub.status.busy": "2025-06-13T14:06:31.459349Z",
     "iopub.status.idle": "2025-06-13T14:06:31.466924Z",
     "shell.execute_reply": "2025-06-13T14:06:31.466025Z"
    },
    "papermill": {
     "duration": 0.049391,
     "end_time": "2025-06-13T14:06:31.468273",
     "exception": false,
     "start_time": "2025-06-13T14:06:31.418882",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating configuration file...\n",
      "s2a-netconfiguration saved to /kaggle/working/mmrotate/configs/s2anet/s2anet_r50_fpn_1x_sccos.py\n"
     ]
    }
   ],
   "source": [
    "# Create configuration file for S^2A-Net on SCCOS dataset (MMRotate 0.3.4)\n",
    "def create_config():\n",
    "    print(\"Creating configuration file...\")\n",
    "    config_dir = \"/kaggle/working/mmrotate/configs/s2anet\"\n",
    "    os.makedirs(config_dir, exist_ok=True)\n",
    "    config_path = os.path.join(config_dir, \"s2anet_r50_fpn_1x_sccos.py\")\n",
    "    config_content = \"\"\"\n",
    "_base_ = [\n",
    "    '../_base_/datasets/dotav1.py',\n",
    "    '../_base_/schedules/schedule_1x.py',\n",
    "    '../_base_/default_runtime.py'\n",
    "]\n",
    "\n",
    "angle_version = 'le135'\n",
    "model = dict(\n",
    "    type='S2ANet',\n",
    "    backbone=dict(\n",
    "        type='ResNet',\n",
    "        depth=50,\n",
    "        num_stages=4,\n",
    "        out_indices=(0, 1, 2, 3),\n",
    "        frozen_stages=1,\n",
    "        zero_init_residual=False,\n",
    "        norm_cfg=dict(type='BN', requires_grad=True),\n",
    "        norm_eval=True,\n",
    "        style='pytorch',\n",
    "        init_cfg=dict(type='Pretrained', checkpoint='torchvision://resnet50')),\n",
    "    neck=dict(\n",
    "        type='FPN',\n",
    "        in_channels=[256, 512, 1024, 2048],\n",
    "        out_channels=256,\n",
    "        start_level=1,\n",
    "        add_extra_convs='on_input',\n",
    "        num_outs=5),\n",
    "    fam_head=dict(\n",
    "        type='RotatedRetinaHead',\n",
    "        num_classes=1,\n",
    "        in_channels=256,\n",
    "        stacked_convs=2,\n",
    "        feat_channels=256,\n",
    "        assign_by_circumhbbox=None,\n",
    "        anchor_generator=dict(\n",
    "            type='RotatedAnchorGenerator',\n",
    "            scales=[4],\n",
    "            ratios=[1.0],\n",
    "            strides=[8, 16, 32, 64, 128]),\n",
    "        bbox_coder=dict(\n",
    "            type='DeltaXYWHAOBBoxCoder',\n",
    "            angle_range='le135',\n",
    "            norm_factor=1,\n",
    "            edge_swap=False,\n",
    "            proj_xy=True,\n",
    "            target_means=(0.0, 0.0, 0.0, 0.0, 0.0),\n",
    "            target_stds=(1.0, 1.0, 1.0, 1.0, 1.0)),\n",
    "        loss_cls=dict(\n",
    "            type='FocalLoss',\n",
    "            use_sigmoid=True,\n",
    "            gamma=2.0,\n",
    "            alpha=0.25,\n",
    "            loss_weight=1.0),\n",
    "        loss_bbox=dict(type='SmoothL1Loss', beta=0.11, loss_weight=1.0)),\n",
    "    align_cfgs=dict(\n",
    "        type='AlignConv',\n",
    "        kernel_size=3,\n",
    "        channels=256,\n",
    "        featmap_strides=[8, 16, 32, 64, 128]),\n",
    "    odm_head=dict(\n",
    "        type='ODMRefineHead',\n",
    "        num_classes=1,\n",
    "        in_channels=256,\n",
    "        stacked_convs=2,\n",
    "        feat_channels=256,\n",
    "        assign_by_circumhbbox=None,\n",
    "        anchor_generator=dict(\n",
    "            type='PseudoAnchorGenerator', strides=[8, 16, 32, 64, 128]),\n",
    "        bbox_coder=dict(\n",
    "            type='DeltaXYWHAOBBoxCoder',\n",
    "            angle_range='le135',\n",
    "            norm_factor=1,\n",
    "            edge_swap=False,\n",
    "            proj_xy=True,\n",
    "            target_means=(0.0, 0.0, 0.0, 0.0, 0.0),\n",
    "            target_stds=(1.0, 1.0, 1.0, 1.0, 1.0)),\n",
    "        loss_cls=dict(\n",
    "            type='FocalLoss',\n",
    "            use_sigmoid=True,\n",
    "            gamma=2.0,\n",
    "            alpha=0.25,\n",
    "            loss_weight=1.0),\n",
    "        loss_bbox=dict(type='SmoothL1Loss', beta=0.11, loss_weight=1.0)),\n",
    "    train_cfg=dict(\n",
    "        fam_cfg=dict(\n",
    "            assigner=dict(\n",
    "                type='MaxIoUAssigner',\n",
    "                pos_iou_thr=0.5,\n",
    "                neg_iou_thr=0.4,\n",
    "                min_pos_iou=0,\n",
    "                ignore_iof_thr=-1,\n",
    "                iou_calculator=dict(type='RBboxOverlaps2D')),\n",
    "            allowed_border=-1,\n",
    "            pos_weight=-1,\n",
    "            debug=False),\n",
    "        odm_cfg=dict(\n",
    "            assigner=dict(\n",
    "                type='MaxIoUAssigner',\n",
    "                pos_iou_thr=0.5,\n",
    "                neg_iou_thr=0.4,\n",
    "                min_pos_iou=0,\n",
    "                ignore_iof_thr=-1,\n",
    "                iou_calculator=dict(type='RBboxOverlaps2D')),\n",
    "            allowed_border=-1,\n",
    "            pos_weight=-1,\n",
    "            debug=False)),\n",
    "    test_cfg=dict(\n",
    "        nms_pre=2000,\n",
    "        min_bbox_size=0,\n",
    "        score_thr=0.05,\n",
    "        nms=dict(iou_thr=0.1),\n",
    "        max_per_img=2000))\n",
    "\n",
    "dataset_type = 'DOTADataset'\n",
    "data_root = '/kaggle/working/sccos_dota/'\n",
    "classes = ('ship',)  # Explicitly define classes\n",
    "img_norm_cfg = dict(\n",
    "    mean=[123.675, 116.28, 103.53],\n",
    "    std=[58.395, 57.12, 57.375],\n",
    "    to_rgb=True)\n",
    "train_pipeline = [\n",
    "    dict(type='LoadImageFromFile'),\n",
    "    dict(type='LoadAnnotations', with_bbox=True),\n",
    "    dict(type='RResize', img_scale=(1024, 1024)),\n",
    "    dict(\n",
    "        type='RRandomFlip',\n",
    "        flip_ratio=[0.25, 0.25, 0.25],\n",
    "        direction=['horizontal', 'vertical', 'diagonal'],\n",
    "        version='le135'),\n",
    "    dict(type='Normalize', **img_norm_cfg),\n",
    "    dict(type='Pad', size_divisor=32),\n",
    "    dict(type='DefaultFormatBundle'),\n",
    "    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n",
    "]\n",
    "test_pipeline = [\n",
    "    dict(type='LoadImageFromFile'),\n",
    "    dict(\n",
    "        type='MultiScaleFlipAug',\n",
    "        img_scale=(1024, 1024),\n",
    "        flip=False,\n",
    "        transforms=[\n",
    "            dict(type='RResize'),\n",
    "            dict(type='Normalize', **img_norm_cfg),\n",
    "            dict(type='Pad', size_divisor=32),\n",
    "            dict(type='DefaultFormatBundle'),\n",
    "            dict(type='Collect', keys=['img'])\n",
    "        ])\n",
    "]\n",
    "data = dict(\n",
    "    samples_per_gpu=2,\n",
    "    workers_per_gpu=2,\n",
    "    train=dict(\n",
    "        type=dataset_type,\n",
    "        ann_file=data_root + 'train/labels/',\n",
    "        img_prefix=data_root + 'train/images/',\n",
    "        pipeline=train_pipeline,\n",
    "        version='le135',\n",
    "        classes=('ship',)),\n",
    "    val=dict(\n",
    "        type=dataset_type,\n",
    "        ann_file=data_root + 'val/labels/',\n",
    "        img_prefix=data_root + 'val/images/',\n",
    "        pipeline=test_pipeline,\n",
    "        version='le135',\n",
    "        classes=('ship',)),\n",
    "    test=dict(\n",
    "        type=dataset_type,\n",
    "        ann_file=data_root + 'test/labels/',\n",
    "        img_prefix=data_root + 'test/images/',\n",
    "        pipeline=test_pipeline,\n",
    "        version='le135',\n",
    "        classes=('ship',)))\n",
    "evaluation = dict(interval=1, metric='mAP')\n",
    "runner = dict(type='EpochBasedRunner', max_epochs=2)\n",
    "\"\"\"\n",
    "    with open(config_path, 'w') as f:\n",
    "        f.write(config_content)\n",
    "    return config_path\n",
    "\n",
    "config_path = create_config()\n",
    "print(f\"s2a-netconfiguration saved to {config_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "073f297e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T14:06:31.548789Z",
     "iopub.status.busy": "2025-06-13T14:06:31.548517Z",
     "iopub.status.idle": "2025-06-13T14:34:04.387285Z",
     "shell.execute_reply": "2025-06-13T14:34:04.386134Z"
    },
    "papermill": {
     "duration": 1652.8809,
     "end_time": "2025-06-13T14:34:04.388977",
     "exception": false,
     "start_time": "2025-06-13T14:06:31.508077",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/mmrotate\n",
      "/usr/local/lib/python3.10/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 2.0.8 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\r\n",
      "  check_for_updates()\r\n",
      "/kaggle/working/mmrotate/mmrotate/utils/setup_env.py:38: UserWarning: Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.\r\n",
      "  warnings.warn(\r\n",
      "/kaggle/working/mmrotate/mmrotate/utils/setup_env.py:48: UserWarning: Setting MKL_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.\r\n",
      "  warnings.warn(\r\n",
      "2025-06-13 14:06:39,408 - mmrotate - INFO - Environment info:\r\n",
      "------------------------------------------------------------\r\n",
      "sys.platform: linux\r\n",
      "Python: 3.10.12 (main, Nov  6 2024, 20:22:13) [GCC 11.4.0]\r\n",
      "CUDA available: True\r\n",
      "GPU 0: Tesla P100-PCIE-16GB\r\n",
      "CUDA_HOME: /usr/local/cuda\r\n",
      "NVCC: Cuda compilation tools, release 12.2, V12.2.140\r\n",
      "GCC: x86_64-linux-gnu-gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\r\n",
      "PyTorch: 1.13.1+cu116\r\n",
      "PyTorch compiling details: PyTorch built with:\r\n",
      "  - GCC 9.3\r\n",
      "  - C++ Version: 201402\r\n",
      "  - Intel(R) oneAPI Math Kernel Library Version 2025.0.1-Product Build 20241031 for Intel(R) 64 architecture applications\r\n",
      "  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)\r\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\r\n",
      "  - LAPACK is enabled (usually provided by MKL)\r\n",
      "  - NNPACK is enabled\r\n",
      "  - CPU capability usage: AVX2\r\n",
      "  - CUDA Runtime 11.6\r\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\r\n",
      "  - CuDNN 8.3.2  (built against CUDA 11.5)\r\n",
      "  - Magma 2.6.1\r\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.6, CUDNN_VERSION=8.3.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.13.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \r\n",
      "\r\n",
      "TorchVision: 0.14.1+cu116\r\n",
      "OpenCV: 4.10.0\r\n",
      "MMCV: 1.7.1\r\n",
      "MMCV Compiler: GCC 9.3\r\n",
      "MMCV CUDA Compiler: 11.6\r\n",
      "MMRotate: 0.3.4+b030f38\r\n",
      "------------------------------------------------------------\r\n",
      "\r\n",
      "2025-06-13 14:06:39,738 - mmrotate - INFO - Distributed training: False\r\n",
      "2025-06-13 14:06:39,949 - mmrotate - INFO - Config:\r\n",
      "dataset_type = 'DOTADataset'\r\n",
      "data_root = '/kaggle/working/sccos_dota/'\r\n",
      "img_norm_cfg = dict(\r\n",
      "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\r\n",
      "train_pipeline = [\r\n",
      "    dict(type='LoadImageFromFile'),\r\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\r\n",
      "    dict(type='RResize', img_scale=(1024, 1024)),\r\n",
      "    dict(\r\n",
      "        type='RRandomFlip',\r\n",
      "        flip_ratio=[0.25, 0.25, 0.25],\r\n",
      "        direction=['horizontal', 'vertical', 'diagonal'],\r\n",
      "        version='le135'),\r\n",
      "    dict(\r\n",
      "        type='Normalize',\r\n",
      "        mean=[123.675, 116.28, 103.53],\r\n",
      "        std=[58.395, 57.12, 57.375],\r\n",
      "        to_rgb=True),\r\n",
      "    dict(type='Pad', size_divisor=32),\r\n",
      "    dict(type='DefaultFormatBundle'),\r\n",
      "    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\r\n",
      "]\r\n",
      "test_pipeline = [\r\n",
      "    dict(type='LoadImageFromFile'),\r\n",
      "    dict(\r\n",
      "        type='MultiScaleFlipAug',\r\n",
      "        img_scale=(1024, 1024),\r\n",
      "        flip=False,\r\n",
      "        transforms=[\r\n",
      "            dict(type='RResize'),\r\n",
      "            dict(\r\n",
      "                type='Normalize',\r\n",
      "                mean=[123.675, 116.28, 103.53],\r\n",
      "                std=[58.395, 57.12, 57.375],\r\n",
      "                to_rgb=True),\r\n",
      "            dict(type='Pad', size_divisor=32),\r\n",
      "            dict(type='DefaultFormatBundle'),\r\n",
      "            dict(type='Collect', keys=['img'])\r\n",
      "        ])\r\n",
      "]\r\n",
      "data = dict(\r\n",
      "    samples_per_gpu=2,\r\n",
      "    workers_per_gpu=2,\r\n",
      "    train=dict(\r\n",
      "        type='DOTADataset',\r\n",
      "        ann_file='/kaggle/working/sccos_dota/train/labels/',\r\n",
      "        img_prefix='/kaggle/working/sccos_dota/train/images/',\r\n",
      "        pipeline=[\r\n",
      "            dict(type='LoadImageFromFile'),\r\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\r\n",
      "            dict(type='RResize', img_scale=(1024, 1024)),\r\n",
      "            dict(\r\n",
      "                type='RRandomFlip',\r\n",
      "                flip_ratio=[0.25, 0.25, 0.25],\r\n",
      "                direction=['horizontal', 'vertical', 'diagonal'],\r\n",
      "                version='le135'),\r\n",
      "            dict(\r\n",
      "                type='Normalize',\r\n",
      "                mean=[123.675, 116.28, 103.53],\r\n",
      "                std=[58.395, 57.12, 57.375],\r\n",
      "                to_rgb=True),\r\n",
      "            dict(type='Pad', size_divisor=32),\r\n",
      "            dict(type='DefaultFormatBundle'),\r\n",
      "            dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\r\n",
      "        ],\r\n",
      "        version='le135',\r\n",
      "        classes=('ship', )),\r\n",
      "    val=dict(\r\n",
      "        type='DOTADataset',\r\n",
      "        ann_file='/kaggle/working/sccos_dota/val/labels/',\r\n",
      "        img_prefix='/kaggle/working/sccos_dota/val/images/',\r\n",
      "        pipeline=[\r\n",
      "            dict(type='LoadImageFromFile'),\r\n",
      "            dict(\r\n",
      "                type='MultiScaleFlipAug',\r\n",
      "                img_scale=(1024, 1024),\r\n",
      "                flip=False,\r\n",
      "                transforms=[\r\n",
      "                    dict(type='RResize'),\r\n",
      "                    dict(\r\n",
      "                        type='Normalize',\r\n",
      "                        mean=[123.675, 116.28, 103.53],\r\n",
      "                        std=[58.395, 57.12, 57.375],\r\n",
      "                        to_rgb=True),\r\n",
      "                    dict(type='Pad', size_divisor=32),\r\n",
      "                    dict(type='DefaultFormatBundle'),\r\n",
      "                    dict(type='Collect', keys=['img'])\r\n",
      "                ])\r\n",
      "        ],\r\n",
      "        version='le135',\r\n",
      "        classes=('ship', )),\r\n",
      "    test=dict(\r\n",
      "        type='DOTADataset',\r\n",
      "        ann_file='/kaggle/working/sccos_dota/test/labels/',\r\n",
      "        img_prefix='/kaggle/working/sccos_dota/test/images/',\r\n",
      "        pipeline=[\r\n",
      "            dict(type='LoadImageFromFile'),\r\n",
      "            dict(\r\n",
      "                type='MultiScaleFlipAug',\r\n",
      "                img_scale=(1024, 1024),\r\n",
      "                flip=False,\r\n",
      "                transforms=[\r\n",
      "                    dict(type='RResize'),\r\n",
      "                    dict(\r\n",
      "                        type='Normalize',\r\n",
      "                        mean=[123.675, 116.28, 103.53],\r\n",
      "                        std=[58.395, 57.12, 57.375],\r\n",
      "                        to_rgb=True),\r\n",
      "                    dict(type='Pad', size_divisor=32),\r\n",
      "                    dict(type='DefaultFormatBundle'),\r\n",
      "                    dict(type='Collect', keys=['img'])\r\n",
      "                ])\r\n",
      "        ],\r\n",
      "        version='le135',\r\n",
      "        classes=('ship', )))\r\n",
      "evaluation = dict(interval=1, metric='mAP')\r\n",
      "optimizer = dict(type='SGD', lr=0.0025, momentum=0.9, weight_decay=0.0001)\r\n",
      "optimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))\r\n",
      "lr_config = dict(\r\n",
      "    policy='step',\r\n",
      "    warmup='linear',\r\n",
      "    warmup_iters=500,\r\n",
      "    warmup_ratio=0.3333333333333333,\r\n",
      "    step=[8, 11])\r\n",
      "runner = dict(type='EpochBasedRunner', max_epochs=2)\r\n",
      "checkpoint_config = dict(interval=1)\r\n",
      "log_config = dict(interval=50, hooks=[dict(type='TextLoggerHook')])\r\n",
      "dist_params = dict(backend='nccl')\r\n",
      "log_level = 'INFO'\r\n",
      "load_from = None\r\n",
      "resume_from = None\r\n",
      "workflow = [('train', 1)]\r\n",
      "opencv_num_threads = 0\r\n",
      "mp_start_method = 'fork'\r\n",
      "angle_version = 'le135'\r\n",
      "model = dict(\r\n",
      "    type='S2ANet',\r\n",
      "    backbone=dict(\r\n",
      "        type='ResNet',\r\n",
      "        depth=50,\r\n",
      "        num_stages=4,\r\n",
      "        out_indices=(0, 1, 2, 3),\r\n",
      "        frozen_stages=1,\r\n",
      "        zero_init_residual=False,\r\n",
      "        norm_cfg=dict(type='BN', requires_grad=True),\r\n",
      "        norm_eval=True,\r\n",
      "        style='pytorch',\r\n",
      "        init_cfg=dict(type='Pretrained', checkpoint='torchvision://resnet50')),\r\n",
      "    neck=dict(\r\n",
      "        type='FPN',\r\n",
      "        in_channels=[256, 512, 1024, 2048],\r\n",
      "        out_channels=256,\r\n",
      "        start_level=1,\r\n",
      "        add_extra_convs='on_input',\r\n",
      "        num_outs=5),\r\n",
      "    fam_head=dict(\r\n",
      "        type='RotatedRetinaHead',\r\n",
      "        num_classes=1,\r\n",
      "        in_channels=256,\r\n",
      "        stacked_convs=2,\r\n",
      "        feat_channels=256,\r\n",
      "        assign_by_circumhbbox=None,\r\n",
      "        anchor_generator=dict(\r\n",
      "            type='RotatedAnchorGenerator',\r\n",
      "            scales=[4],\r\n",
      "            ratios=[1.0],\r\n",
      "            strides=[8, 16, 32, 64, 128]),\r\n",
      "        bbox_coder=dict(\r\n",
      "            type='DeltaXYWHAOBBoxCoder',\r\n",
      "            angle_range='le135',\r\n",
      "            norm_factor=1,\r\n",
      "            edge_swap=False,\r\n",
      "            proj_xy=True,\r\n",
      "            target_means=(0.0, 0.0, 0.0, 0.0, 0.0),\r\n",
      "            target_stds=(1.0, 1.0, 1.0, 1.0, 1.0)),\r\n",
      "        loss_cls=dict(\r\n",
      "            type='FocalLoss',\r\n",
      "            use_sigmoid=True,\r\n",
      "            gamma=2.0,\r\n",
      "            alpha=0.25,\r\n",
      "            loss_weight=1.0),\r\n",
      "        loss_bbox=dict(type='SmoothL1Loss', beta=0.11, loss_weight=1.0)),\r\n",
      "    align_cfgs=dict(\r\n",
      "        type='AlignConv',\r\n",
      "        kernel_size=3,\r\n",
      "        channels=256,\r\n",
      "        featmap_strides=[8, 16, 32, 64, 128]),\r\n",
      "    odm_head=dict(\r\n",
      "        type='ODMRefineHead',\r\n",
      "        num_classes=1,\r\n",
      "        in_channels=256,\r\n",
      "        stacked_convs=2,\r\n",
      "        feat_channels=256,\r\n",
      "        assign_by_circumhbbox=None,\r\n",
      "        anchor_generator=dict(\r\n",
      "            type='PseudoAnchorGenerator', strides=[8, 16, 32, 64, 128]),\r\n",
      "        bbox_coder=dict(\r\n",
      "            type='DeltaXYWHAOBBoxCoder',\r\n",
      "            angle_range='le135',\r\n",
      "            norm_factor=1,\r\n",
      "            edge_swap=False,\r\n",
      "            proj_xy=True,\r\n",
      "            target_means=(0.0, 0.0, 0.0, 0.0, 0.0),\r\n",
      "            target_stds=(1.0, 1.0, 1.0, 1.0, 1.0)),\r\n",
      "        loss_cls=dict(\r\n",
      "            type='FocalLoss',\r\n",
      "            use_sigmoid=True,\r\n",
      "            gamma=2.0,\r\n",
      "            alpha=0.25,\r\n",
      "            loss_weight=1.0),\r\n",
      "        loss_bbox=dict(type='SmoothL1Loss', beta=0.11, loss_weight=1.0)),\r\n",
      "    train_cfg=dict(\r\n",
      "        fam_cfg=dict(\r\n",
      "            assigner=dict(\r\n",
      "                type='MaxIoUAssigner',\r\n",
      "                pos_iou_thr=0.5,\r\n",
      "                neg_iou_thr=0.4,\r\n",
      "                min_pos_iou=0,\r\n",
      "                ignore_iof_thr=-1,\r\n",
      "                iou_calculator=dict(type='RBboxOverlaps2D')),\r\n",
      "            allowed_border=-1,\r\n",
      "            pos_weight=-1,\r\n",
      "            debug=False),\r\n",
      "        odm_cfg=dict(\r\n",
      "            assigner=dict(\r\n",
      "                type='MaxIoUAssigner',\r\n",
      "                pos_iou_thr=0.5,\r\n",
      "                neg_iou_thr=0.4,\r\n",
      "                min_pos_iou=0,\r\n",
      "                ignore_iof_thr=-1,\r\n",
      "                iou_calculator=dict(type='RBboxOverlaps2D')),\r\n",
      "            allowed_border=-1,\r\n",
      "            pos_weight=-1,\r\n",
      "            debug=False)),\r\n",
      "    test_cfg=dict(\r\n",
      "        nms_pre=2000,\r\n",
      "        min_bbox_size=0,\r\n",
      "        score_thr=0.05,\r\n",
      "        nms=dict(iou_thr=0.1),\r\n",
      "        max_per_img=2000))\r\n",
      "classes = ('ship', )\r\n",
      "work_dir = '/kaggle/working/runs/s2anet_train'\r\n",
      "auto_resume = False\r\n",
      "gpu_ids = range(0, 1)\r\n",
      "\r\n",
      "2025-06-13 14:06:39,951 - mmrotate - INFO - Set random seed to 2066868010, deterministic: False\r\n",
      "2025-06-13 14:06:40,396 - mmcv - INFO - initialize ResNet with init_cfg {'type': 'Pretrained', 'checkpoint': 'torchvision://resnet50'}\r\n",
      "2025-06-13 14:06:40,396 - mmcv - INFO - load model from: torchvision://resnet50\r\n",
      "2025-06-13 14:06:40,396 - mmcv - INFO - load checkpoint from torchvision path: torchvision://resnet50\r\n",
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\r\n",
      "100%|███████████████████████████████████████| 97.8M/97.8M [00:00<00:00, 293MB/s]\r\n",
      "2025-06-13 14:06:41,046 - mmcv - WARNING - The model and loaded state dict do not match exactly\r\n",
      "\r\n",
      "unexpected key in source state_dict: fc.weight, fc.bias\r\n",
      "\r\n",
      "2025-06-13 14:06:41,068 - mmcv - INFO - initialize FPN with init_cfg {'type': 'Xavier', 'layer': 'Conv2d', 'distribution': 'uniform'}\r\n",
      "2025-06-13 14:06:41,120 - mmcv - INFO - initialize RotatedRetinaHead with init_cfg {'type': 'Normal', 'layer': 'Conv2d', 'std': 0.01, 'override': {'type': 'Normal', 'name': 'retina_cls', 'std': 0.01, 'bias_prob': 0.01}}\r\n",
      "2025-06-13 14:06:41,137 - mmcv - INFO - initialize ODMRefineHead with init_cfg {'type': 'Normal', 'layer': 'Conv2d', 'std': 0.01, 'override': {'type': 'Normal', 'name': 'odm_cls', 'std': 0.01, 'bias_prob': 0.01}}\r\n",
      "2025-06-13 14:06:41,152 - mmcv - INFO - \r\n",
      "backbone.conv1.weight - torch.Size([64, 3, 7, 7]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,152 - mmcv - INFO - \r\n",
      "backbone.bn1.weight - torch.Size([64]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,152 - mmcv - INFO - \r\n",
      "backbone.bn1.bias - torch.Size([64]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,152 - mmcv - INFO - \r\n",
      "backbone.layer1.0.conv1.weight - torch.Size([64, 64, 1, 1]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,152 - mmcv - INFO - \r\n",
      "backbone.layer1.0.bn1.weight - torch.Size([64]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,152 - mmcv - INFO - \r\n",
      "backbone.layer1.0.bn1.bias - torch.Size([64]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,152 - mmcv - INFO - \r\n",
      "backbone.layer1.0.conv2.weight - torch.Size([64, 64, 3, 3]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,152 - mmcv - INFO - \r\n",
      "backbone.layer1.0.bn2.weight - torch.Size([64]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,152 - mmcv - INFO - \r\n",
      "backbone.layer1.0.bn2.bias - torch.Size([64]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,153 - mmcv - INFO - \r\n",
      "backbone.layer1.0.conv3.weight - torch.Size([256, 64, 1, 1]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,153 - mmcv - INFO - \r\n",
      "backbone.layer1.0.bn3.weight - torch.Size([256]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,153 - mmcv - INFO - \r\n",
      "backbone.layer1.0.bn3.bias - torch.Size([256]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,153 - mmcv - INFO - \r\n",
      "backbone.layer1.0.downsample.0.weight - torch.Size([256, 64, 1, 1]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,153 - mmcv - INFO - \r\n",
      "backbone.layer1.0.downsample.1.weight - torch.Size([256]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,153 - mmcv - INFO - \r\n",
      "backbone.layer1.0.downsample.1.bias - torch.Size([256]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,153 - mmcv - INFO - \r\n",
      "backbone.layer1.1.conv1.weight - torch.Size([64, 256, 1, 1]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,153 - mmcv - INFO - \r\n",
      "backbone.layer1.1.bn1.weight - torch.Size([64]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,153 - mmcv - INFO - \r\n",
      "backbone.layer1.1.bn1.bias - torch.Size([64]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,153 - mmcv - INFO - \r\n",
      "backbone.layer1.1.conv2.weight - torch.Size([64, 64, 3, 3]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,153 - mmcv - INFO - \r\n",
      "backbone.layer1.1.bn2.weight - torch.Size([64]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,153 - mmcv - INFO - \r\n",
      "backbone.layer1.1.bn2.bias - torch.Size([64]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,153 - mmcv - INFO - \r\n",
      "backbone.layer1.1.conv3.weight - torch.Size([256, 64, 1, 1]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,154 - mmcv - INFO - \r\n",
      "backbone.layer1.1.bn3.weight - torch.Size([256]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,154 - mmcv - INFO - \r\n",
      "backbone.layer1.1.bn3.bias - torch.Size([256]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,154 - mmcv - INFO - \r\n",
      "backbone.layer1.2.conv1.weight - torch.Size([64, 256, 1, 1]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,154 - mmcv - INFO - \r\n",
      "backbone.layer1.2.bn1.weight - torch.Size([64]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,154 - mmcv - INFO - \r\n",
      "backbone.layer1.2.bn1.bias - torch.Size([64]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,154 - mmcv - INFO - \r\n",
      "backbone.layer1.2.conv2.weight - torch.Size([64, 64, 3, 3]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,154 - mmcv - INFO - \r\n",
      "backbone.layer1.2.bn2.weight - torch.Size([64]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,154 - mmcv - INFO - \r\n",
      "backbone.layer1.2.bn2.bias - torch.Size([64]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,154 - mmcv - INFO - \r\n",
      "backbone.layer1.2.conv3.weight - torch.Size([256, 64, 1, 1]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,154 - mmcv - INFO - \r\n",
      "backbone.layer1.2.bn3.weight - torch.Size([256]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,154 - mmcv - INFO - \r\n",
      "backbone.layer1.2.bn3.bias - torch.Size([256]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,154 - mmcv - INFO - \r\n",
      "backbone.layer2.0.conv1.weight - torch.Size([128, 256, 1, 1]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,154 - mmcv - INFO - \r\n",
      "backbone.layer2.0.bn1.weight - torch.Size([128]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,155 - mmcv - INFO - \r\n",
      "backbone.layer2.0.bn1.bias - torch.Size([128]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,155 - mmcv - INFO - \r\n",
      "backbone.layer2.0.conv2.weight - torch.Size([128, 128, 3, 3]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,155 - mmcv - INFO - \r\n",
      "backbone.layer2.0.bn2.weight - torch.Size([128]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,155 - mmcv - INFO - \r\n",
      "backbone.layer2.0.bn2.bias - torch.Size([128]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,155 - mmcv - INFO - \r\n",
      "backbone.layer2.0.conv3.weight - torch.Size([512, 128, 1, 1]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,155 - mmcv - INFO - \r\n",
      "backbone.layer2.0.bn3.weight - torch.Size([512]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,155 - mmcv - INFO - \r\n",
      "backbone.layer2.0.bn3.bias - torch.Size([512]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,155 - mmcv - INFO - \r\n",
      "backbone.layer2.0.downsample.0.weight - torch.Size([512, 256, 1, 1]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,155 - mmcv - INFO - \r\n",
      "backbone.layer2.0.downsample.1.weight - torch.Size([512]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,155 - mmcv - INFO - \r\n",
      "backbone.layer2.0.downsample.1.bias - torch.Size([512]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,155 - mmcv - INFO - \r\n",
      "backbone.layer2.1.conv1.weight - torch.Size([128, 512, 1, 1]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,155 - mmcv - INFO - \r\n",
      "backbone.layer2.1.bn1.weight - torch.Size([128]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,155 - mmcv - INFO - \r\n",
      "backbone.layer2.1.bn1.bias - torch.Size([128]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,156 - mmcv - INFO - \r\n",
      "backbone.layer2.1.conv2.weight - torch.Size([128, 128, 3, 3]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,156 - mmcv - INFO - \r\n",
      "backbone.layer2.1.bn2.weight - torch.Size([128]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,156 - mmcv - INFO - \r\n",
      "backbone.layer2.1.bn2.bias - torch.Size([128]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,156 - mmcv - INFO - \r\n",
      "backbone.layer2.1.conv3.weight - torch.Size([512, 128, 1, 1]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,156 - mmcv - INFO - \r\n",
      "backbone.layer2.1.bn3.weight - torch.Size([512]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,156 - mmcv - INFO - \r\n",
      "backbone.layer2.1.bn3.bias - torch.Size([512]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,156 - mmcv - INFO - \r\n",
      "backbone.layer2.2.conv1.weight - torch.Size([128, 512, 1, 1]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,156 - mmcv - INFO - \r\n",
      "backbone.layer2.2.bn1.weight - torch.Size([128]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,156 - mmcv - INFO - \r\n",
      "backbone.layer2.2.bn1.bias - torch.Size([128]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,156 - mmcv - INFO - \r\n",
      "backbone.layer2.2.conv2.weight - torch.Size([128, 128, 3, 3]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,156 - mmcv - INFO - \r\n",
      "backbone.layer2.2.bn2.weight - torch.Size([128]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,156 - mmcv - INFO - \r\n",
      "backbone.layer2.2.bn2.bias - torch.Size([128]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,156 - mmcv - INFO - \r\n",
      "backbone.layer2.2.conv3.weight - torch.Size([512, 128, 1, 1]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,156 - mmcv - INFO - \r\n",
      "backbone.layer2.2.bn3.weight - torch.Size([512]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,157 - mmcv - INFO - \r\n",
      "backbone.layer2.2.bn3.bias - torch.Size([512]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,157 - mmcv - INFO - \r\n",
      "backbone.layer2.3.conv1.weight - torch.Size([128, 512, 1, 1]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,157 - mmcv - INFO - \r\n",
      "backbone.layer2.3.bn1.weight - torch.Size([128]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,157 - mmcv - INFO - \r\n",
      "backbone.layer2.3.bn1.bias - torch.Size([128]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,157 - mmcv - INFO - \r\n",
      "backbone.layer2.3.conv2.weight - torch.Size([128, 128, 3, 3]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,157 - mmcv - INFO - \r\n",
      "backbone.layer2.3.bn2.weight - torch.Size([128]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,157 - mmcv - INFO - \r\n",
      "backbone.layer2.3.bn2.bias - torch.Size([128]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,157 - mmcv - INFO - \r\n",
      "backbone.layer2.3.conv3.weight - torch.Size([512, 128, 1, 1]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,157 - mmcv - INFO - \r\n",
      "backbone.layer2.3.bn3.weight - torch.Size([512]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,157 - mmcv - INFO - \r\n",
      "backbone.layer2.3.bn3.bias - torch.Size([512]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,157 - mmcv - INFO - \r\n",
      "backbone.layer3.0.conv1.weight - torch.Size([256, 512, 1, 1]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,157 - mmcv - INFO - \r\n",
      "backbone.layer3.0.bn1.weight - torch.Size([256]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,157 - mmcv - INFO - \r\n",
      "backbone.layer3.0.bn1.bias - torch.Size([256]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,158 - mmcv - INFO - \r\n",
      "backbone.layer3.0.conv2.weight - torch.Size([256, 256, 3, 3]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,158 - mmcv - INFO - \r\n",
      "backbone.layer3.0.bn2.weight - torch.Size([256]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,158 - mmcv - INFO - \r\n",
      "backbone.layer3.0.bn2.bias - torch.Size([256]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,158 - mmcv - INFO - \r\n",
      "backbone.layer3.0.conv3.weight - torch.Size([1024, 256, 1, 1]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,158 - mmcv - INFO - \r\n",
      "backbone.layer3.0.bn3.weight - torch.Size([1024]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,158 - mmcv - INFO - \r\n",
      "backbone.layer3.0.bn3.bias - torch.Size([1024]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,158 - mmcv - INFO - \r\n",
      "backbone.layer3.0.downsample.0.weight - torch.Size([1024, 512, 1, 1]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,158 - mmcv - INFO - \r\n",
      "backbone.layer3.0.downsample.1.weight - torch.Size([1024]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,158 - mmcv - INFO - \r\n",
      "backbone.layer3.0.downsample.1.bias - torch.Size([1024]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,158 - mmcv - INFO - \r\n",
      "backbone.layer3.1.conv1.weight - torch.Size([256, 1024, 1, 1]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,158 - mmcv - INFO - \r\n",
      "backbone.layer3.1.bn1.weight - torch.Size([256]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,158 - mmcv - INFO - \r\n",
      "backbone.layer3.1.bn1.bias - torch.Size([256]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,158 - mmcv - INFO - \r\n",
      "backbone.layer3.1.conv2.weight - torch.Size([256, 256, 3, 3]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,159 - mmcv - INFO - \r\n",
      "backbone.layer3.1.bn2.weight - torch.Size([256]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,159 - mmcv - INFO - \r\n",
      "backbone.layer3.1.bn2.bias - torch.Size([256]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,159 - mmcv - INFO - \r\n",
      "backbone.layer3.1.conv3.weight - torch.Size([1024, 256, 1, 1]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,159 - mmcv - INFO - \r\n",
      "backbone.layer3.1.bn3.weight - torch.Size([1024]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,159 - mmcv - INFO - \r\n",
      "backbone.layer3.1.bn3.bias - torch.Size([1024]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,159 - mmcv - INFO - \r\n",
      "backbone.layer3.2.conv1.weight - torch.Size([256, 1024, 1, 1]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,159 - mmcv - INFO - \r\n",
      "backbone.layer3.2.bn1.weight - torch.Size([256]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,159 - mmcv - INFO - \r\n",
      "backbone.layer3.2.bn1.bias - torch.Size([256]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,159 - mmcv - INFO - \r\n",
      "backbone.layer3.2.conv2.weight - torch.Size([256, 256, 3, 3]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,159 - mmcv - INFO - \r\n",
      "backbone.layer3.2.bn2.weight - torch.Size([256]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,159 - mmcv - INFO - \r\n",
      "backbone.layer3.2.bn2.bias - torch.Size([256]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,159 - mmcv - INFO - \r\n",
      "backbone.layer3.2.conv3.weight - torch.Size([1024, 256, 1, 1]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,159 - mmcv - INFO - \r\n",
      "backbone.layer3.2.bn3.weight - torch.Size([1024]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,160 - mmcv - INFO - \r\n",
      "backbone.layer3.2.bn3.bias - torch.Size([1024]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,160 - mmcv - INFO - \r\n",
      "backbone.layer3.3.conv1.weight - torch.Size([256, 1024, 1, 1]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,160 - mmcv - INFO - \r\n",
      "backbone.layer3.3.bn1.weight - torch.Size([256]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,160 - mmcv - INFO - \r\n",
      "backbone.layer3.3.bn1.bias - torch.Size([256]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,160 - mmcv - INFO - \r\n",
      "backbone.layer3.3.conv2.weight - torch.Size([256, 256, 3, 3]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,160 - mmcv - INFO - \r\n",
      "backbone.layer3.3.bn2.weight - torch.Size([256]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,160 - mmcv - INFO - \r\n",
      "backbone.layer3.3.bn2.bias - torch.Size([256]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,160 - mmcv - INFO - \r\n",
      "backbone.layer3.3.conv3.weight - torch.Size([1024, 256, 1, 1]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,160 - mmcv - INFO - \r\n",
      "backbone.layer3.3.bn3.weight - torch.Size([1024]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,160 - mmcv - INFO - \r\n",
      "backbone.layer3.3.bn3.bias - torch.Size([1024]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,160 - mmcv - INFO - \r\n",
      "backbone.layer3.4.conv1.weight - torch.Size([256, 1024, 1, 1]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,160 - mmcv - INFO - \r\n",
      "backbone.layer3.4.bn1.weight - torch.Size([256]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,160 - mmcv - INFO - \r\n",
      "backbone.layer3.4.bn1.bias - torch.Size([256]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,161 - mmcv - INFO - \r\n",
      "backbone.layer3.4.conv2.weight - torch.Size([256, 256, 3, 3]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,161 - mmcv - INFO - \r\n",
      "backbone.layer3.4.bn2.weight - torch.Size([256]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,161 - mmcv - INFO - \r\n",
      "backbone.layer3.4.bn2.bias - torch.Size([256]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,161 - mmcv - INFO - \r\n",
      "backbone.layer3.4.conv3.weight - torch.Size([1024, 256, 1, 1]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,161 - mmcv - INFO - \r\n",
      "backbone.layer3.4.bn3.weight - torch.Size([1024]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,161 - mmcv - INFO - \r\n",
      "backbone.layer3.4.bn3.bias - torch.Size([1024]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,161 - mmcv - INFO - \r\n",
      "backbone.layer3.5.conv1.weight - torch.Size([256, 1024, 1, 1]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,161 - mmcv - INFO - \r\n",
      "backbone.layer3.5.bn1.weight - torch.Size([256]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,161 - mmcv - INFO - \r\n",
      "backbone.layer3.5.bn1.bias - torch.Size([256]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,161 - mmcv - INFO - \r\n",
      "backbone.layer3.5.conv2.weight - torch.Size([256, 256, 3, 3]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,161 - mmcv - INFO - \r\n",
      "backbone.layer3.5.bn2.weight - torch.Size([256]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,161 - mmcv - INFO - \r\n",
      "backbone.layer3.5.bn2.bias - torch.Size([256]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,161 - mmcv - INFO - \r\n",
      "backbone.layer3.5.conv3.weight - torch.Size([1024, 256, 1, 1]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,162 - mmcv - INFO - \r\n",
      "backbone.layer3.5.bn3.weight - torch.Size([1024]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,162 - mmcv - INFO - \r\n",
      "backbone.layer3.5.bn3.bias - torch.Size([1024]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,162 - mmcv - INFO - \r\n",
      "backbone.layer4.0.conv1.weight - torch.Size([512, 1024, 1, 1]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,162 - mmcv - INFO - \r\n",
      "backbone.layer4.0.bn1.weight - torch.Size([512]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,162 - mmcv - INFO - \r\n",
      "backbone.layer4.0.bn1.bias - torch.Size([512]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,162 - mmcv - INFO - \r\n",
      "backbone.layer4.0.conv2.weight - torch.Size([512, 512, 3, 3]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,162 - mmcv - INFO - \r\n",
      "backbone.layer4.0.bn2.weight - torch.Size([512]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,162 - mmcv - INFO - \r\n",
      "backbone.layer4.0.bn2.bias - torch.Size([512]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,162 - mmcv - INFO - \r\n",
      "backbone.layer4.0.conv3.weight - torch.Size([2048, 512, 1, 1]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,162 - mmcv - INFO - \r\n",
      "backbone.layer4.0.bn3.weight - torch.Size([2048]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,162 - mmcv - INFO - \r\n",
      "backbone.layer4.0.bn3.bias - torch.Size([2048]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,162 - mmcv - INFO - \r\n",
      "backbone.layer4.0.downsample.0.weight - torch.Size([2048, 1024, 1, 1]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,162 - mmcv - INFO - \r\n",
      "backbone.layer4.0.downsample.1.weight - torch.Size([2048]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,162 - mmcv - INFO - \r\n",
      "backbone.layer4.0.downsample.1.bias - torch.Size([2048]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,163 - mmcv - INFO - \r\n",
      "backbone.layer4.1.conv1.weight - torch.Size([512, 2048, 1, 1]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,163 - mmcv - INFO - \r\n",
      "backbone.layer4.1.bn1.weight - torch.Size([512]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,163 - mmcv - INFO - \r\n",
      "backbone.layer4.1.bn1.bias - torch.Size([512]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,163 - mmcv - INFO - \r\n",
      "backbone.layer4.1.conv2.weight - torch.Size([512, 512, 3, 3]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,163 - mmcv - INFO - \r\n",
      "backbone.layer4.1.bn2.weight - torch.Size([512]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,163 - mmcv - INFO - \r\n",
      "backbone.layer4.1.bn2.bias - torch.Size([512]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,163 - mmcv - INFO - \r\n",
      "backbone.layer4.1.conv3.weight - torch.Size([2048, 512, 1, 1]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,163 - mmcv - INFO - \r\n",
      "backbone.layer4.1.bn3.weight - torch.Size([2048]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,163 - mmcv - INFO - \r\n",
      "backbone.layer4.1.bn3.bias - torch.Size([2048]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,163 - mmcv - INFO - \r\n",
      "backbone.layer4.2.conv1.weight - torch.Size([512, 2048, 1, 1]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,163 - mmcv - INFO - \r\n",
      "backbone.layer4.2.bn1.weight - torch.Size([512]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,163 - mmcv - INFO - \r\n",
      "backbone.layer4.2.bn1.bias - torch.Size([512]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,163 - mmcv - INFO - \r\n",
      "backbone.layer4.2.conv2.weight - torch.Size([512, 512, 3, 3]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,164 - mmcv - INFO - \r\n",
      "backbone.layer4.2.bn2.weight - torch.Size([512]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,164 - mmcv - INFO - \r\n",
      "backbone.layer4.2.bn2.bias - torch.Size([512]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,164 - mmcv - INFO - \r\n",
      "backbone.layer4.2.conv3.weight - torch.Size([2048, 512, 1, 1]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,164 - mmcv - INFO - \r\n",
      "backbone.layer4.2.bn3.weight - torch.Size([2048]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,164 - mmcv - INFO - \r\n",
      "backbone.layer4.2.bn3.bias - torch.Size([2048]): \r\n",
      "PretrainedInit: load from torchvision://resnet50 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,164 - mmcv - INFO - \r\n",
      "neck.lateral_convs.0.conv.weight - torch.Size([256, 512, 1, 1]): \r\n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,164 - mmcv - INFO - \r\n",
      "neck.lateral_convs.0.conv.bias - torch.Size([256]): \r\n",
      "The value is the same before and after calling `init_weights` of S2ANet  \r\n",
      " \r\n",
      "2025-06-13 14:06:41,164 - mmcv - INFO - \r\n",
      "neck.lateral_convs.1.conv.weight - torch.Size([256, 1024, 1, 1]): \r\n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,164 - mmcv - INFO - \r\n",
      "neck.lateral_convs.1.conv.bias - torch.Size([256]): \r\n",
      "The value is the same before and after calling `init_weights` of S2ANet  \r\n",
      " \r\n",
      "2025-06-13 14:06:41,164 - mmcv - INFO - \r\n",
      "neck.lateral_convs.2.conv.weight - torch.Size([256, 2048, 1, 1]): \r\n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,164 - mmcv - INFO - \r\n",
      "neck.lateral_convs.2.conv.bias - torch.Size([256]): \r\n",
      "The value is the same before and after calling `init_weights` of S2ANet  \r\n",
      " \r\n",
      "2025-06-13 14:06:41,164 - mmcv - INFO - \r\n",
      "neck.fpn_convs.0.conv.weight - torch.Size([256, 256, 3, 3]): \r\n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,165 - mmcv - INFO - \r\n",
      "neck.fpn_convs.0.conv.bias - torch.Size([256]): \r\n",
      "The value is the same before and after calling `init_weights` of S2ANet  \r\n",
      " \r\n",
      "2025-06-13 14:06:41,165 - mmcv - INFO - \r\n",
      "neck.fpn_convs.1.conv.weight - torch.Size([256, 256, 3, 3]): \r\n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,165 - mmcv - INFO - \r\n",
      "neck.fpn_convs.1.conv.bias - torch.Size([256]): \r\n",
      "The value is the same before and after calling `init_weights` of S2ANet  \r\n",
      " \r\n",
      "2025-06-13 14:06:41,165 - mmcv - INFO - \r\n",
      "neck.fpn_convs.2.conv.weight - torch.Size([256, 256, 3, 3]): \r\n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,165 - mmcv - INFO - \r\n",
      "neck.fpn_convs.2.conv.bias - torch.Size([256]): \r\n",
      "The value is the same before and after calling `init_weights` of S2ANet  \r\n",
      " \r\n",
      "2025-06-13 14:06:41,165 - mmcv - INFO - \r\n",
      "neck.fpn_convs.3.conv.weight - torch.Size([256, 2048, 3, 3]): \r\n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,165 - mmcv - INFO - \r\n",
      "neck.fpn_convs.3.conv.bias - torch.Size([256]): \r\n",
      "The value is the same before and after calling `init_weights` of S2ANet  \r\n",
      " \r\n",
      "2025-06-13 14:06:41,165 - mmcv - INFO - \r\n",
      "neck.fpn_convs.4.conv.weight - torch.Size([256, 256, 3, 3]): \r\n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,165 - mmcv - INFO - \r\n",
      "neck.fpn_convs.4.conv.bias - torch.Size([256]): \r\n",
      "The value is the same before and after calling `init_weights` of S2ANet  \r\n",
      " \r\n",
      "2025-06-13 14:06:41,165 - mmcv - INFO - \r\n",
      "fam_head.cls_convs.0.conv.weight - torch.Size([256, 256, 3, 3]): \r\n",
      "NormalInit: mean=0, std=0.01, bias=0 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,165 - mmcv - INFO - \r\n",
      "fam_head.cls_convs.0.conv.bias - torch.Size([256]): \r\n",
      "The value is the same before and after calling `init_weights` of S2ANet  \r\n",
      " \r\n",
      "2025-06-13 14:06:41,165 - mmcv - INFO - \r\n",
      "fam_head.cls_convs.1.conv.weight - torch.Size([256, 256, 3, 3]): \r\n",
      "NormalInit: mean=0, std=0.01, bias=0 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,165 - mmcv - INFO - \r\n",
      "fam_head.cls_convs.1.conv.bias - torch.Size([256]): \r\n",
      "The value is the same before and after calling `init_weights` of S2ANet  \r\n",
      " \r\n",
      "2025-06-13 14:06:41,166 - mmcv - INFO - \r\n",
      "fam_head.reg_convs.0.conv.weight - torch.Size([256, 256, 3, 3]): \r\n",
      "NormalInit: mean=0, std=0.01, bias=0 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,166 - mmcv - INFO - \r\n",
      "fam_head.reg_convs.0.conv.bias - torch.Size([256]): \r\n",
      "The value is the same before and after calling `init_weights` of S2ANet  \r\n",
      " \r\n",
      "2025-06-13 14:06:41,166 - mmcv - INFO - \r\n",
      "fam_head.reg_convs.1.conv.weight - torch.Size([256, 256, 3, 3]): \r\n",
      "NormalInit: mean=0, std=0.01, bias=0 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,166 - mmcv - INFO - \r\n",
      "fam_head.reg_convs.1.conv.bias - torch.Size([256]): \r\n",
      "The value is the same before and after calling `init_weights` of S2ANet  \r\n",
      " \r\n",
      "2025-06-13 14:06:41,166 - mmcv - INFO - \r\n",
      "fam_head.retina_cls.weight - torch.Size([1, 256, 3, 3]): \r\n",
      "NormalInit: mean=0, std=0.01, bias=-4.59511985013459 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,166 - mmcv - INFO - \r\n",
      "fam_head.retina_cls.bias - torch.Size([1]): \r\n",
      "NormalInit: mean=0, std=0.01, bias=-4.59511985013459 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,166 - mmcv - INFO - \r\n",
      "fam_head.retina_reg.weight - torch.Size([5, 256, 3, 3]): \r\n",
      "NormalInit: mean=0, std=0.01, bias=0 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,166 - mmcv - INFO - \r\n",
      "fam_head.retina_reg.bias - torch.Size([5]): \r\n",
      "NormalInit: mean=0, std=0.01, bias=0 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,166 - mmcv - INFO - \r\n",
      "align_conv.ac.0.deform_conv.weight - torch.Size([256, 256, 3, 3]): \r\n",
      "The value is the same before and after calling `init_weights` of S2ANet  \r\n",
      " \r\n",
      "2025-06-13 14:06:41,166 - mmcv - INFO - \r\n",
      "align_conv.ac.1.deform_conv.weight - torch.Size([256, 256, 3, 3]): \r\n",
      "The value is the same before and after calling `init_weights` of S2ANet  \r\n",
      " \r\n",
      "2025-06-13 14:06:41,166 - mmcv - INFO - \r\n",
      "align_conv.ac.2.deform_conv.weight - torch.Size([256, 256, 3, 3]): \r\n",
      "The value is the same before and after calling `init_weights` of S2ANet  \r\n",
      " \r\n",
      "2025-06-13 14:06:41,166 - mmcv - INFO - \r\n",
      "align_conv.ac.3.deform_conv.weight - torch.Size([256, 256, 3, 3]): \r\n",
      "The value is the same before and after calling `init_weights` of S2ANet  \r\n",
      " \r\n",
      "2025-06-13 14:06:41,166 - mmcv - INFO - \r\n",
      "align_conv.ac.4.deform_conv.weight - torch.Size([256, 256, 3, 3]): \r\n",
      "The value is the same before and after calling `init_weights` of S2ANet  \r\n",
      " \r\n",
      "2025-06-13 14:06:41,167 - mmcv - INFO - \r\n",
      "odm_head.or_conv.weight - torch.Size([32, 256, 1, 3, 3]): \r\n",
      "NormalInit: mean=0, std=0.01, bias=0 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,167 - mmcv - INFO - \r\n",
      "odm_head.or_conv.bias - torch.Size([256]): \r\n",
      "The value is the same before and after calling `init_weights` of S2ANet  \r\n",
      " \r\n",
      "2025-06-13 14:06:41,167 - mmcv - INFO - \r\n",
      "odm_head.cls_convs.0.conv.weight - torch.Size([256, 32, 3, 3]): \r\n",
      "NormalInit: mean=0, std=0.01, bias=0 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,167 - mmcv - INFO - \r\n",
      "odm_head.cls_convs.0.conv.bias - torch.Size([256]): \r\n",
      "The value is the same before and after calling `init_weights` of S2ANet  \r\n",
      " \r\n",
      "2025-06-13 14:06:41,167 - mmcv - INFO - \r\n",
      "odm_head.cls_convs.1.conv.weight - torch.Size([256, 256, 3, 3]): \r\n",
      "NormalInit: mean=0, std=0.01, bias=0 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,167 - mmcv - INFO - \r\n",
      "odm_head.cls_convs.1.conv.bias - torch.Size([256]): \r\n",
      "The value is the same before and after calling `init_weights` of S2ANet  \r\n",
      " \r\n",
      "2025-06-13 14:06:41,167 - mmcv - INFO - \r\n",
      "odm_head.reg_convs.0.conv.weight - torch.Size([256, 256, 3, 3]): \r\n",
      "NormalInit: mean=0, std=0.01, bias=0 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,167 - mmcv - INFO - \r\n",
      "odm_head.reg_convs.0.conv.bias - torch.Size([256]): \r\n",
      "The value is the same before and after calling `init_weights` of S2ANet  \r\n",
      " \r\n",
      "2025-06-13 14:06:41,167 - mmcv - INFO - \r\n",
      "odm_head.reg_convs.1.conv.weight - torch.Size([256, 256, 3, 3]): \r\n",
      "NormalInit: mean=0, std=0.01, bias=0 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,167 - mmcv - INFO - \r\n",
      "odm_head.reg_convs.1.conv.bias - torch.Size([256]): \r\n",
      "The value is the same before and after calling `init_weights` of S2ANet  \r\n",
      " \r\n",
      "2025-06-13 14:06:41,167 - mmcv - INFO - \r\n",
      "odm_head.odm_cls.weight - torch.Size([1, 256, 3, 3]): \r\n",
      "NormalInit: mean=0, std=0.01, bias=-4.59511985013459 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,168 - mmcv - INFO - \r\n",
      "odm_head.odm_cls.bias - torch.Size([1]): \r\n",
      "NormalInit: mean=0, std=0.01, bias=-4.59511985013459 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,168 - mmcv - INFO - \r\n",
      "odm_head.odm_reg.weight - torch.Size([5, 256, 3, 3]): \r\n",
      "NormalInit: mean=0, std=0.01, bias=0 \r\n",
      " \r\n",
      "2025-06-13 14:06:41,168 - mmcv - INFO - \r\n",
      "odm_head.odm_reg.bias - torch.Size([5]): \r\n",
      "NormalInit: mean=0, std=0.01, bias=0 \r\n",
      " \r\n",
      "2025-06-13 14:06:43,546 - mmrotate - INFO - Start running, host: root@ec17075b4412, work_dir: /kaggle/working/runs/s2anet_train\r\n",
      "2025-06-13 14:06:43,547 - mmrotate - INFO - Hooks will be executed in the following order:\r\n",
      "before_run:\r\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \r\n",
      "(NORMAL      ) CheckpointHook                     \r\n",
      "(LOW         ) EvalHook                           \r\n",
      "(VERY_LOW    ) TextLoggerHook                     \r\n",
      " -------------------- \r\n",
      "before_train_epoch:\r\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \r\n",
      "(LOW         ) IterTimerHook                      \r\n",
      "(LOW         ) EvalHook                           \r\n",
      "(VERY_LOW    ) TextLoggerHook                     \r\n",
      " -------------------- \r\n",
      "before_train_iter:\r\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \r\n",
      "(LOW         ) IterTimerHook                      \r\n",
      "(LOW         ) EvalHook                           \r\n",
      " -------------------- \r\n",
      "after_train_iter:\r\n",
      "(ABOVE_NORMAL) OptimizerHook                      \r\n",
      "(NORMAL      ) CheckpointHook                     \r\n",
      "(LOW         ) IterTimerHook                      \r\n",
      "(LOW         ) EvalHook                           \r\n",
      "(VERY_LOW    ) TextLoggerHook                     \r\n",
      " -------------------- \r\n",
      "after_train_epoch:\r\n",
      "(NORMAL      ) CheckpointHook                     \r\n",
      "(LOW         ) EvalHook                           \r\n",
      "(VERY_LOW    ) TextLoggerHook                     \r\n",
      " -------------------- \r\n",
      "before_val_epoch:\r\n",
      "(LOW         ) IterTimerHook                      \r\n",
      "(VERY_LOW    ) TextLoggerHook                     \r\n",
      " -------------------- \r\n",
      "before_val_iter:\r\n",
      "(LOW         ) IterTimerHook                      \r\n",
      " -------------------- \r\n",
      "after_val_iter:\r\n",
      "(LOW         ) IterTimerHook                      \r\n",
      " -------------------- \r\n",
      "after_val_epoch:\r\n",
      "(VERY_LOW    ) TextLoggerHook                     \r\n",
      " -------------------- \r\n",
      "after_run:\r\n",
      "(VERY_LOW    ) TextLoggerHook                     \r\n",
      " -------------------- \r\n",
      "2025-06-13 14:06:43,547 - mmrotate - INFO - workflow: [('train', 1)], max: 2 epochs\r\n",
      "2025-06-13 14:06:43,547 - mmrotate - INFO - Checkpoints will be saved to /kaggle/working/runs/s2anet_train by HardDiskBackend.\r\n",
      "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\r\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\r\n",
      "2025-06-13 14:07:08,062 - mmrotate - INFO - Epoch [1][50/1855]\tlr: 9.967e-04, eta: 0:29:54, time: 0.490, data_time: 0.055, memory: 3067, fam.loss_cls: 0.8586, fam.loss_bbox: 1.1113, odm.loss_cls: 1.1103, odm.loss_bbox: 1.1950, loss: 4.2752, grad_norm: 22.6912\r\n",
      "2025-06-13 14:07:28,614 - mmrotate - INFO - Epoch [1][100/1855]\tlr: 1.163e-03, eta: 0:27:06, time: 0.411, data_time: 0.011, memory: 3067, fam.loss_cls: 0.7140, fam.loss_bbox: 0.8974, odm.loss_cls: 0.8784, odm.loss_bbox: 1.0875, loss: 3.5773, grad_norm: 17.1700\r\n",
      "2025-06-13 14:07:49,209 - mmrotate - INFO - Epoch [1][150/1855]\tlr: 1.330e-03, eta: 0:25:58, time: 0.412, data_time: 0.011, memory: 3067, fam.loss_cls: 0.6386, fam.loss_bbox: 0.8921, odm.loss_cls: 0.8077, odm.loss_bbox: 1.1481, loss: 3.4865, grad_norm: 18.0207\r\n",
      "2025-06-13 14:08:09,886 - mmrotate - INFO - Epoch [1][200/1855]\tlr: 1.497e-03, eta: 0:25:15, time: 0.414, data_time: 0.012, memory: 3067, fam.loss_cls: 0.7757, fam.loss_bbox: 0.8653, odm.loss_cls: 0.9144, odm.loss_bbox: 1.0110, loss: 3.5665, grad_norm: 21.2603\r\n",
      "2025-06-13 14:08:30,417 - mmrotate - INFO - Epoch [1][250/1855]\tlr: 1.663e-03, eta: 0:24:39, time: 0.411, data_time: 0.011, memory: 3067, fam.loss_cls: 0.7655, fam.loss_bbox: 0.8339, odm.loss_cls: 0.8356, odm.loss_bbox: 0.9298, loss: 3.3648, grad_norm: 18.5982\r\n",
      "2025-06-13 14:08:51,010 - mmrotate - INFO - Epoch [1][300/1855]\tlr: 1.830e-03, eta: 0:24:08, time: 0.412, data_time: 0.011, memory: 3067, fam.loss_cls: 0.7404, fam.loss_bbox: 0.7570, odm.loss_cls: 0.7509, odm.loss_bbox: 0.7701, loss: 3.0185, grad_norm: 12.7330\r\n",
      "2025-06-13 14:09:11,617 - mmrotate - INFO - Epoch [1][350/1855]\tlr: 1.997e-03, eta: 0:23:41, time: 0.412, data_time: 0.011, memory: 3067, fam.loss_cls: 0.5734, fam.loss_bbox: 0.8077, odm.loss_cls: 0.7522, odm.loss_bbox: 0.9883, loss: 3.1216, grad_norm: 12.2706\r\n",
      "2025-06-13 14:09:32,153 - mmrotate - INFO - Epoch [1][400/1855]\tlr: 2.163e-03, eta: 0:23:15, time: 0.411, data_time: 0.010, memory: 3067, fam.loss_cls: 0.8077, fam.loss_bbox: 0.7120, odm.loss_cls: 0.7107, odm.loss_bbox: 0.6671, loss: 2.8976, grad_norm: 14.4124\r\n",
      "2025-06-13 14:09:52,763 - mmrotate - INFO - Epoch [1][450/1855]\tlr: 2.330e-03, eta: 0:22:50, time: 0.412, data_time: 0.011, memory: 3067, fam.loss_cls: 0.7223, fam.loss_bbox: 0.6827, odm.loss_cls: 0.6260, odm.loss_bbox: 0.5928, loss: 2.6238, grad_norm: 15.3978\r\n",
      "2025-06-13 14:10:13,318 - mmrotate - INFO - Epoch [1][500/1855]\tlr: 2.497e-03, eta: 0:22:26, time: 0.411, data_time: 0.010, memory: 3067, fam.loss_cls: 0.6257, fam.loss_bbox: 0.7236, odm.loss_cls: 0.7040, odm.loss_bbox: 0.6253, loss: 2.6786, grad_norm: 10.9547\r\n",
      "2025-06-13 14:10:33,839 - mmrotate - INFO - Epoch [1][550/1855]\tlr: 2.500e-03, eta: 0:22:03, time: 0.410, data_time: 0.010, memory: 3067, fam.loss_cls: 0.5584, fam.loss_bbox: 0.7044, odm.loss_cls: 0.5795, odm.loss_bbox: 0.5886, loss: 2.4309, grad_norm: 10.2499\r\n",
      "2025-06-13 14:10:54,489 - mmrotate - INFO - Epoch [1][600/1855]\tlr: 2.500e-03, eta: 0:21:40, time: 0.413, data_time: 0.011, memory: 3067, fam.loss_cls: 0.5979, fam.loss_bbox: 0.7582, odm.loss_cls: 0.6279, odm.loss_bbox: 0.6405, loss: 2.6245, grad_norm: 12.4581\r\n",
      "2025-06-13 14:11:15,073 - mmrotate - INFO - Epoch [1][650/1855]\tlr: 2.500e-03, eta: 0:21:18, time: 0.412, data_time: 0.011, memory: 3067, fam.loss_cls: 0.4796, fam.loss_bbox: 0.6523, odm.loss_cls: 0.5079, odm.loss_bbox: 0.5523, loss: 2.1921, grad_norm: 9.6612\r\n",
      "2025-06-13 14:11:35,811 - mmrotate - INFO - Epoch [1][700/1855]\tlr: 2.500e-03, eta: 0:20:56, time: 0.415, data_time: 0.012, memory: 3067, fam.loss_cls: 0.4902, fam.loss_bbox: 0.6052, odm.loss_cls: 0.5312, odm.loss_bbox: 0.5426, loss: 2.1692, grad_norm: 9.4602\r\n",
      "2025-06-13 14:11:56,463 - mmrotate - INFO - Epoch [1][750/1855]\tlr: 2.500e-03, eta: 0:20:34, time: 0.413, data_time: 0.011, memory: 3067, fam.loss_cls: 0.4982, fam.loss_bbox: 0.6106, odm.loss_cls: 0.4191, odm.loss_bbox: 0.5049, loss: 2.0328, grad_norm: 9.9972\r\n",
      "2025-06-13 14:12:16,995 - mmrotate - INFO - Epoch [1][800/1855]\tlr: 2.500e-03, eta: 0:20:12, time: 0.411, data_time: 0.010, memory: 3067, fam.loss_cls: 0.4778, fam.loss_bbox: 0.5774, odm.loss_cls: 0.3707, odm.loss_bbox: 0.4233, loss: 1.8492, grad_norm: 9.7007\r\n",
      "2025-06-13 14:12:37,639 - mmrotate - INFO - Epoch [1][850/1855]\tlr: 2.500e-03, eta: 0:19:51, time: 0.413, data_time: 0.011, memory: 3067, fam.loss_cls: 0.4774, fam.loss_bbox: 0.5767, odm.loss_cls: 0.3790, odm.loss_bbox: 0.4734, loss: 1.9065, grad_norm: 10.2600\r\n",
      "2025-06-13 14:12:58,200 - mmrotate - INFO - Epoch [1][900/1855]\tlr: 2.500e-03, eta: 0:19:29, time: 0.411, data_time: 0.010, memory: 3067, fam.loss_cls: 0.5088, fam.loss_bbox: 0.5345, odm.loss_cls: 0.3615, odm.loss_bbox: 0.4311, loss: 1.8359, grad_norm: 9.3384\r\n",
      "2025-06-13 14:13:18,772 - mmrotate - INFO - Epoch [1][950/1855]\tlr: 2.500e-03, eta: 0:19:08, time: 0.411, data_time: 0.010, memory: 3067, fam.loss_cls: 0.5095, fam.loss_bbox: 0.5545, odm.loss_cls: 0.4334, odm.loss_bbox: 0.4501, loss: 1.9474, grad_norm: 9.8840\r\n",
      "2025-06-13 14:13:39,507 - mmrotate - INFO - Exp name: s2anet_r50_fpn_1x_sccos.py\r\n",
      "2025-06-13 14:13:39,507 - mmrotate - INFO - Epoch [1][1000/1855]\tlr: 2.500e-03, eta: 0:18:47, time: 0.415, data_time: 0.013, memory: 3067, fam.loss_cls: 0.4926, fam.loss_bbox: 0.4502, odm.loss_cls: 0.3718, odm.loss_bbox: 0.3901, loss: 1.7047, grad_norm: 9.7404\r\n",
      "2025-06-13 14:14:00,147 - mmrotate - INFO - Epoch [1][1050/1855]\tlr: 2.500e-03, eta: 0:18:26, time: 0.413, data_time: 0.012, memory: 3067, fam.loss_cls: 0.4782, fam.loss_bbox: 0.5435, odm.loss_cls: 0.4346, odm.loss_bbox: 0.4572, loss: 1.9134, grad_norm: 9.9207\r\n",
      "2025-06-13 14:14:20,783 - mmrotate - INFO - Epoch [1][1100/1855]\tlr: 2.500e-03, eta: 0:18:04, time: 0.413, data_time: 0.011, memory: 3067, fam.loss_cls: 0.4552, fam.loss_bbox: 0.5229, odm.loss_cls: 0.2826, odm.loss_bbox: 0.3683, loss: 1.6289, grad_norm: 9.2771\r\n",
      "2025-06-13 14:14:41,423 - mmrotate - INFO - Epoch [1][1150/1855]\tlr: 2.500e-03, eta: 0:17:43, time: 0.413, data_time: 0.011, memory: 3067, fam.loss_cls: 0.4529, fam.loss_bbox: 0.4720, odm.loss_cls: 0.2643, odm.loss_bbox: 0.3540, loss: 1.5433, grad_norm: 9.3143\r\n",
      "2025-06-13 14:15:02,067 - mmrotate - INFO - Epoch [1][1200/1855]\tlr: 2.500e-03, eta: 0:17:22, time: 0.413, data_time: 0.011, memory: 3067, fam.loss_cls: 0.4619, fam.loss_bbox: 0.5001, odm.loss_cls: 0.2878, odm.loss_bbox: 0.3783, loss: 1.6282, grad_norm: 9.4630\r\n",
      "2025-06-13 14:15:22,588 - mmrotate - INFO - Epoch [1][1250/1855]\tlr: 2.500e-03, eta: 0:17:01, time: 0.410, data_time: 0.010, memory: 3067, fam.loss_cls: 0.4927, fam.loss_bbox: 0.4807, odm.loss_cls: 0.2833, odm.loss_bbox: 0.3759, loss: 1.6326, grad_norm: 8.7441\r\n",
      "2025-06-13 14:15:43,240 - mmrotate - INFO - Epoch [1][1300/1855]\tlr: 2.500e-03, eta: 0:16:40, time: 0.413, data_time: 0.011, memory: 3067, fam.loss_cls: 0.4133, fam.loss_bbox: 0.4776, odm.loss_cls: 0.2510, odm.loss_bbox: 0.3731, loss: 1.5150, grad_norm: 8.5101\r\n",
      "2025-06-13 14:16:03,838 - mmrotate - INFO - Epoch [1][1350/1855]\tlr: 2.500e-03, eta: 0:16:19, time: 0.412, data_time: 0.011, memory: 3067, fam.loss_cls: 0.4680, fam.loss_bbox: 0.4578, odm.loss_cls: 0.2965, odm.loss_bbox: 0.3324, loss: 1.5547, grad_norm: 9.5016\r\n",
      "2025-06-13 14:16:24,385 - mmrotate - INFO - Epoch [1][1400/1855]\tlr: 2.500e-03, eta: 0:15:58, time: 0.411, data_time: 0.010, memory: 3067, fam.loss_cls: 0.4380, fam.loss_bbox: 0.4047, odm.loss_cls: 0.2476, odm.loss_bbox: 0.3088, loss: 1.3991, grad_norm: 8.7137\r\n",
      "2025-06-13 14:16:45,004 - mmrotate - INFO - Epoch [1][1450/1855]\tlr: 2.500e-03, eta: 0:15:37, time: 0.412, data_time: 0.011, memory: 3067, fam.loss_cls: 0.4183, fam.loss_bbox: 0.4427, odm.loss_cls: 0.2835, odm.loss_bbox: 0.3697, loss: 1.5142, grad_norm: 8.5892\r\n",
      "2025-06-13 14:17:05,655 - mmrotate - INFO - Epoch [1][1500/1855]\tlr: 2.500e-03, eta: 0:15:16, time: 0.413, data_time: 0.011, memory: 3067, fam.loss_cls: 0.4003, fam.loss_bbox: 0.4143, odm.loss_cls: 0.2379, odm.loss_bbox: 0.3048, loss: 1.3573, grad_norm: 8.6310\r\n",
      "2025-06-13 14:17:26,220 - mmrotate - INFO - Epoch [1][1550/1855]\tlr: 2.500e-03, eta: 0:14:55, time: 0.411, data_time: 0.011, memory: 3067, fam.loss_cls: 0.4342, fam.loss_bbox: 0.4182, odm.loss_cls: 0.2249, odm.loss_bbox: 0.3316, loss: 1.4090, grad_norm: 10.0273\r\n",
      "2025-06-13 14:17:46,878 - mmrotate - INFO - Epoch [1][1600/1855]\tlr: 2.500e-03, eta: 0:14:34, time: 0.413, data_time: 0.011, memory: 3067, fam.loss_cls: 0.4221, fam.loss_bbox: 0.4577, odm.loss_cls: 0.2690, odm.loss_bbox: 0.3462, loss: 1.4950, grad_norm: 9.3310\r\n",
      "2025-06-13 14:18:07,518 - mmrotate - INFO - Epoch [1][1650/1855]\tlr: 2.500e-03, eta: 0:14:13, time: 0.413, data_time: 0.011, memory: 3067, fam.loss_cls: 0.4010, fam.loss_bbox: 0.4506, odm.loss_cls: 0.2474, odm.loss_bbox: 0.3515, loss: 1.4505, grad_norm: 8.2493\r\n",
      "2025-06-13 14:18:28,127 - mmrotate - INFO - Epoch [1][1700/1855]\tlr: 2.500e-03, eta: 0:13:53, time: 0.412, data_time: 0.011, memory: 3067, fam.loss_cls: 0.4116, fam.loss_bbox: 0.4036, odm.loss_cls: 0.2186, odm.loss_bbox: 0.2858, loss: 1.3197, grad_norm: 8.3809\r\n",
      "2025-06-13 14:18:48,789 - mmrotate - INFO - Epoch [1][1750/1855]\tlr: 2.500e-03, eta: 0:13:32, time: 0.413, data_time: 0.011, memory: 3067, fam.loss_cls: 0.4342, fam.loss_bbox: 0.4475, odm.loss_cls: 0.2384, odm.loss_bbox: 0.3296, loss: 1.4496, grad_norm: 8.0059\r\n",
      "2025-06-13 14:19:09,339 - mmrotate - INFO - Epoch [1][1800/1855]\tlr: 2.500e-03, eta: 0:13:11, time: 0.411, data_time: 0.010, memory: 3067, fam.loss_cls: 0.3905, fam.loss_bbox: 0.3848, odm.loss_cls: 0.2014, odm.loss_bbox: 0.2907, loss: 1.2674, grad_norm: 7.8276\r\n",
      "2025-06-13 14:19:29,887 - mmrotate - INFO - Epoch [1][1850/1855]\tlr: 2.500e-03, eta: 0:12:50, time: 0.411, data_time: 0.010, memory: 3067, fam.loss_cls: 0.3825, fam.loss_bbox: 0.4307, odm.loss_cls: 0.1981, odm.loss_bbox: 0.2918, loss: 1.3030, grad_norm: 8.0237\r\n",
      "2025-06-13 14:19:31,988 - mmrotate - INFO - Saving checkpoint at 1 epochs\r\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 464/464, 11.1 task/s, elapsed: 42s, ETA:     0s/usr/local/lib/python3.10/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.10/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.10/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.10/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 2.0.8 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\r\n",
      "  check_for_updates()\r\n",
      "/usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 2.0.8 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\r\n",
      "  check_for_updates()\r\n",
      "/usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 2.0.8 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\r\n",
      "  check_for_updates()\r\n",
      "/usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 2.0.8 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\r\n",
      "  check_for_updates()\r\n",
      "2025-06-13 14:20:21,712 - mmrotate - INFO - \r\n",
      "+-------+------+------+--------+-------+\r\n",
      "| class | gts  | dets | recall | ap    |\r\n",
      "+-------+------+------+--------+-------+\r\n",
      "| ship  | 2147 | 7745 | 0.489  | 0.419 |\r\n",
      "+-------+------+------+--------+-------+\r\n",
      "| mAP   |      |      |        | 0.419 |\r\n",
      "+-------+------+------+--------+-------+\r\n",
      "2025-06-13 14:20:21,784 - mmrotate - INFO - Exp name: s2anet_r50_fpn_1x_sccos.py\r\n",
      "2025-06-13 14:20:21,785 - mmrotate - INFO - Epoch(val) [1][464]\tmAP: 0.4193\r\n",
      "2025-06-13 14:20:44,770 - mmrotate - INFO - Epoch [2][50/1855]\tlr: 2.500e-03, eta: 0:12:27, time: 0.460, data_time: 0.057, memory: 3067, fam.loss_cls: 0.3865, fam.loss_bbox: 0.3705, odm.loss_cls: 0.2263, odm.loss_bbox: 0.2981, loss: 1.2814, grad_norm: 8.4421\r\n",
      "2025-06-13 14:21:05,350 - mmrotate - INFO - Epoch [2][100/1855]\tlr: 2.500e-03, eta: 0:12:07, time: 0.412, data_time: 0.011, memory: 3067, fam.loss_cls: 0.4147, fam.loss_bbox: 0.3651, odm.loss_cls: 0.1892, odm.loss_bbox: 0.2846, loss: 1.2535, grad_norm: 8.0810\r\n",
      "2025-06-13 14:21:25,954 - mmrotate - INFO - Epoch [2][150/1855]\tlr: 2.500e-03, eta: 0:11:46, time: 0.412, data_time: 0.011, memory: 3067, fam.loss_cls: 0.3854, fam.loss_bbox: 0.3686, odm.loss_cls: 0.1902, odm.loss_bbox: 0.2772, loss: 1.2214, grad_norm: 7.8692\r\n",
      "2025-06-13 14:21:46,728 - mmrotate - INFO - Epoch [2][200/1855]\tlr: 2.500e-03, eta: 0:11:25, time: 0.415, data_time: 0.011, memory: 3067, fam.loss_cls: 0.3590, fam.loss_bbox: 0.3622, odm.loss_cls: 0.1578, odm.loss_bbox: 0.2858, loss: 1.1648, grad_norm: 7.7352\r\n",
      "2025-06-13 14:22:07,485 - mmrotate - INFO - Epoch [2][250/1855]\tlr: 2.500e-03, eta: 0:11:04, time: 0.415, data_time: 0.011, memory: 3067, fam.loss_cls: 0.3606, fam.loss_bbox: 0.3785, odm.loss_cls: 0.1835, odm.loss_bbox: 0.2628, loss: 1.1854, grad_norm: 8.0484\r\n",
      "2025-06-13 14:22:28,259 - mmrotate - INFO - Epoch [2][300/1855]\tlr: 2.500e-03, eta: 0:10:44, time: 0.415, data_time: 0.011, memory: 3067, fam.loss_cls: 0.3687, fam.loss_bbox: 0.3763, odm.loss_cls: 0.2384, odm.loss_bbox: 0.2686, loss: 1.2519, grad_norm: 8.7843\r\n",
      "2025-06-13 14:22:48,890 - mmrotate - INFO - Epoch [2][350/1855]\tlr: 2.500e-03, eta: 0:10:23, time: 0.413, data_time: 0.011, memory: 3067, fam.loss_cls: 0.4810, fam.loss_bbox: 0.2994, odm.loss_cls: 0.2764, odm.loss_bbox: 0.2652, loss: 1.3220, grad_norm: 7.6432\r\n",
      "2025-06-13 14:23:09,671 - mmrotate - INFO - Epoch [2][400/1855]\tlr: 2.500e-03, eta: 0:10:02, time: 0.416, data_time: 0.012, memory: 3067, fam.loss_cls: 0.3586, fam.loss_bbox: 0.3557, odm.loss_cls: 0.1804, odm.loss_bbox: 0.2752, loss: 1.1699, grad_norm: 7.0968\r\n",
      "2025-06-13 14:23:30,460 - mmrotate - INFO - Epoch [2][450/1855]\tlr: 2.500e-03, eta: 0:09:42, time: 0.416, data_time: 0.012, memory: 3067, fam.loss_cls: 0.3840, fam.loss_bbox: 0.3689, odm.loss_cls: 0.2346, odm.loss_bbox: 0.2502, loss: 1.2377, grad_norm: 10.3276\r\n",
      "2025-06-13 14:23:51,141 - mmrotate - INFO - Epoch [2][500/1855]\tlr: 2.500e-03, eta: 0:09:21, time: 0.414, data_time: 0.011, memory: 3067, fam.loss_cls: 0.3724, fam.loss_bbox: 0.3729, odm.loss_cls: 0.2111, odm.loss_bbox: 0.2656, loss: 1.2219, grad_norm: 7.7990\r\n",
      "2025-06-13 14:24:11,876 - mmrotate - INFO - Epoch [2][550/1855]\tlr: 2.500e-03, eta: 0:09:00, time: 0.415, data_time: 0.011, memory: 3067, fam.loss_cls: 0.3772, fam.loss_bbox: 0.4018, odm.loss_cls: 0.1933, odm.loss_bbox: 0.2809, loss: 1.2532, grad_norm: 8.5916\r\n",
      "2025-06-13 14:24:32,616 - mmrotate - INFO - Epoch [2][600/1855]\tlr: 2.500e-03, eta: 0:08:39, time: 0.415, data_time: 0.012, memory: 3067, fam.loss_cls: 0.3753, fam.loss_bbox: 0.3449, odm.loss_cls: 0.1670, odm.loss_bbox: 0.2851, loss: 1.1723, grad_norm: 8.2440\r\n",
      "2025-06-13 14:24:53,251 - mmrotate - INFO - Epoch [2][650/1855]\tlr: 2.500e-03, eta: 0:08:19, time: 0.413, data_time: 0.011, memory: 3067, fam.loss_cls: 0.4149, fam.loss_bbox: 0.3681, odm.loss_cls: 0.1820, odm.loss_bbox: 0.2835, loss: 1.2484, grad_norm: 7.8938\r\n",
      "2025-06-13 14:25:13,887 - mmrotate - INFO - Epoch [2][700/1855]\tlr: 2.500e-03, eta: 0:07:58, time: 0.413, data_time: 0.011, memory: 3067, fam.loss_cls: 0.3375, fam.loss_bbox: 0.3337, odm.loss_cls: 0.1630, odm.loss_bbox: 0.2399, loss: 1.0741, grad_norm: 6.9134\r\n",
      "2025-06-13 14:25:34,569 - mmrotate - INFO - Epoch [2][750/1855]\tlr: 2.500e-03, eta: 0:07:37, time: 0.414, data_time: 0.011, memory: 3067, fam.loss_cls: 0.3424, fam.loss_bbox: 0.2766, odm.loss_cls: 0.1118, odm.loss_bbox: 0.2092, loss: 0.9399, grad_norm: 6.9460\r\n",
      "2025-06-13 14:25:55,173 - mmrotate - INFO - Epoch [2][800/1855]\tlr: 2.500e-03, eta: 0:07:16, time: 0.412, data_time: 0.010, memory: 3067, fam.loss_cls: 0.3674, fam.loss_bbox: 0.3333, odm.loss_cls: 0.1782, odm.loss_bbox: 0.2597, loss: 1.1387, grad_norm: 7.8234\r\n",
      "2025-06-13 14:26:15,782 - mmrotate - INFO - Epoch [2][850/1855]\tlr: 2.500e-03, eta: 0:06:56, time: 0.412, data_time: 0.010, memory: 3067, fam.loss_cls: 0.3804, fam.loss_bbox: 0.3847, odm.loss_cls: 0.1579, odm.loss_bbox: 0.2577, loss: 1.1807, grad_norm: 8.2385\r\n",
      "2025-06-13 14:26:36,434 - mmrotate - INFO - Epoch [2][900/1855]\tlr: 2.500e-03, eta: 0:06:35, time: 0.413, data_time: 0.011, memory: 3067, fam.loss_cls: 0.3297, fam.loss_bbox: 0.3327, odm.loss_cls: 0.1735, odm.loss_bbox: 0.2369, loss: 1.0728, grad_norm: 8.1479\r\n",
      "2025-06-13 14:26:57,077 - mmrotate - INFO - Epoch [2][950/1855]\tlr: 2.500e-03, eta: 0:06:14, time: 0.413, data_time: 0.011, memory: 3067, fam.loss_cls: 0.3576, fam.loss_bbox: 0.3459, odm.loss_cls: 0.1767, odm.loss_bbox: 0.2468, loss: 1.1271, grad_norm: 6.9135\r\n",
      "2025-06-13 14:27:17,782 - mmrotate - INFO - Epoch [2][1000/1855]\tlr: 2.500e-03, eta: 0:05:54, time: 0.414, data_time: 0.012, memory: 3067, fam.loss_cls: 0.3482, fam.loss_bbox: 0.3424, odm.loss_cls: 0.1443, odm.loss_bbox: 0.2607, loss: 1.0957, grad_norm: 7.1627\r\n",
      "2025-06-13 14:27:38,386 - mmrotate - INFO - Epoch [2][1050/1855]\tlr: 2.500e-03, eta: 0:05:33, time: 0.412, data_time: 0.011, memory: 3067, fam.loss_cls: 0.3578, fam.loss_bbox: 0.3825, odm.loss_cls: 0.1698, odm.loss_bbox: 0.2543, loss: 1.1644, grad_norm: 8.5567\r\n",
      "2025-06-13 14:27:59,020 - mmrotate - INFO - Epoch [2][1100/1855]\tlr: 2.500e-03, eta: 0:05:12, time: 0.413, data_time: 0.011, memory: 3067, fam.loss_cls: 0.3651, fam.loss_bbox: 0.3565, odm.loss_cls: 0.1726, odm.loss_bbox: 0.2418, loss: 1.1361, grad_norm: 7.1624\r\n",
      "2025-06-13 14:28:19,660 - mmrotate - INFO - Epoch [2][1150/1855]\tlr: 2.500e-03, eta: 0:04:51, time: 0.413, data_time: 0.011, memory: 3067, fam.loss_cls: 0.3544, fam.loss_bbox: 0.3317, odm.loss_cls: 0.1424, odm.loss_bbox: 0.2368, loss: 1.0653, grad_norm: 7.6778\r\n",
      "2025-06-13 14:28:40,318 - mmrotate - INFO - Epoch [2][1200/1855]\tlr: 2.500e-03, eta: 0:04:31, time: 0.413, data_time: 0.011, memory: 3067, fam.loss_cls: 0.3177, fam.loss_bbox: 0.3011, odm.loss_cls: 0.1034, odm.loss_bbox: 0.2231, loss: 0.9452, grad_norm: 7.7930\r\n",
      "2025-06-13 14:29:00,954 - mmrotate - INFO - Epoch [2][1250/1855]\tlr: 2.500e-03, eta: 0:04:10, time: 0.413, data_time: 0.011, memory: 3067, fam.loss_cls: 0.3650, fam.loss_bbox: 0.3584, odm.loss_cls: 0.1553, odm.loss_bbox: 0.2464, loss: 1.1251, grad_norm: 7.9809\r\n",
      "2025-06-13 14:29:21,762 - mmrotate - INFO - Epoch [2][1300/1855]\tlr: 2.500e-03, eta: 0:03:49, time: 0.416, data_time: 0.013, memory: 3067, fam.loss_cls: 0.3381, fam.loss_bbox: 0.3084, odm.loss_cls: 0.1230, odm.loss_bbox: 0.2172, loss: 0.9867, grad_norm: 7.1555\r\n",
      "2025-06-13 14:29:42,445 - mmrotate - INFO - Epoch [2][1350/1855]\tlr: 2.500e-03, eta: 0:03:29, time: 0.414, data_time: 0.011, memory: 3067, fam.loss_cls: 0.3425, fam.loss_bbox: 0.3165, odm.loss_cls: 0.1545, odm.loss_bbox: 0.2254, loss: 1.0389, grad_norm: 7.8368\r\n",
      "2025-06-13 14:30:03,155 - mmrotate - INFO - Epoch [2][1400/1855]\tlr: 2.500e-03, eta: 0:03:08, time: 0.414, data_time: 0.011, memory: 3067, fam.loss_cls: 0.3464, fam.loss_bbox: 0.3186, odm.loss_cls: 0.1540, odm.loss_bbox: 0.2406, loss: 1.0595, grad_norm: 7.0145\r\n",
      "2025-06-13 14:30:23,879 - mmrotate - INFO - Epoch [2][1450/1855]\tlr: 2.500e-03, eta: 0:02:47, time: 0.414, data_time: 0.011, memory: 3067, fam.loss_cls: 0.3688, fam.loss_bbox: 0.3001, odm.loss_cls: 0.1438, odm.loss_bbox: 0.2233, loss: 1.0360, grad_norm: 7.2745\r\n",
      "2025-06-13 14:30:44,628 - mmrotate - INFO - Epoch [2][1500/1855]\tlr: 2.500e-03, eta: 0:02:26, time: 0.415, data_time: 0.011, memory: 3067, fam.loss_cls: 0.3546, fam.loss_bbox: 0.3246, odm.loss_cls: 0.1445, odm.loss_bbox: 0.2312, loss: 1.0548, grad_norm: 6.9308\r\n",
      "2025-06-13 14:31:05,222 - mmrotate - INFO - Epoch [2][1550/1855]\tlr: 2.500e-03, eta: 0:02:06, time: 0.412, data_time: 0.011, memory: 3067, fam.loss_cls: 0.2959, fam.loss_bbox: 0.2623, odm.loss_cls: 0.1084, odm.loss_bbox: 0.2070, loss: 0.8737, grad_norm: 6.9471\r\n",
      "2025-06-13 14:31:25,909 - mmrotate - INFO - Epoch [2][1600/1855]\tlr: 2.500e-03, eta: 0:01:45, time: 0.414, data_time: 0.012, memory: 3067, fam.loss_cls: 0.3653, fam.loss_bbox: 0.3383, odm.loss_cls: 0.1607, odm.loss_bbox: 0.2509, loss: 1.1152, grad_norm: 7.7637\r\n",
      "2025-06-13 14:31:46,596 - mmrotate - INFO - Epoch [2][1650/1855]\tlr: 2.500e-03, eta: 0:01:24, time: 0.414, data_time: 0.011, memory: 3067, fam.loss_cls: 0.3460, fam.loss_bbox: 0.2693, odm.loss_cls: 0.1392, odm.loss_bbox: 0.2026, loss: 0.9572, grad_norm: 6.7320\r\n",
      "2025-06-13 14:32:07,245 - mmrotate - INFO - Epoch [2][1700/1855]\tlr: 2.500e-03, eta: 0:01:04, time: 0.413, data_time: 0.011, memory: 3067, fam.loss_cls: 0.4067, fam.loss_bbox: 0.2807, odm.loss_cls: 0.1189, odm.loss_bbox: 0.1958, loss: 1.0021, grad_norm: 6.9197\r\n",
      "2025-06-13 14:32:27,944 - mmrotate - INFO - Epoch [2][1750/1855]\tlr: 2.500e-03, eta: 0:00:43, time: 0.414, data_time: 0.012, memory: 3067, fam.loss_cls: 0.3592, fam.loss_bbox: 0.2922, odm.loss_cls: 0.1578, odm.loss_bbox: 0.2123, loss: 1.0215, grad_norm: 8.0097\r\n",
      "2025-06-13 14:32:48,556 - mmrotate - INFO - Epoch [2][1800/1855]\tlr: 2.500e-03, eta: 0:00:22, time: 0.412, data_time: 0.011, memory: 3067, fam.loss_cls: 0.3306, fam.loss_bbox: 0.2842, odm.loss_cls: 0.1275, odm.loss_bbox: 0.2197, loss: 0.9620, grad_norm: 6.1746\r\n",
      "2025-06-13 14:33:09,153 - mmrotate - INFO - Epoch [2][1850/1855]\tlr: 2.500e-03, eta: 0:00:02, time: 0.412, data_time: 0.011, memory: 3067, fam.loss_cls: 0.3358, fam.loss_bbox: 0.2948, odm.loss_cls: 0.1444, odm.loss_bbox: 0.2103, loss: 0.9854, grad_norm: 6.8347\r\n",
      "2025-06-13 14:33:11,270 - mmrotate - INFO - Saving checkpoint at 2 epochs\r\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 464/464, 11.0 task/s, elapsed: 42s, ETA:     0s/usr/local/lib/python3.10/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.10/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.10/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.10/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 2.0.8 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\r\n",
      "  check_for_updates()\r\n",
      "/usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 2.0.8 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\r\n",
      "  check_for_updates()\r\n",
      "/usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 2.0.8 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\r\n",
      "  check_for_updates()\r\n",
      "/usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 2.0.8 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\r\n",
      "  check_for_updates()\r\n",
      "2025-06-13 14:34:01,757 - mmrotate - INFO - \r\n",
      "+-------+------+-------+--------+-------+\r\n",
      "| class | gts  | dets  | recall | ap    |\r\n",
      "+-------+------+-------+--------+-------+\r\n",
      "| ship  | 2147 | 27138 | 0.669  | 0.588 |\r\n",
      "+-------+------+-------+--------+-------+\r\n",
      "| mAP   |      |       |        | 0.588 |\r\n",
      "+-------+------+-------+--------+-------+\r\n",
      "2025-06-13 14:34:01,828 - mmrotate - INFO - Exp name: s2anet_r50_fpn_1x_sccos.py\r\n",
      "2025-06-13 14:34:01,828 - mmrotate - INFO - Epoch(val) [2][464]\tmAP: 0.5876\r\n",
      "Training completed.\n"
     ]
    }
   ],
   "source": [
    "# Step 8: Train the Model\n",
    "%cd /kaggle/working/mmrotate\n",
    "!mkdir -p /kaggle/working/runs/s2anet_train\n",
    "!python tools/train.py \\\n",
    "    configs/s2anet/s2anet_r50_fpn_1x_sccos.py \\\n",
    "    --work-dir /kaggle/working/runs/s2anet_train \\\n",
    "    --gpus 1\n",
    "\n",
    "print(\"Training completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f9ea606d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T14:34:04.564526Z",
     "iopub.status.busy": "2025-06-13T14:34:04.564185Z",
     "iopub.status.idle": "2025-06-13T14:34:09.684948Z",
     "shell.execute_reply": "2025-06-13T14:34:09.683842Z"
    },
    "papermill": {
     "duration": 5.209271,
     "end_time": "2025-06-13T14:34:09.686252",
     "exception": false,
     "start_time": "2025-06-13T14:34:04.476981",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/mmrotate\n",
      "/usr/local/lib/python3.10/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 2.0.8 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\r\n",
      "  check_for_updates()\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/kaggle/working/mmrotate/tools/test.py\", line 271, in <module>\r\n",
      "    main()\r\n",
      "  File \"/kaggle/working/mmrotate/tools/test.py\", line 116, in main\r\n",
      "    cfg = Config.fromfile(args.config)\r\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/mmcv/utils/config.py\", line 340, in fromfile\r\n",
      "    cfg_dict, cfg_text = Config._file2dict(filename,\r\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/mmcv/utils/config.py\", line 183, in _file2dict\r\n",
      "    check_file_exist(filename)\r\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/mmcv/utils/path.py\", line 23, in check_file_exist\r\n",
      "    raise FileNotFoundError(msg_tmpl.format(filename))\r\n",
      "FileNotFoundError: file \"/kaggle/working/mmrotate/configs/oriented_rcnn/oriented_rcnn_r50_fpn_1x_sccos.py\" does not exist\r\n",
      "Testing completed.\n"
     ]
    }
   ],
   "source": [
    "# Step 9: Test the Model\n",
    "%cd /kaggle/working/mmrotate\n",
    "!mkdir -p /kaggle/working/runs/oriented_rcnn_test\n",
    "!python tools/test.py \\\n",
    "    configs/oriented_rcnn/oriented_rcnn_r50_fpn_1x_sccos.py \\\n",
    "    /kaggle/working/runs/oriented_rcnn_train/latest.pth \\\n",
    "    --eval mAP \\\n",
    "    --out /kaggle/working/runs/oriented_rcnn_test/results.pkl\\\n",
    "    --show-dir /kaggle/working/runs/oriented_rcnn_test/vis\n",
    "\n",
    "print(\"Testing completed.\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6771261,
     "sourceId": 10895847,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2168.70812,
   "end_time": "2025-06-13T14:34:10.595135",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-06-13T13:58:01.887015",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
