{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c255b479",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T19:20:00.895815Z",
     "iopub.status.busy": "2025-03-17T19:20:00.895524Z",
     "iopub.status.idle": "2025-03-17T19:20:05.576826Z",
     "shell.execute_reply": "2025-03-17T19:20:05.575720Z"
    },
    "papermill": {
     "duration": 4.687476,
     "end_time": "2025-03-17T19:20:05.578661",
     "exception": false,
     "start_time": "2025-03-17T19:20:00.891185",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\r\n",
      "Copyright (c) 2005-2023 NVIDIA Corporation\r\n",
      "Built on Tue_Aug_15_22:02:13_PDT_2023\r\n",
      "Cuda compilation tools, release 12.2, V12.2.140\r\n",
      "Build cuda_12.2.r12.2/compiler.33191640_0\r\n",
      "PyTorch: 2.5.1+cu121 CUDA Available: True CUDA Version: 12.1\r\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version\n",
    "!python -c \"import torch; print('PyTorch:', torch.__version__, 'CUDA Available:', torch.cuda.is_available(), 'CUDA Version:', torch.version.cuda)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3160f576",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T19:20:05.586269Z",
     "iopub.status.busy": "2025-03-17T19:20:05.585914Z",
     "iopub.status.idle": "2025-03-17T19:21:00.568554Z",
     "shell.execute_reply": "2025-03-17T19:21:00.567447Z"
    },
    "papermill": {
     "duration": 54.988537,
     "end_time": "2025-03-17T19:21:00.570412",
     "exception": false,
     "start_time": "2025-03-17T19:20:05.581875",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Skipping mmcv as it is not installed.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Skipping mmcv-full as it is not installed.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Skipping mmdet as it is not installed.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Step 2: Uninstall Conflicting Packages\n",
    "!pip uninstall -y mmcv mmcv-full mmdet torch torchvision tensorflow tensorboard -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "467208fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T19:21:00.577668Z",
     "iopub.status.busy": "2025-03-17T19:21:00.577407Z",
     "iopub.status.idle": "2025-03-17T19:23:25.383903Z",
     "shell.execute_reply": "2025-03-17T19:23:25.382692Z"
    },
    "papermill": {
     "duration": 144.812002,
     "end_time": "2025-03-17T19:23:25.385688",
     "exception": false,
     "start_time": "2025-03-17T19:21:00.573686",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 GB\u001b[0m \u001b[31m438.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.2/24.2 MB\u001b[0m \u001b[31m58.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "pytorch-lightning 2.5.0.post0 requires torch>=2.1.0, but you have torch 1.13.1+cu116 which is incompatible.\r\n",
      "torchaudio 2.5.1+cu121 requires torch==2.5.1, but you have torch 1.13.1+cu116 which is incompatible.\r\n",
      "torchmetrics 1.6.1 requires torch>=2.0.0, but you have torch 1.13.1+cu116 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 MB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.8/46.8 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m256.2/256.2 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.5/259.5 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.1/50.1 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.7/89.7 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m449.6/449.6 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.5/311.5 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.4/239.4 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m506.5/506.5 kB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.2/144.2 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.1/953.1 kB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.5/99.5 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Building wheel for oss2 (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Building wheel for aliyun-python-sdk-core (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Building wheel for crcmod (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "dopamine-rl 4.1.0 requires tensorflow>=2.2.0, which is not installed.\r\n",
      "tensorflow-decision-forests 1.10.0 requires tensorflow==2.17.0, which is not installed.\r\n",
      "datasets 3.3.1 requires requests>=2.32.2, but you have requests 2.28.2 which is incompatible.\r\n",
      "datasets 3.3.1 requires tqdm>=4.66.3, but you have tqdm 4.65.2 which is incompatible.\r\n",
      "featuretools 1.31.0 requires tqdm>=4.66.3, but you have tqdm 4.65.2 which is incompatible.\r\n",
      "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.12.0 which is incompatible.\r\n",
      "google-cloud-bigtable 2.27.0 requires google-api-core[grpc]<3.0.0dev,>=2.16.0, but you have google-api-core 1.34.1 which is incompatible.\r\n",
      "google-colab 1.0.0 requires notebook==6.5.5, but you have notebook 6.5.4 which is incompatible.\r\n",
      "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\r\n",
      "google-colab 1.0.0 requires requests==2.32.3, but you have requests 2.28.2 which is incompatible.\r\n",
      "jupyterlab-server 2.27.3 requires requests>=2.31, but you have requests 2.28.2 which is incompatible.\r\n",
      "langchain 0.3.12 requires async-timeout<5.0.0,>=4.0.0; python_version < \"3.11\", but you have async-timeout 5.0.1 which is incompatible.\r\n",
      "pandas-gbq 0.25.0 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\r\n",
      "plotnine 0.14.4 requires matplotlib>=3.8.0, but you have matplotlib 3.7.5 which is incompatible.\r\n",
      "pymc 5.19.1 requires rich>=13.7.1, but you have rich 13.4.2 which is incompatible.\r\n",
      "pytensor 2.26.4 requires filelock>=3.15, but you have filelock 3.14.0 which is incompatible.\r\n",
      "pytorch-lightning 2.5.0.post0 requires torch>=2.1.0, but you have torch 1.13.1+cu116 which is incompatible.\r\n",
      "sphinx 8.1.3 requires requests>=2.30.0, but you have requests 2.28.2 which is incompatible.\r\n",
      "torchmetrics 1.6.1 requires torch>=2.0.0, but you have torch 1.13.1+cu116 which is incompatible.\r\n",
      "yfinance 0.2.50 requires requests>=2.31, but you have requests 2.28.2 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.7/452.7 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install torch==1.13.1+cu116 torchvision==0.14.1+cu116 -f https://download.pytorch.org/whl/torch_stable.html -q\n",
    "!pip install mmcv-full==1.7.1 -f https://download.openmmlab.com/mmcv/dist/cu116/torch1.13.0/index.html -q\n",
    "!pip install mmdet==2.28.2 -q\n",
    "!pip install -U openmim -q\n",
    "!mim install \"mmengine>=0.7.0\" -q\n",
    "!pip install xmltodict -q  # For dataset conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d6c71f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T19:23:25.469556Z",
     "iopub.status.busy": "2025-03-17T19:23:25.469244Z",
     "iopub.status.idle": "2025-03-17T19:23:27.155138Z",
     "shell.execute_reply": "2025-03-17T19:23:27.154207Z"
    },
    "papermill": {
     "duration": 1.730416,
     "end_time": "2025-03-17T19:23:27.156824",
     "exception": false,
     "start_time": "2025-03-17T19:23:25.426408",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\r\n",
      "Copyright (c) 2005-2023 NVIDIA Corporation\r\n",
      "Built on Tue_Aug_15_22:02:13_PDT_2023\r\n",
      "Cuda compilation tools, release 12.2, V12.2.140\r\n",
      "Build cuda_12.2.r12.2/compiler.33191640_0\r\n",
      "PyTorch: 1.13.1+cu116 CUDA Available: True CUDA Version: 11.6\r\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version\n",
    "!python -c \"import torch; print('PyTorch:', torch.__version__, 'CUDA Available:', torch.cuda.is_available(), 'CUDA Version:', torch.version.cuda)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbcbb726",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T19:23:27.242290Z",
     "iopub.status.busy": "2025-03-17T19:23:27.241953Z",
     "iopub.status.idle": "2025-03-17T19:23:41.494480Z",
     "shell.execute_reply": "2025-03-17T19:23:41.493250Z"
    },
    "papermill": {
     "duration": 14.296734,
     "end_time": "2025-03-17T19:23:41.496199",
     "exception": false,
     "start_time": "2025-03-17T19:23:27.199465",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into '/kaggle/working/mmrotate'...\r\n",
      "remote: Enumerating objects: 3897, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (1265/1265), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (386/386), done.\u001b[K\r\n",
      "remote: Total 3897 (delta 987), reused 879 (delta 879), pack-reused 2632 (from 2)\u001b[K\r\n",
      "Receiving objects: 100% (3897/3897), 25.33 MiB | 20.52 MiB/s, done.\r\n",
      "Resolving deltas: 100% (2384/2384), done.\r\n",
      "/kaggle/working/mmrotate\n",
      "Obtaining file:///kaggle/working/mmrotate\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "Collecting e2cnn (from mmrotate==0.3.4)\r\n",
      "  Downloading e2cnn-0.2.3-py3-none-any.whl.metadata (15 kB)\r\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mmrotate==0.3.4) (3.7.5)\r\n",
      "Requirement already satisfied: mmcv-full in /usr/local/lib/python3.10/dist-packages (from mmrotate==0.3.4) (1.7.1)\r\n",
      "Requirement already satisfied: mmdet<3.0.0,>=2.25.1 in /usr/local/lib/python3.10/dist-packages (from mmrotate==0.3.4) (2.28.2)\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mmrotate==0.3.4) (1.26.4)\r\n",
      "Requirement already satisfied: pycocotools in /usr/local/lib/python3.10/dist-packages (from mmrotate==0.3.4) (2.0.8)\r\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from mmrotate==0.3.4) (1.17.0)\r\n",
      "Requirement already satisfied: terminaltables in /usr/local/lib/python3.10/dist-packages (from mmrotate==0.3.4) (3.1.10)\r\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from mmrotate==0.3.4) (1.13.1+cu116)\r\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from mmdet<3.0.0,>=2.25.1->mmrotate==0.3.4) (1.13.1)\r\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from e2cnn->mmrotate==0.3.4) (1.13.1)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmrotate==0.3.4) (1.3.1)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmrotate==0.3.4) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmrotate==0.3.4) (4.55.3)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmrotate==0.3.4) (1.4.7)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmrotate==0.3.4) (24.2)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmrotate==0.3.4) (11.0.0)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmrotate==0.3.4) (3.2.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmrotate==0.3.4) (2.9.0.post0)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->mmrotate==0.3.4) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->mmrotate==0.3.4) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->mmrotate==0.3.4) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->mmrotate==0.3.4) (2025.0.1)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->mmrotate==0.3.4) (2022.0.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->mmrotate==0.3.4) (2.4.1)\r\n",
      "Requirement already satisfied: addict in /usr/local/lib/python3.10/dist-packages (from mmcv-full->mmrotate==0.3.4) (2.4.0)\r\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from mmcv-full->mmrotate==0.3.4) (6.0.2)\r\n",
      "Requirement already satisfied: yapf in /usr/local/lib/python3.10/dist-packages (from mmcv-full->mmrotate==0.3.4) (0.43.0)\r\n",
      "Requirement already satisfied: opencv-python>=3 in /usr/local/lib/python3.10/dist-packages (from mmcv-full->mmrotate==0.3.4) (4.10.0.84)\r\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->mmrotate==0.3.4) (4.12.2)\r\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->mmrotate==0.3.4) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->mmrotate==0.3.4) (2022.0.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->mmrotate==0.3.4) (1.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->mmrotate==0.3.4) (2024.2.0)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->e2cnn->mmrotate==0.3.4) (1.3.0)\r\n",
      "Requirement already satisfied: platformdirs>=3.5.1 in /usr/local/lib/python3.10/dist-packages (from yapf->mmcv-full->mmrotate==0.3.4) (4.3.6)\r\n",
      "Requirement already satisfied: tomli>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from yapf->mmcv-full->mmrotate==0.3.4) (2.2.1)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->mmrotate==0.3.4) (2024.2.0)\r\n",
      "Downloading e2cnn-0.2.3-py3-none-any.whl (225 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.3/225.3 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: e2cnn, mmrotate\r\n",
      "  Running setup.py develop for mmrotate\r\n",
      "Successfully installed e2cnn-0.2.3 mmrotate-0.3.4\r\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Clone and Install MMRotate 0.3.4\n",
    "!git clone https://github.com/open-mmlab/mmrotate.git /kaggle/working/mmrotate\n",
    "%cd /kaggle/working/mmrotate\n",
    "# !git checkout v0.3.4  # Ensure exact version\n",
    "!pip install -r requirements/build.txt -q\n",
    "!pip install -v -e . -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99fce91e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T19:23:41.585047Z",
     "iopub.status.busy": "2025-03-17T19:23:41.584658Z",
     "iopub.status.idle": "2025-03-17T19:23:43.103327Z",
     "shell.execute_reply": "2025-03-17T19:23:43.102070Z"
    },
    "papermill": {
     "duration": 1.565561,
     "end_time": "2025-03-17T19:23:43.105815",
     "exception": false,
     "start_time": "2025-03-17T19:23:41.540254",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mmcv-full                          1.7.1\r\n",
      "mmdet                              2.28.2\r\n",
      "mmengine                           0.10.7\r\n",
      "mmrotate                           0.3.4                /kaggle/working/mmrotate\r\n",
      "pytorch-ignite                     0.5.1\r\n",
      "pytorch-lightning                  2.5.0.post0\r\n",
      "torch                              1.13.1+cu116\r\n",
      "torchaudio                         2.5.1+cu121\r\n",
      "torchinfo                          1.8.0\r\n",
      "torchmetrics                       1.6.1\r\n",
      "torchsummary                       1.5.1\r\n",
      "torchtune                          0.5.0\r\n",
      "torchvision                        0.14.1+cu116\r\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Verify Installations\n",
    "!pip list | grep -E 'torch|mmcv|mmdet|mmengine|mmrotate'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4e86686",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T19:23:43.196210Z",
     "iopub.status.busy": "2025-03-17T19:23:43.195831Z",
     "iopub.status.idle": "2025-03-17T19:23:43.211751Z",
     "shell.execute_reply": "2025-03-17T19:23:43.211001Z"
    },
    "papermill": {
     "duration": 0.062887,
     "end_time": "2025-03-17T19:23:43.213335",
     "exception": false,
     "start_time": "2025-03-17T19:23:43.150448",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 6: Prepare Dataset (SCCOS to DOTA format)\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import xmltodict\n",
    "import tqdm\n",
    "import math\n",
    "\n",
    "dataset_path = \"/kaggle/input/sccos-dataset/\"\n",
    "working_dir = \"/kaggle/working/sccos_dota\"\n",
    "train_images_dir = os.path.join(working_dir, \"train/images\")\n",
    "train_labels_dir = os.path.join(working_dir, \"train/labels\")\n",
    "val_images_dir = os.path.join(working_dir, \"val/images\")\n",
    "val_labels_dir = os.path.join(working_dir, \"val/labels\")\n",
    "test_images_dir = os.path.join(working_dir, \"test/images\")\n",
    "test_labels_dir = os.path.join(working_dir, \"test/labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ada4cbb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T19:23:43.303870Z",
     "iopub.status.busy": "2025-03-17T19:23:43.303472Z",
     "iopub.status.idle": "2025-03-17T19:26:01.577045Z",
     "shell.execute_reply": "2025-03-17T19:26:01.575985Z"
    },
    "papermill": {
     "duration": 138.321298,
     "end_time": "2025-03-17T19:26:01.578619",
     "exception": false,
     "start_time": "2025-03-17T19:23:43.257321",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset split: Train=3711, Val=464, Test=464\n",
      "Converting train set to DOTA format...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3711/3711 [00:01<00:00, 1919.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting val set to DOTA format...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 464/464 [00:00<00:00, 1899.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting test set to DOTA format...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 464/464 [00:00<00:00, 2082.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset conversion to DOTA format complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Clean and recreate directories\n",
    "if os.path.exists(working_dir):\n",
    "    shutil.rmtree(working_dir)\n",
    "for dir_path in [train_images_dir, train_labels_dir, val_images_dir, val_labels_dir, test_images_dir, test_labels_dir]:\n",
    "    os.makedirs(dir_path, exist_ok=True)\n",
    "\n",
    "# Source paths\n",
    "train_img_dir = os.path.join(dataset_path, \"train/images\")\n",
    "train_ann_dir = os.path.join(dataset_path, \"train/annotations\")\n",
    "test_img_dir = os.path.join(dataset_path, \"test/images\")\n",
    "test_ann_dir = os.path.join(dataset_path, \"test/annotations\")\n",
    "\n",
    "# Get all files and split\n",
    "train_files = [f for f in os.listdir(train_img_dir) if f.endswith('.png')]\n",
    "test_files = [f for f in os.listdir(test_img_dir) if f.endswith('.png')]\n",
    "random.seed(42)\n",
    "random.shuffle(train_files)\n",
    "random.shuffle(test_files)\n",
    "test_size = len(test_files)\n",
    "val_size = test_size // 2\n",
    "val_files = test_files[:val_size]\n",
    "test_files = test_files[val_size:]\n",
    "\n",
    "# Copy files\n",
    "def copy_files(file_list, src_img_dir, src_ann_dir, dst_img_dir, dst_ann_dir):\n",
    "    for img_file in file_list:\n",
    "        shutil.copy(os.path.join(src_img_dir, img_file), os.path.join(dst_img_dir, img_file))\n",
    "        ann_file = img_file.replace('.png', '.xml')\n",
    "        if os.path.exists(os.path.join(src_ann_dir, ann_file)):\n",
    "            shutil.copy(os.path.join(src_ann_dir, ann_file), os.path.join(dst_ann_dir, ann_file))\n",
    "\n",
    "copy_files(train_files, train_img_dir, train_ann_dir, train_images_dir, train_labels_dir)\n",
    "copy_files(val_files, test_img_dir, test_ann_dir, val_images_dir, val_labels_dir)\n",
    "copy_files(test_files, test_img_dir, test_ann_dir, test_images_dir, test_labels_dir)\n",
    "print(f\"Dataset split: Train={len(train_files)}, Val={len(val_files)}, Test={len(test_files)}\")\n",
    "\n",
    "# Convert XML to DOTA format\n",
    "def convert_robndbox_to_corners(cx, cy, w, h, angle):\n",
    "    angle = float(angle)\n",
    "    cx, cy, w, h = float(cx), float(cy), float(w), float(h)\n",
    "    cos_a = math.cos(angle)\n",
    "    sin_a = math.sin(angle)\n",
    "    dx, dy = w / 2, h / 2\n",
    "    corners = [(-dx, -dy), (dx, -dy), (dx, dy), (-dx, dy)]\n",
    "    rotated_corners = [(cx + x * cos_a - y * sin_a, cy + x * sin_a + y * cos_a) for x, y in corners]\n",
    "    return rotated_corners\n",
    "\n",
    "def convert_xml_to_dota(xml_path, output_label_dir):\n",
    "    with open(xml_path, 'r') as f:\n",
    "        xml_data = xmltodict.parse(f.read())\n",
    "    objects = xml_data['annotation'].get('object', [])\n",
    "    if not isinstance(objects, list):\n",
    "        objects = [objects] if objects else []\n",
    "    txt_lines = []\n",
    "    for obj in objects:\n",
    "        if obj and 'robndbox' in obj:\n",
    "            robndbox = obj['robndbox']\n",
    "            try:\n",
    "                cx, cy, w, h, angle = robndbox['cx'], robndbox['cy'], robndbox['w'], robndbox['h'], robndbox['angle']\n",
    "                (x1, y1), (x2, y2), (x3, y3), (x4, y4) = convert_robndbox_to_corners(cx, cy, w, h, angle)\n",
    "                class_name = \"ship\"\n",
    "                difficulty = 0\n",
    "                txt_lines.append(f\"{x1:.2f} {y1:.2f} {x2:.2f} {y2:.2f} {x3:.2f} {y3:.2f} {x4:.2f} {y4:.2f} {class_name} {difficulty}\")\n",
    "            except (KeyError, ValueError) as e:\n",
    "                print(f\"Invalid robndbox data in {xml_path}: {e}\")\n",
    "                continue\n",
    "    txt_filename = os.path.splitext(os.path.basename(xml_path))[0] + \".txt\"\n",
    "    txt_path = os.path.join(output_label_dir, txt_filename)\n",
    "    if txt_lines:\n",
    "        with open(txt_path, 'w') as f:\n",
    "            f.write(\"\\n\".join(txt_lines))\n",
    "    os.remove(xml_path)\n",
    "\n",
    "for split, label_dir in [(\"train\", train_labels_dir), (\"val\", val_labels_dir), (\"test\", test_labels_dir)]:\n",
    "    print(f\"Converting {split} set to DOTA format...\")\n",
    "    for xml_file in tqdm.tqdm(os.listdir(label_dir)):\n",
    "        if xml_file.endswith(\".xml\"):\n",
    "            convert_xml_to_dota(os.path.join(label_dir, xml_file), label_dir)\n",
    "print(\"Dataset conversion to DOTA format complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1482acb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T19:26:01.670046Z",
     "iopub.status.busy": "2025-03-17T19:26:01.669644Z",
     "iopub.status.idle": "2025-03-17T19:27:58.845758Z",
     "shell.execute_reply": "2025-03-17T19:27:58.844654Z"
    },
    "papermill": {
     "duration": 117.268298,
     "end_time": "2025-03-17T19:27:58.892332",
     "exception": false,
     "start_time": "2025-03-17T19:26:01.624034",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.2/190.2 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating training images...\n",
      "Empty file detected: /kaggle/working/sccos_dota/train/images/2284.png\n",
      "Removed bad image: /kaggle/working/sccos_dota/train/images/2284.png\n",
      "Removed corresponding label: /kaggle/working/sccos_dota/train/labels/2284.txt\n",
      "Found and handled 1 bad files.\n"
     ]
    }
   ],
   "source": [
    "# NEW: Fix YAPF compatibility issue\n",
    "!pip install yapf==0.32.0 -q  # Pin to a version compatible with MMCV 1.7.1\n",
    "\n",
    "# NEW: Validate training images\n",
    "import os\n",
    "import cv2\n",
    "import mmcv\n",
    "\n",
    "def validate_images(image_dir, label_dir):\n",
    "    bad_files = []\n",
    "    for img_file in os.listdir(image_dir):\n",
    "        if not img_file.endswith('.png'):\n",
    "            continue\n",
    "        img_path = os.path.join(image_dir, img_file)\n",
    "        # Check if file is empty\n",
    "        if os.path.getsize(img_path) == 0:\n",
    "            bad_files.append(img_file)\n",
    "            print(f\"Empty file detected: {img_path}\")\n",
    "            continue\n",
    "        # Try loading with mmcv (mimics pipeline behavior)\n",
    "        try:\n",
    "            img = mmcv.imread(img_path)\n",
    "            if img is None:\n",
    "                raise ValueError(\"Image loaded as None\")\n",
    "        except Exception as e:\n",
    "            bad_files.append(img_file)\n",
    "            print(f\"Corrupt or unreadable file: {img_path} - Error: {e}\")\n",
    "    \n",
    "    # Remove bad files and their labels\n",
    "    for bad_file in bad_files:\n",
    "        img_path = os.path.join(image_dir, bad_file)\n",
    "        label_file = bad_file.replace('.png', '.txt')\n",
    "        label_path = os.path.join(label_dir, label_file)\n",
    "        if os.path.exists(img_path):\n",
    "            os.remove(img_path)\n",
    "            print(f\"Removed bad image: {img_path}\")\n",
    "        if os.path.exists(label_path):\n",
    "            os.remove(label_path)\n",
    "            print(f\"Removed corresponding label: {label_path}\")\n",
    "    \n",
    "    if bad_files:\n",
    "        print(f\"Found and handled {len(bad_files)} bad files.\")\n",
    "    else:\n",
    "        print(\"All images validated successfully.\")\n",
    "\n",
    "# Validate training set\n",
    "train_images_dir = \"/kaggle/working/sccos_dota/train/images\"\n",
    "train_labels_dir = \"/kaggle/working/sccos_dota/train/labels\"\n",
    "print(\"Validating training images...\")\n",
    "validate_images(train_images_dir, train_labels_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eed30c5a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T19:27:58.983988Z",
     "iopub.status.busy": "2025-03-17T19:27:58.983495Z",
     "iopub.status.idle": "2025-03-17T19:27:58.990562Z",
     "shell.execute_reply": "2025-03-17T19:27:58.989623Z"
    },
    "papermill": {
     "duration": 0.054555,
     "end_time": "2025-03-17T19:27:58.992102",
     "exception": false,
     "start_time": "2025-03-17T19:27:58.937547",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReDet configuration saved to /kaggle/working/mmrotate/configs/redet/redet_re50_refpn_1x_sccos.py\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Create Config File for ReDet\n",
    "config_content = \"\"\"\n",
    "_base_ = 'redet_re50_refpn_1x_dota_le90.py'\n",
    "dataset_type = 'DOTADataset'\n",
    "data_root = '/kaggle/working/sccos_dota/'\n",
    "classes = ('ship',)  # Single class\n",
    "img_norm_cfg = dict(mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
    "angle_version = 'le90'  # Match base config\n",
    "\n",
    "train_pipeline = [\n",
    "    dict(type='LoadImageFromFile'),\n",
    "    dict(type='LoadAnnotations', with_bbox=True),\n",
    "    dict(type='RResize', img_scale=(1024, 1024)),\n",
    "    dict(type='RRandomFlip', flip_ratio=0.1, version=angle_version),\n",
    "    dict(type='Normalize', **img_norm_cfg),\n",
    "    dict(type='Pad', size_divisor=32),\n",
    "    dict(type='DefaultFormatBundle'),\n",
    "    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n",
    "]\n",
    "test_pipeline = [\n",
    "    dict(type='LoadImageFromFile'),\n",
    "    dict(type='MultiScaleFlipAug', img_scale=(1024, 1024), flip=False,\n",
    "         transforms=[\n",
    "             dict(type='RResize'),\n",
    "             dict(type='Normalize', **img_norm_cfg),\n",
    "             dict(type='Pad', size_divisor=32),\n",
    "             dict(type='DefaultFormatBundle'),\n",
    "             dict(type='Collect', keys=['img'])\n",
    "         ])\n",
    "]\n",
    "data = dict(\n",
    "    samples_per_gpu=4,\n",
    "    workers_per_gpu=1,\n",
    "    train=dict(\n",
    "        type=dataset_type,\n",
    "        ann_file=data_root + 'train/labels/',\n",
    "        img_prefix=data_root + 'train/images/',\n",
    "        pipeline=train_pipeline,\n",
    "        classes=classes,\n",
    "        version=angle_version),\n",
    "    val=dict(\n",
    "        type=dataset_type,\n",
    "        ann_file=data_root + 'val/labels/',\n",
    "        img_prefix=data_root + 'val/images/',\n",
    "        pipeline=test_pipeline,\n",
    "        classes=classes,\n",
    "        version=angle_version),\n",
    "    test=dict(\n",
    "        type=dataset_type,\n",
    "        ann_file=data_root + 'test/labels/',\n",
    "        img_prefix=data_root + 'test/images/',\n",
    "        pipeline=test_pipeline,\n",
    "        classes=classes,\n",
    "        version=angle_version))\n",
    "evaluation = dict(\n",
    "    interval=1,\n",
    "    metric='mAP'\n",
    ")\n",
    "optimizer = dict(type='SGD', lr=0.005, momentum=0.9, weight_decay=0.0001)\n",
    "optimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))\n",
    "lr_config = dict(\n",
    "    policy='step',\n",
    "    warmup='linear',\n",
    "    warmup_iters=200,\n",
    "    warmup_ratio=1.0 / 3,\n",
    "    step=[8, 11])\n",
    "runner = dict(type='EpochBasedRunner', max_epochs=10)\n",
    "checkpoint_config = dict(interval=1)\n",
    "log_config = dict(interval=100, hooks=[dict(type='TextLoggerHook')])\n",
    "model = dict(\n",
    "    type='ReDet',\n",
    "    backbone=dict(\n",
    "        type='ReResNet',\n",
    "        depth=50,\n",
    "        num_stages=4,\n",
    "        out_indices=(0, 1, 2, 3),\n",
    "        frozen_stages=1,\n",
    "        style='pytorch',\n",
    "        init_cfg=dict(type='Pretrained', checkpoint='torchvision://resnet50')),\n",
    "    neck=dict(\n",
    "        type='ReFPN',\n",
    "        in_channels=[256, 512, 1024, 2048],\n",
    "        out_channels=256,\n",
    "        num_outs=5),\n",
    "    rpn_head=dict(\n",
    "        type='OrientedRPNHead',\n",
    "        in_channels=256,\n",
    "        feat_channels=256,\n",
    "        version=angle_version,\n",
    "        anchor_generator=dict(\n",
    "            type='AnchorGenerator',\n",
    "            scales=[8],\n",
    "            ratios=[0.5, 1.0, 2.0],\n",
    "            strides=[4, 8, 16, 32, 64]),\n",
    "        bbox_coder=dict(\n",
    "            type='DeltaXYWHBBoxCoder',\n",
    "            target_means=[0., 0., 0., 0.],\n",
    "            target_stds=[1.0, 1.0, 1.0, 1.0]),\n",
    "        loss_cls=dict(\n",
    "            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),\n",
    "        loss_bbox=dict(type='SmoothL1Loss', beta=1.0 / 9.0, loss_weight=1.0)),\n",
    "    roi_head=dict(\n",
    "        type='RoITransRoIHead',\n",
    "        version=angle_version,\n",
    "        bbox_roi_extractor=dict(\n",
    "            type='SingleRoIExtractor',\n",
    "            roi_layer=dict(type='RoIAlignRotated', out_size=7, sample_num=2),\n",
    "            out_channels=256,\n",
    "            featmap_strides=[4, 8, 16, 32]),\n",
    "        bbox_head=dict(\n",
    "            type='RoITransHead',\n",
    "            in_channels=256,\n",
    "            fc_out_channels=1024,\n",
    "            roi_feat_size=7,\n",
    "            num_classes=1,  # Single class: ship\n",
    "            bbox_coder=dict(\n",
    "                type='DeltaXYWHAOBBoxCoder',\n",
    "                angle_range=angle_version,\n",
    "                norm_factor=None,\n",
    "                edge_swap=True,\n",
    "                proj_xy=True,\n",
    "                target_means=[0., 0., 0., 0., 0.],\n",
    "                target_stds=[0.1, 0.1, 0.2, 0.2, 0.1]),\n",
    "            reg_class_agnostic=True,\n",
    "            loss_cls=dict(\n",
    "                type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0),\n",
    "            loss_bbox=dict(type='SmoothL1Loss', beta=1.0, loss_weight=1.0)))\n",
    ")\n",
    "\"\"\"\n",
    "config_path = \"/kaggle/working/mmrotate/configs/redet/redet_re50_refpn_1x_sccos.py\"\n",
    "with open(config_path, 'w') as f:\n",
    "    f.write(config_content)\n",
    "print(f\"ReDet configuration saved to {config_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d4b498f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T19:27:59.084361Z",
     "iopub.status.busy": "2025-03-17T19:27:59.083994Z",
     "iopub.status.idle": "2025-03-17T19:28:08.291174Z",
     "shell.execute_reply": "2025-03-17T19:28:08.290142Z"
    },
    "papermill": {
     "duration": 9.255866,
     "end_time": "2025-03-17T19:28:08.292604",
     "exception": false,
     "start_time": "2025-03-17T19:27:59.036738",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/mmrotate\n",
      "/usr/local/lib/python3.10/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 2.0.5 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\r\n",
      "  check_for_updates()\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/kaggle/working/mmrotate/tools/train.py\", line 194, in <module>\r\n",
      "    main()\r\n",
      "  File \"/kaggle/working/mmrotate/tools/train.py\", line 86, in main\r\n",
      "    cfg = Config.fromfile(args.config)\r\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/mmcv/utils/config.py\", line 340, in fromfile\r\n",
      "    cfg_dict, cfg_text = Config._file2dict(filename,\r\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/mmcv/utils/config.py\", line 268, in _file2dict\r\n",
      "    base_cfg_dict = Config._merge_a_into_b(cfg_dict, base_cfg_dict)\r\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/mmcv/utils/config.py\", line 327, in _merge_a_into_b\r\n",
      "    b[k] = Config._merge_a_into_b(v, b[k], allow_list_keys)\r\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/mmcv/utils/config.py\", line 327, in _merge_a_into_b\r\n",
      "    b[k] = Config._merge_a_into_b(v, b[k], allow_list_keys)\r\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/mmcv/utils/config.py\", line 321, in _merge_a_into_b\r\n",
      "    raise TypeError(\r\n",
      "TypeError: bbox_roi_extractor={'type': 'SingleRoIExtractor', 'roi_layer': {'type': 'RoIAlignRotated', 'out_size': 7, 'sample_num': 2}, 'out_channels': 256, 'featmap_strides': [4, 8, 16, 32]} in child config cannot inherit from base because bbox_roi_extractor is a dict in the child config but is of type <class 'list'> in base config. You may set `_delete_=True` to ignore the base config.\r\n",
      "Training completed.\n"
     ]
    }
   ],
   "source": [
    "# Step 8: Train the Model\n",
    "%cd /kaggle/working/mmrotate\n",
    "!mkdir -p /kaggle/working/runs/redet_train\n",
    "!python tools/train.py \\\n",
    "    configs/redet/redet_re50_refpn_1x_sccos.py \\\n",
    "    --work-dir /kaggle/working/runs/redet_train \\\n",
    "    --gpus 1\n",
    "print(\"Training completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06c51529",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T19:28:08.383372Z",
     "iopub.status.busy": "2025-03-17T19:28:08.383043Z",
     "iopub.status.idle": "2025-03-17T19:28:13.783153Z",
     "shell.execute_reply": "2025-03-17T19:28:13.782063Z"
    },
    "papermill": {
     "duration": 5.448544,
     "end_time": "2025-03-17T19:28:13.784600",
     "exception": false,
     "start_time": "2025-03-17T19:28:08.336056",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/mmrotate\n",
      "/usr/local/lib/python3.10/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 2.0.5 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\r\n",
      "  check_for_updates()\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/kaggle/working/mmrotate/tools/test.py\", line 271, in <module>\r\n",
      "    main()\r\n",
      "  File \"/kaggle/working/mmrotate/tools/test.py\", line 116, in main\r\n",
      "    cfg = Config.fromfile(args.config)\r\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/mmcv/utils/config.py\", line 340, in fromfile\r\n",
      "    cfg_dict, cfg_text = Config._file2dict(filename,\r\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/mmcv/utils/config.py\", line 268, in _file2dict\r\n",
      "    base_cfg_dict = Config._merge_a_into_b(cfg_dict, base_cfg_dict)\r\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/mmcv/utils/config.py\", line 327, in _merge_a_into_b\r\n",
      "    b[k] = Config._merge_a_into_b(v, b[k], allow_list_keys)\r\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/mmcv/utils/config.py\", line 327, in _merge_a_into_b\r\n",
      "    b[k] = Config._merge_a_into_b(v, b[k], allow_list_keys)\r\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/mmcv/utils/config.py\", line 321, in _merge_a_into_b\r\n",
      "    raise TypeError(\r\n",
      "TypeError: bbox_roi_extractor={'type': 'SingleRoIExtractor', 'roi_layer': {'type': 'RoIAlignRotated', 'out_size': 7, 'sample_num': 2}, 'out_channels': 256, 'featmap_strides': [4, 8, 16, 32]} in child config cannot inherit from base because bbox_roi_extractor is a dict in the child config but is of type <class 'list'> in base config. You may set `_delete_=True` to ignore the base config.\r\n",
      "Testing completed. Results saved to /kaggle/working/runs/redet_test_results.pkl\n"
     ]
    }
   ],
   "source": [
    "# Step 9: Test the Model\n",
    "%cd /kaggle/working/mmrotate\n",
    "!python tools/test.py \\\n",
    "    configs/redet/redet_re50_refpn_1x_sccos.py \\\n",
    "    /kaggle/working/runs/redet_train/latest.pth \\\n",
    "    --eval mAP \\\n",
    "    --out /kaggle/working/runs/redet_test_results.pkl\n",
    "print(\"Testing completed. Results saved to /kaggle/working/runs/redet_test_results.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6c6f32",
   "metadata": {
    "papermill": {
     "duration": 0.046223,
     "end_time": "2025-03-17T19:28:13.878464",
     "exception": false,
     "start_time": "2025-03-17T19:28:13.832241",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6771261,
     "sourceId": 10895847,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 496.5644,
   "end_time": "2025-03-17T19:28:14.748425",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-03-17T19:19:58.184025",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
